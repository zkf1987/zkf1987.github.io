<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[容器云线程阻塞引起CPU过高问题排查]]></title>
    <url>%2F2019%2F01%2F22%2Fblog%2F%E5%AE%B9%E5%99%A8%E4%BA%91%E7%BA%BF%E7%A8%8B%E9%98%BB%E5%A1%9E%E5%BC%95%E8%B5%B7CPU%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[描述解决因线程阻塞导致主机CPU出现IO等待问题。 情况描述主机上出现CPU总体使用率到达约35%，并且wa 持续在18%以上的情况； 123456top top - 15:56:04 up 125 days, 5:19, 2 users, load average: 25.54, 26.08, 26.86Tasks: 1655 total, 4 running, 1651 sleeping, 0 stopped, 0 zombie%Cpu(s): 7.4 us, 5.6 sy, 0.0 ni, 68.2 id, 18.5 wa, 0.0 hi, 0.2 si, 0.0 stKiB Mem : 39454579+total, 31070960+free, 44192168 used, 39644028 buff/cacheKiB Swap: 32767996 total, 31950172 free, 817824 used. 34117923+avail Mem 通过分析，发现其中7个核因IO wait导致CPU占用到达近100%；123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051mpstat -P ALL 1 3 Average: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idleAverage: all 2.84 0.01 5.44 18.09 0.00 0.36 0.00 0.00 0.00 73.26Average: 0 6.09 0.00 5.38 87.46 0.00 1.08 0.00 0.00 0.00 0.00Average: 1 4.15 0.00 3.46 0.35 0.00 0.35 0.00 0.00 0.00 91.70Average: 2 6.16 0.00 7.88 84.93 0.00 1.03 0.00 0.00 0.00 0.00Average: 3 5.84 0.00 5.50 0.00 0.00 1.72 0.00 0.00 0.00 86.94Average: 4 5.84 0.00 4.12 0.00 0.00 1.03 0.00 0.00 0.00 89.00Average: 5 6.16 0.00 5.48 0.00 0.00 1.03 0.00 0.00 0.00 87.33Average: 6 10.17 0.00 4.41 0.00 0.00 1.36 0.00 0.00 0.00 84.07Average: 7 5.88 0.00 4.15 0.00 0.00 1.04 0.00 0.00 0.00 88.93Average: 8 4.78 0.00 6.83 0.00 0.00 1.02 0.00 0.00 0.00 87.37Average: 9 4.79 0.00 8.22 86.30 0.00 0.68 0.00 0.00 0.00 0.00Average: 10 6.85 0.00 5.14 0.00 0.00 1.03 0.00 0.00 0.00 86.99Average: 11 7.17 0.00 4.10 87.03 0.00 1.71 0.00 0.00 0.00 0.00Average: 12 1.01 0.00 6.42 0.00 0.00 0.00 0.00 0.00 0.00 92.57Average: 13 1.36 0.00 10.51 0.00 0.00 0.00 0.00 0.00 0.00 88.14Average: 14 1.68 0.00 15.49 0.34 0.00 0.00 0.00 0.00 0.00 82.49Average: 15 1.02 0.00 3.06 95.92 0.00 0.00 0.00 0.00 0.00 0.00Average: 16 1.01 0.00 3.03 0.34 0.00 0.00 0.00 0.00 0.00 95.62Average: 17 1.02 0.00 3.05 0.34 0.00 0.00 0.00 0.00 0.00 95.59Average: 18 1.01 0.00 2.70 0.00 0.00 0.00 0.00 0.00 0.00 96.28Average: 19 1.02 0.00 2.72 96.26 0.00 0.00 0.00 0.00 0.00 0.00Average: 20 1.36 0.00 4.76 0.00 0.00 0.00 0.00 0.00 0.00 93.88Average: 21 0.68 0.00 3.39 0.00 0.00 0.00 0.00 0.00 0.00 95.93Average: 22 1.69 0.00 2.71 0.00 0.00 0.00 0.00 0.00 0.00 95.59Average: 23 1.36 0.00 3.05 0.00 0.00 0.00 0.00 0.00 0.00 95.59Average: 24 4.73 0.00 3.38 0.00 0.00 0.68 0.00 0.00 0.00 91.22Average: 25 8.70 0.00 36.12 55.18 0.00 0.00 0.00 0.00 0.00 0.00Average: 26 4.73 0.00 7.09 87.50 0.00 0.68 0.00 0.00 0.00 0.00Average: 27 1.34 0.00 2.68 0.00 0.00 0.33 0.00 0.00 0.00 95.65Average: 28 3.04 0.00 3.38 0.00 0.00 0.34 0.00 0.00 0.00 93.24Average: 29 2.35 0.00 2.35 0.00 0.00 0.34 0.00 0.00 0.00 94.97Average: 30 2.01 0.00 3.34 94.31 0.00 0.33 0.00 0.00 0.00 0.00Average: 31 2.01 0.00 2.35 0.00 0.00 0.34 0.00 0.00 0.00 95.30Average: 32 2.02 0.00 8.75 0.00 0.00 0.67 0.00 0.00 0.00 88.55Average: 33 1.34 0.00 24.83 0.00 0.00 0.67 0.00 0.00 0.00 73.15Average: 34 4.73 0.00 2.03 0.00 0.00 0.34 0.00 0.00 0.00 92.91Average: 35 2.01 0.00 2.68 0.00 0.00 0.34 0.00 0.00 0.00 94.97Average: 36 0.67 0.00 2.68 0.00 0.00 0.00 0.00 0.00 0.00 96.66Average: 37 0.00 0.00 2.01 97.99 0.00 0.00 0.00 0.00 0.00 0.00Average: 38 1.00 0.00 11.33 0.00 0.00 0.00 0.00 0.00 0.00 87.67Average: 39 0.33 0.00 2.67 0.00 0.00 0.00 0.00 0.00 0.00 97.00Average: 40 0.67 0.33 2.68 0.00 0.00 0.00 0.00 0.00 0.00 96.32Average: 41 0.33 0.00 2.33 0.00 0.00 0.00 0.00 0.00 0.00 97.33Average: 42 0.67 0.00 2.34 0.00 0.00 0.00 0.00 0.00 0.00 96.99Average: 43 0.67 0.00 1.67 0.00 0.00 0.33 0.00 0.00 0.00 97.33Average: 44 0.33 0.00 2.00 0.00 0.00 0.00 0.00 0.00 0.00 97.67Average: 45 0.67 0.00 2.01 0.00 0.00 0.00 0.00 0.00 0.00 97.32Average: 46 0.33 0.00 2.33 0.00 0.00 0.00 0.00 0.00 0.00 97.33Average: 47 2.68 0.00 2.68 0.00 0.00 0.00 0.00 0.00 0.00 94.65 进一步问题定位，该主机存在17个阻塞线程，因此怀疑，主机上存在经常出现阻塞的进程12345vmstat 1 2procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 4 17 817824 310717472 5868 39639032 1 1 1 9 0 0 0 2 91 7 0 4 17 817824 310716000 5868 39639172 0 0 0 1568 52662 261199 2 5 74 19 0 通过以下命令查出主机阻塞进程，且CPU占用量异常高，PID为： 52726。123ps -eo ppid,pid,user,stat,pcpu.comm,wchan | grep DPPID PID USER STAT %CPU COMMAND WCHAN 52726 52726 root DS 475493 sh vmpressure 并通过以下方式进一步判断，发现该进程占用的CPU为异常IO wait的核。123456while : ; do ps -eo pid,ni,pri,pcpu,psr,comm |grep "52726" ; sleep 1 ; done52726 0 19 475510 42 sh52726 0 19 475510 8 sh52726 0 19 475510 8 sh52726 0 19 475510 9 sh52726 0 19 475510 19 sh 进一步确定该进程信息，通过查看命名空间下的pod，发现一直是terminating的状态；通过该命令强制删除1 kubectl delete pods mq-consumer-597b4cbb5-5hwx2 --grace-period=0 --force 说明：强制删除会出现一个告警警告：立即删除不等待确认正在运行的资源已终止。资源可能会无限期地继续在集群上运行。 登录到主机上，发现52726进程依然存在，最后通过kill -9 52726 52707 52739删除相关进程，并发现所有CPU核恢复正常。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何发现linux中引起高io等待的进程]]></title>
    <url>%2F2019%2F01%2F18%2Fblog%2F%E5%A6%82%E4%BD%95%E5%8F%91%E7%8E%B0linux%E4%B8%AD%E5%BC%95%E8%B5%B7%E9%AB%98io%E7%AD%89%E5%BE%85%E7%9A%84%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[描述使用系统命令top即可看到如下类似信息：1Cpu(s): 0.0%us, 0.5%sy, 0.0%ni, 99.5%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st us 用户空间占用CPU百分比 sy 内核空间占用CPU百分比 ni 用户进程空间内改变过优先级的进程占用CPU百分比 id 空闲CPU百分比 wa 等待输入输出的CPU时间百分比 hi 硬件中断 si 软件中断 st: 实时 linux用很多可用的工具可以用来发现排错，有些很容易使用，有些用法则比较高级 查看I/O wait问题不仅需要使用一些高级工具，也需要一些基本工具的高级用法。I/O wait之所以难以排查是因为默认有太多的工具告诉你系统I/O阻塞，但没那么多工具可以帮你缩小范围以便确定出是哪个或哪些进程引起的问题。 首先回答是不是I/O引起系统缓慢确定是不是I/O引起系统缓慢，你可以使用很多工具但最简单的还是unix命令top123456[root@coolnull ~]# top top - 14:31:20 up 35 min, 4 users, load average: 2.25, 1.74, 1.68 Tasks: 71 total, 1 running, 70 sleeping, 0 stopped, 0 zombie Cpu(s): 2.3%us, 1.7%sy, 0.0%ni, 0.0%id, 96.0%wa, 0.0%hi, 0.0%si, 0.0%st Mem: 245440k total, 241004k used, 4436k free, 496k buffers Swap: 409596k total, 5436k used, 404160k free, 182812k cached 从CPU(s) 这行你可以看出当前CPU I/O Wait的情况；越高的wa表示越多的cpu资源在等待I/O12wa -- iowaitAmount of time the CPU has been waiting for I/O to complete. //cpu已经等待I/O完成的时间 查找哪个硬盘正在被写入上面的top命令从系统面大体展示了I/O Wait，但它没有告诉你哪个硬盘正在被影响；为此我们需要使用iostat命令12345678[root@coolnull ~]# iostat -x 2 5 avg-cpu: %user %nice %system %iowait %steal %idle 3.66 0.00 47.64 48.69 0.00 0.00 Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %util sda 44.50 39.27 117.28 29.32 11220.94 13126.70 332.17 65.77 462.79 9.80 2274.71 7.60 111.41 dm-0 0.00 0.00 83.25 9.95 10515.18 4295.29 317.84 57.01 648.54 16.73 5935.79 11.48 107.02 dm-1 0.00 0.00 57.07 40.84 228.27 163.35 8.00 93.84 979.61 13.94 2329.08 10.93 107.02 上述示例的iostat命令将每2秒打印出报告，共打印5次；-x参数告诉iostata打印出更详尽的报告 iostat打印出的第1个报告，数值是基于最后一次系统启动的时间统计的；基于这个原因，在大部份情况下，iostat打印出的第1个报告应该被忽略。每个子报告都是基于上1次的报告。在这个例子中，我们的命令将打印5次报告，第2份报告就是从第1份报告开始后的硬盘数据，第3份报告基于第2份，依此类推。 上述示例，sda盘的%utilized达到了111.41%。这表示引起I/O慢的进程在写入sda盘。因为我这个测试实例中只有1个硬盘，但对于有多硬盘的服务器来说，这可以缩小在使用I/O的进程范围。 除了iostat的%utilized能提供丰富的信息外，像rrqm/s、wrqm/s这些每秒读、写的请求数，r/s、w/s每秒读写数也很有用。在我们的例子中，我们的程序看起来读写很繁重的信息也能帮助我们确定这个讨人厌的进程。 查找引起高I/O的进程iotop1234[root@coolnull ~]# iotop Total DISK READ: 8.00 M/s | Total DISK WRITE: 20.36 M/s TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND 15758 be/4 root 7.99 M/s 8.01 M/s 0.00 % 61.97 % bonnie++ -n 0 -u 0 -r 239 -s 478 -f -b -d /tmp 查看哪个进程使用硬盘最多的最简单的方法就是使用iotop命令。通过查看数据，我们很容易就能确定是bonnie++这个进程引起我们机器高I/O 虽然iotop好用，但默认主流的linux发行版中是没有安装的；并且我个人也不推荐依赖默认系统没有安装的命令。系统管理员总是会碰到这样的情况，他们没办法在短时间内简单地安装这些非默认包。 如果iotop没办法用，以下的步聚还是可以帮助你缩小这些讨人厌进程的范围 进程状态列表 ps命令能打印出内存，cpu的情况但没办法打印出硬盘I/O的情况。虽然ps没办法打印出I/O的情况，但它可以显示出进程是否在等待I/O。 The ps state field provides the processes current state; below is a list of states from the man page.ps状态列提供了进程当前的状态，以下从man ps上获取的进程stat列表12345678PROCESS STATE CODES D uninterruptible sleep (usually IO) R running or runnable (on run queue) S interruptible sleep (waiting for an event to complete) T stopped, either by a job control signal or because it is being traced. W paging (not valid since the 2.6.xx kernel) X dead (should never be seen) Z defunct ("zombie") process, terminated but not reaped by its parent. 等待I/O的进程通过处于uninterruptible sleep或D状态；通过给出这些信息我们就可以简单的查找出处在wait状态的进程 示例：123456789101112131415[root@coolnull ~]# for x in `seq 1 1 10`; do ps -eo state,pid,cmd | grep "^D"; echo "----"; sleep 5; done D 248 [jbd2/dm-0-8] D 16528 bonnie++ -n 0 -u 0 -r 239 -s 478 -f -b -d /tmp ---- D 22 [kswapd0] D 16528 bonnie++ -n 0 -u 0 -r 239 -s 478 -f -b -d /tmp ---- D 22 [kswapd0] D 16528 bonnie++ -n 0 -u 0 -r 239 -s 478 -f -b -d /tmp ---- D 22 [kswapd0] D 16528 bonnie++ -n 0 -u 0 -r 239 -s 478 -f -b -d /tmp ---- D 16528 bonnie++ -n 0 -u 0 -r 239 -s 478 -f -b -d /tmp ---- 上述命令会每5秒循环打印出位于D状态的进程，共打印10次 从上面的输出可以看出bonnie++，pid 16528比其它进程更加占用I/O。从这点，bonnie++看起来更有可能引起I/O Wait。但仅凭进程处于uninterruptible sleep state誊，还不能完全确定就是这引起的I/O wait。 为了帮助肯定我们的怀疑，我们可以使用/proc文件系统。在这个进程目录里，每个进程都有一个io文件，里面的数值跟iotop命令获取的I/O数值一样。12345678[root@coolnull ~]# cat /proc/16528/io rchar: 48752567 wchar: 549961789 syscr: 5967 syscw: 67138 read_bytes: 49020928 write_bytes: 549961728 cancelled_write_bytes: 0 read_bytes和write_bytes就这个进程读写硬盘的字节数。在这里，bonnie++已经读取了46MB，写入524MB的数据。对很多进程，这可能不是很多，但在我们这个实例这足够引起高i/o wait。 查找哪个文件在被繁重地写入 lsof命令会为你展示指定进程打开的所有文件或依赖提供选项的所有进程。从这个列表，人们可以根据文件的大小和/proc io文件里出现的次数做出有用的猜测，哪个文件正在被频繁地写入。 为了减少输出的内容，我们可以使用-p 选项来只打印指定进程id打开的文件123456789[root@coolnull ~]# lsof -p 16528 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME bonnie++ 16528 root cwd DIR 252,0 4096 130597 /tmp &lt;truncated&gt; bonnie++ 16528 root 8u REG 252,0 501219328 131869 /tmp/Bonnie.16528 bonnie++ 16528 root 9u REG 252,0 501219328 131869 /tmp/Bonnie.16528 bonnie++ 16528 root 10u REG 252,0 501219328 131869 /tmp/Bonnie.16528 bonnie++ 16528 root 11u REG 252,0 501219328 131869 /tmp/Bonnie.16528 bonnie++ 16528 root 12u REG 252,0 501219328 131869 &lt;strong&gt;/tmp/Bonnie.16528 为了更进一步确认是这些文件被繁重地写入，我们可以看下/tmp文件系统是不是sda盘的一部份。123[root@coolnull ~]# df /tmpFilesystem 1K-blocks Used Available Use% Mounted on/dev/mapper/workstation-root 7667140 2628608 4653920 37% / 从df的输出我们可以判断出/tmp是根目录下的一部份。1234567891011[root@coolnull ~]# pvdisplay --- Physical volume --- PV Name /dev/sda5 VG Name workstation PV Size 7.76 GiB / not usable 2.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 1986 Free PE 8 Allocated PE 1978 PV UUID CLbABb-GcLB-l5z3-TCj3-IOK3-SQ2p-RDPW5S 使用pvdisplay我们可以看到硬盘sda的/dev/sda5分区就是workstation volume group在使用的分区也即是/tmp目录。通过给出的信息就可以更安全地说上述losf命令列出来的大量文件很有可能就是正在被频繁读写的文件。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Controller manager 的高可用实现方式]]></title>
    <url>%2F2019%2F01%2F17%2Fblog%2FController%20manager%20%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[描述这不是一系列入门级别的文章，也不是按部就班而来的，而是我看到哪里，发现有些代码写的精妙的地方，都值得我们学习下，顺手记录下来，一方面是让自己将来可以有迹可循，另外对大家应该也会有所帮助。而且记录本身成本并不是很高。 高可用部署情况下，需要部署多个controller manager （以下简称 cm ），每个 cm 需要 –leader-elect=true 启动参数，即告知 cm 以高可用方式启动，谁要想进行真正的工作，必须先抢到锁，被选举为 leader 才行，而抢不到所得只能待机，在 leader 因为异常终止的时候，由剩余的其余节点再次获得锁。 关于分布式锁的实现很多，可以自己从零开始制造。当然更简单的是基于现有中间件，比如有基于 Redis 或数据库的实现方式，最近 Zookeeper/ETCD 也提供了相关功能。但 K8s 的实现并没有使用这些方式，而是另辟蹊径使用了资源锁的概念，简单来说就是通过创建 K8s 的资源（当前的实现中实现了 ConfigMap 和 Endpoint 两种类型的资源）来维护锁的状态。 分布式锁一般实现原理就是大家先去抢锁，抢到的人成为 leader ，然后 leader 会定期更新锁的状态，声明自己的活动状态，不让其他人把锁抢走。K8s 的资源锁也类似，抢到锁的节点会将自己的标记（目前是hostname）设为锁的持有者，其他人则需要通过对比锁的更新时间和持有者来判断自己是否能成为新的 leader ，而 leader 则可以通过更新 RenewTime 来确保持续保有该锁。 大概看了下 K8s 的实现，老实说其实现方式并不算高雅，但是却给我们开拓了一种思路：K8s 里的 resource 是万能的，不要以为 Endpoint 只是 Endpoint 。不过反过来有时候也挺让人费解的，刚了解的时候容易摸不着头脑，也不是好事。而且 scheduler 和 cm 都采用了资源锁，但是实现起来却不尽相同，也值得吐槽下。不管怎么说，这个实现算是挺有意思的实现，值得我们深入了解下。 我们首先来看一下 cm 启动的时候，是如何去 初始化 抢锁的。启动的时候，如果指定了 –leader-elect=true 参数的话，则会进入下面的代码，首先获取自己的资源标志（这里是 hostname 加一串随机数字）。 12345678910111213id, err := os.Hostname()// add a uniquifier so that two processes on the same host don't accidentally both become activeid = id + "_" + string(uuid.NewUUID())rl, err := resourcelock.New(c.Generic.ComponentConfig.GenericComponent.LeaderElection.ResourceLock, "kube-system", // 该资源所在 Namespace "kube-controller-manager", // 资源名称 c.Generic.LeaderElectionClient.CoreV1(), resourcelock.ResourceLockConfig&#123; Identity: id, // 锁持有者标志 EventRecorder: c.Generic.EventRecorder, &#125;)&#125; 上面创建资源锁的代码说明请参考文中中文注释。 之后，在下面的代码中，资源锁，即上面的 rl（resource lock） 变量，被用于进行 leader 选举。具体的说明也嵌入在了下面的代码中。12345678910111213leaderelection.RunOrDie(leaderelection.LeaderElectionConfig&#123; Lock: rl, // 下面 3 个参数是一些重时间，租赁期间等的设置，不是很重要 LeaseDuration: c.Generic.ComponentConfig.GenericComponent.LeaderElection.LeaseDuration.Duration, RenewDeadline: c.Generic.ComponentConfig.GenericComponent.LeaderElection.RenewDeadline.Duration, RetryPeriod: c.Generic.ComponentConfig.GenericComponent.LeaderElection.RetryPeriod.Duration, Callbacks: leaderelection.LeaderCallbacks&#123; OnStartedLeading: run, // cm 的主要工作函数 OnStoppedLeading: func() &#123; glog.Fatalf("leaderelection lost") &#125;, &#125;,&#125;) 我们再来看看 LeaderElectionConfig 的内容，说明见注释（其实就是将代码的英文翻译过来而已） 12345678910111213141516type LeaderElectionConfig struct &#123; // 资源锁的实现对象 Lock rl.Interface // 是非 leader 在获取锁之前需要检查 leader 过期的时间 LeaseDuration time.Duration // 当前 leader 尝试更新锁状态的期限。 RenewDeadline time.Duration // 抢锁时尝试间隔 RetryPeriod time.Duration // 锁状态发生变化的时候，需要进行处理的一组回调函数 Callbacks LeaderCallbacks&#125; 这里的 Callbacks 具体如下：123456Callbacks: leaderelection.LeaderCallbacks&#123; OnStartedLeading: run, OnStoppedLeading: func() &#123; glog.Fatalf("leaderelection lost") &#125;,&#125;, 也就是说，在获取锁（成为leader，OnStartedLeading）之后，将会执行 run 方法，在失去锁（OnStoppedLeading）之后打印错误消息后退出。run 方法是 cm 的主要方法，和抢锁选主流程没什么关系，这里就不介绍了。 下面的 LeaderElectionRecord 结构，保存了锁的信息，包括持有者（的hostname），获取时间，更新时间，leader 切换次数等（LeaseDurationSeconds 虽然定义了，但是并没有使用的感觉）。 这个结构可以说是资源锁中最重要的信息了，大家一定先混个脸熟，多念几遍 struct 的名字。12345678910// LeaderElectionRecord is the record that is stored in the leader election annotation.// This information should be used for observational purposes only and could be replaced// with a random string (e.g. UUID) with only slight modification of this code.type LeaderElectionRecord struct &#123; HolderIdentity string `json:"holderIdentity"` LeaseDurationSeconds int `json:"leaseDurationSeconds"` AcquireTime metav1.Time `json:"acquireTime"` RenewTime metav1.Time `json:"renewTime"` LeaderTransitions int `json:"leaderTransitions"`&#125; 这个锁信息，就是存在 K8s 的 ConfigMap 或者 Endpoint 里面的，当然，存哪里可能大家已经想到了，只能存 annotation 里面，该 annotation 的 key 就是 control-plane.alpha.kubernetes.io/leader 。 到这里总结一下就是：LeaderElectionRecord 用于保存锁的信息，但是这一信息会以 annotation 的方式，保存到 k8s 的 ConfigMap 或者 Endpoint 等资源里面。 下面我们来看一下资源锁的实现。 资源锁接口 的定义如下：12345678type Interface interface &#123; Get() (*LeaderElectionRecord, error) Create(ler LeaderElectionRecord) error Update(ler LeaderElectionRecord) error RecordEvent(string) Identity() string Describe() string&#125; 基本实现了 CRUD 几个方法，当然这里没有 D ，即 Delete，因为也没必要 Delete， 下一次抢锁的时候，抢到的 Leader 直接 Update 就可以了。 关键的方法我们看前 3 个就够了： Get 用于获取锁的最新信息，Update 用于更新，Create 用于创建资源锁对象，估计对大多数集群来说，只有第一次的时候才会调用 Create 创建这个对象。RecordEvent 也可以关注下，这个 event 属于锁资源，里面会记录 leader 切换等事件。 这里我们以 Endpoint 为例（这也是默认的资源锁类型，该参数可以通过 leader-elect-resource-lock 来设置），来看看资源锁的具体实现。 下面的代码省略了对 error 的检查，你懂得。123456789101112131415// Get returns the election record from a Endpoints Annotationfunc (el *EndpointsLock) Get() (*LeaderElectionRecord, error) &#123; var record LeaderElectionRecord var err error // el.e 就是一个正经的 Endpoint 资源对象。 el.e, err = el.Client.Endpoints(el.EndpointsMeta.Namespace).Get(el.EndpointsMeta.Name, metav1.GetOptions&#123;&#125;) // 去获取 control-plane.alpha.kubernetes.io/leader annotation。 if recordBytes, found := el.e.Annotations[LeaderElectionRecordAnnotationKey]; found &#123; if err := json.Unmarshal([]byte(recordBytes), &amp;record); err != nil &#123; return nil, err &#125; &#125; return &amp;record, nil&#125; Create 也很简单，就是一个普通的 Endpoint 对象，加上锁专用的 annotation ：123456789el.e, err = el.Client.Endpoints(el.EndpointsMeta.Namespace).Create(&amp;v1.Endpoints&#123; ObjectMeta: metav1.ObjectMeta&#123; Name: el.EndpointsMeta.Name, Namespace: el.EndpointsMeta.Namespace, Annotations: map[string]string&#123; LeaderElectionRecordAnnotationKey: string(recordBytes), &#125;, &#125;,&#125;) 更新方法 的主体如下，将 LeaderElectionRecord 结构的对象序列化为字符串后，存到 annotation：12el.e.Annotations[LeaderElectionRecordAnnotationKey] = string(recordBytes)el.e, err = el.Client.Endpoints(el.EndpointsMeta.Namespace).Update(el.e) 通过上面的方法，我们应该已经了解到了，锁的实现主要载体是 LeaderElectionRecord 对象，其实我们完全可以自己实现其他类型的资源锁了，比如基于 Secret ，不过好像也没啥意义。 介绍了上面的实现基础，我们最后来看看抢锁及使用锁的过程，主要的入口 如下：1234567891011// Run starts the leader election loopfunc (le *LeaderElector) Run() &#123; // 先去抢锁，阻塞操作 le.acquire() stop := make(chan struct&#123;&#125;) // 抢到锁后，执行主函数，就是我们前面提到的 run 函数，通过 Callbacks.OnStartedLeading 回调启动 go le.config.Callbacks.OnStartedLeading(stop) // 抢到锁后，需要定期更新，确保自己一直持有该锁 le.renew() close(stop)&#125; 可以看到，里面主要调用了两个方法： acquire 和 renew 。 我们先来看看 acquire 方法：1234567891011121314func (le *LeaderElector) acquire() &#123; stop := make(chan struct&#123;&#125;) wait.JitterUntil(func() &#123; succeeded := le.tryAcquireOrRenew() le.maybeReportTransition() if !succeeded &#123; glog.V(4).Infof("failed to acquire lease %v", desc) return &#125; le.config.Lock.RecordEvent("became leader") glog.Infof("successfully acquired lease %v", desc) close(stop) &#125;, le.config.RetryPeriod, JitterFactor, true, stop)&#125; 实现也很短，这个函数会通过 wait.JitterUntil 来定期调用 tryAcquireOrRenew 方法 来获取锁，直到成功为止，如果获取不到锁，则会以 RetryPeriod 为间隔不断尝试。如果获取到锁，就会关闭 stop 通道（ close(stop) ），通知 wait.JitterUntil 停止尝试。tryAcquireOrRenew 是最核心的方法，我们会在介绍完 renew 方法之后再进行介绍。 renew 只有在获取锁之后才会调用，它会通过持续更新资源锁的数据，来确保继续持有已获得的锁，保持自己的 leader 状态。这里还是用到了很多 wait 包里的方法。1234567891011121314151617func (le *LeaderElector) renew() &#123; stop := make(chan struct&#123;&#125;) wait.Until(func() &#123; err := wait.Poll(le.config.RetryPeriod, le.config.RenewDeadline, func() (bool, error) &#123; return le.tryAcquireOrRenew(), nil &#125;) le.maybeReportTransition() desc := le.config.Lock.Describe() if err == nil &#123; glog.V(4).Infof("successfully renewed lease %v", desc) return &#125; le.config.Lock.RecordEvent("stopped leading") glog.Infof("failed to renew lease %v: %v", desc, err) close(stop) &#125;, 0, stop)&#125; 这里的精妙之处在于，wait.Until 会不断的调用 wait.Poll 方法，前者是进行无限循环操作，直到 stop chan 被关闭，wait.Poll则不断的对某一条件进行检查，以 RetryPeriod 为间隔，直到该条件返回true、error或者超时（上面的 RenewDeadline 参数）。这一条件是一个需要满足 func() (bool, error) 签名的方法，比如这个例子很简单，只是调用了 le.tryAcquireOrRenew()。 tryAcquireOrRenew 方法本身不是一个阻塞操作，只返回 true/false，对应为获取到锁和没有获取到锁的状态。结合 wait.Poll 来使用，该函数返回会有以下几种情况： tryAcquireOrRenew 获取到锁，返回 truetryAcquireOrRenew 没有获取到锁，返回 falsetryAcquireOrRenew 超时，返回 ErrWaitTimeout（errors.New(“timed out waiting for the condition”)） 最后，我们再来重点了解下 tryAcquireOrRenew 的内容。renew有两个功能，获取锁，或者在已经获取锁的时候，对锁进行更新，确保锁不被他人抢走。 具体的说明也放到了注释里，这段代码流程上不不复杂，但是需要对前后两个状态，以及 leader 和非 leader 两个角色的不同执行流程有所分辨。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func (le *LeaderElector) tryAcquireOrRenew() bool &#123; now := metav1.Now() // 这个 leaderElectionRecord 就是保存在 Endpoint 的 annotation 中的值。 // 每个节点都将 HolderIdentity 设置为自己，以及关于获取和更新锁的时间。后面会对时间进行修正，才会更新到 API server leaderElectionRecord := rl.LeaderElectionRecord&#123; HolderIdentity: le.config.Lock.Identity(), LeaseDurationSeconds: int(le.config.LeaseDuration / time.Second), RenewTime: now, AcquireTime: now, &#125; // 1. 获取或者创建 ElectionRecord oldLeaderElectionRecord, err := le.config.Lock.Get() // 获取记录出错，有可能是记录不存在，这种错误需要处理。 if err != nil &#123; if !errors.IsNotFound(err) &#123; glog.Errorf("error retrieving resource lock %v: %v", le.config.Lock.Describe(), err) return false &#125; // 记录不存在的话，则创建一条新的记录 if err = le.config.Lock.Create(leaderElectionRecord); err != nil &#123; glog.Errorf("error initially creating leader election record: %v", err) return false &#125; // 创建记录成功，同时表示获得了锁，返回true le.observedRecord = leaderElectionRecord le.observedTime = time.Now() return true &#125; // 2. 正常获取了锁资源的记录，检查锁持有者和更新时间。 if !reflect.DeepEqual(le.observedRecord, *oldLeaderElectionRecord) &#123; // 记录之前的锁持有者，其实有可能就是自己。 le.observedRecord = *oldLeaderElectionRecord le.observedTime = time.Now() &#125; // 在满足以下所有的条件下，认为锁由他人持有，并且还没有过期，返回 false // a. 当前锁持有者的并非自己 // b. 上一次观察时间 + 观测检查间隔大于现在时间，即距离上次观测的间隔，小于 `LeaseDuration` 的设置值。 if le.observedTime.Add(le.config.LeaseDuration).After(now.Time) &amp;&amp; oldLeaderElectionRecord.HolderIdentity != le.config.Lock.Identity() &#123; glog.V(4).Infof("lock is held by %v and has not yet expired", oldLeaderElectionRecord.HolderIdentity) return false &#125; // 3. 更新资源的 annotation 内容。 // 在本函数开头 leaderElectionRecord 有一些字段被设置成了默认值，这里来设置正确的值。 if oldLeaderElectionRecord.HolderIdentity == le.config.Lock.Identity() &#123; // 如果自己持有锁，则继承之前的获取时间和 leader 切换次数 leaderElectionRecord.AcquireTime = oldLeaderElectionRecord.AcquireTime leaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions &#125; else &#123; // 发生 leader 切换，所以 LeaderTransitions + 1 leaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions + 1 &#125; // 更新锁资源对象 if err = le.config.Lock.Update(leaderElectionRecord); err != nil &#123; glog.Errorf("Failed to update lock: %v", err) return false &#125; le.observedRecord = leaderElectionRecord le.observedTime = time.Now() return true&#125; 再回到 renew 方法，在被 Poll 阻塞住之后，只要 Poll 返回了，就可以继续执行下面的代码。le.maybeReportTransition() 很关键，里面会判断是否出现了 leader 的切换，进而调用 Callbacks 的 OnNewLeader 方法，尽管 cm 初始化的时候并没有设置这个 Callback 方法。123456789func (l *LeaderElector) maybeReportTransition() &#123; if l.observedRecord.HolderIdentity == l.reportedLeader &#123; return &#125; l.reportedLeader = l.observedRecord.HolderIdentity if l.config.Callbacks.OnNewLeader != nil &#123; go l.config.Callbacks.OnNewLeader(l.reportedLeader) &#125;&#125; 代码看起来比较烧脑，本文读起来也比较摸不着头，可能最好的办法就是一遍遍的阅读源代码了。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Kubernetes</tag>
        <tag>yml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes master服务高可用方案]]></title>
    <url>%2F2019%2F01%2F17%2Fblog%2FKubernetes%20master%E6%9C%8D%E5%8A%A1%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[描述Kubernetes的管理层服务包括kube-scheduler和kube-controller-manager。kube-scheduer和kube-controller-manager使用一主多从的高可用方案，在同一时刻只允许一个服务处以具体的任务。Kubernetes中实现了一套简单的选主逻辑，依赖Etcd实现scheduler和controller-manager的选主功能。 Kubernetes master服务高可用方案如果scheduler和controller-manager在启动的时候设置了leader-elect参数，它们在启动后会先尝试获取leader节点身份，只有在获取leader节点身份后才可以执行具体的业务逻辑。它们分别会在Etcd中创建kube-scheduler和kube-controller-manager的endpoint，endpoint的信息中记录了当前的leader节点信息，以及记录的上次更新时间。leader节点会定期更新endpoint的信息，维护自己的leader身份。每个从节点的服务都会定期检查endpoint的信息，如果endpoint的信息在时间范围内没有更新，它们会尝试更新自己为leader节点。scheduler服务以及controller-manager服务之间不会进行通信，利用Etcd的强一致性，能够保证在分布式高并发情况下leader节点的全局唯一性。 整体方案如下图所示： 当集群中的leader节点服务异常后，其它节点的服务会尝试更新自身为leader节点，当有多个节点同时更新endpoint时，由Etcd保证只有一个服务的更新请求能够成功。通过这种机制sheduler和controller-manager可以保证在leader节点宕机后其它的节点可以顺利选主，保证服务故障后快速恢复。当集群中的网络出现故障时对服务的选主影响不是很大，因为scheduler和controller-manager是依赖Etcd进行选主的，在网络故障后，可以和Etcd通信的主机依然可以按照之前的逻辑进行选主，就算集群被切分，Etcd也可以保证同一时刻只有一个节点的服务处于leader状态。 查看集群中leader12345678910111213kubectl get ep kube-scheduler -n kube-system -o yaml apiVersion: v1kind: Endpointsmetadata: annotations: control-plane.alpha.kubernetes.io/leader: '&#123;"holderIdentity":"ha-svr-vm-2","leaseDurationSeconds":15,"acquireTime":"2018-11-22T01:06:12Z","renewTime":"2019-01-17T11:25:00Z","leaderTransitions":370&#125;' creationTimestamp: 2018-06-30T14:52:25Z name: kube-scheduler namespace: kube-system resourceVersion: "83825210" selfLink: /api/v1/namespaces/kube-system/endpoints/kube-scheduler uid: 33ef97df-7c75-11e8-9ab0-fa163ef4249asubsets: null Kubernetes apiserver服务高可用方案Kubernetes的接入层服务主要是kube-apiserver。apiserver本身是无状态的服务，它的主要任务职责是把资源数据存储到Etcd中，后续具体的业务逻辑是由scheduler和controller-manager执行的。 可以同时起多个apiserver服务，使用nginx把客户端的流量转发到不同的后端apiserver上实现接入层的高可用。具体的实现如下图所示： 接入层的高可用分为两个部分，一个部分是多活的apiserver服务，另一个部分是一主一备的nginx服务。 总结本文主要从存储层，管理层和接入层三个部分介绍了Kubernetes高可用方案的原理，整体的方案架构如下图所示：]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Kubernetes</tag>
        <tag>yml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes之路-Java应用资源限制的迷思]]></title>
    <url>%2F2019%2F01%2F10%2Fblog%2FKubernetes%E4%B9%8B%E8%B7%AF-Java%E5%BA%94%E7%94%A8%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%E7%9A%84%E8%BF%B7%E6%80%9D%2F</url>
    <content type="text"><![CDATA[描述随着容器技术的成熟，越来越多的企业客户在企业中选择Docker和Kubernetes作为应用平台的基础。然而在实践过程中，还会遇到很多具体问题。本系列文章会记录阿里云容器服务团队在支持客户中的一些心得体会和最佳实践。我们也欢迎您通过邮件和钉钉群和我们联系，分享您的思路和遇到的问题。 问题有些同学反映：自己设置了容器的资源限制，但是Java应用容器在运行中还是会莫名奇妙地被OOM Killer干掉。 这背后一个非常常见的原因是：没有正确设置容器的资源限制以及对应的JVM的堆空间大小。 我们拿一个tomcat应用为例，其实例代码和Kubernetes部署文件可以从Github中获得。 下面是一个Kubernetes的Pod的定义描述： 1、Pod中的app是一个初始化容器，负责把一个JSP应用拷贝到 tomcat 容器的 “webapps”目录下。注： 镜像中JSP应用index.jsp用于显示JVM和系统资源信息。2、tomcat 容器会保持运行，而且我们限制了容器最大的内存用量为256MB内存。 我们执行如下命令来部署、测试应用 我们可以看到HTML格式的系统CPU/Memory等信息，我们也可以用 html2text 命令将其转化成为文本格式。 注意：本文是在一个 2C 4G的节点上进行的测试，在不同环境中测试输出的结果会有所不同 我们可以发现，容器中看到的系统内存是 3951MB，而JVM Heap Size最大是 878MB。纳尼？！我们不是设置容器资源的容量为256MB了吗？如果这样，当应用内存的用量超出了256MB，JVM还没对其进行GC，而JVM进程就会被系统直接OOM干掉了。 问题的根源在于：对于JVM而言，如果没有设置Heap Size，就会按照宿主机环境的内存大小缺省设置自己的最大堆大小。Docker容器利用CGroup对进程使用的资源进行限制，而在容器中的JVM依然会利用宿主机环境的内存大小和CPU核数进行缺省设置，这导致了JVM Heap的错误计算。类似，JVM缺省的GC、JIT编译线程数量取决于宿主机CPU核数。如果我们在一个节点上运行多个Java应用，即使我们设置了CPU的限制，应用之间依然有可能因为GC线程抢占切换，导致应用性能收到影响。 了解了问题的根源，我们就可以非常简单地解决问题了 解决思路开启CGroup资源感知Java社区也关注到这个问题，并在JavaSE8u131+和JDK9 支持了对容器资源限制的自动感知能力 https://blogs.oracle.com/java-platform-group/java-se-support-for-docker-cpu-and-memory-limits 其用法就是添加如下参数 我们在上文示例的tomcat容器添加环境变量 “JAVA_OPTS”参数 我们部署一个新的Pod，并重复相应的测试 我们看到JVM最大的Heap大小变成了112MB，这很不错，这样就能保证我们的应用不会轻易被OOM了。随后问题又来了，为什么我们设置了容器最大内存限制是256MB，而JVM只给Heap设置了112MB的最大值呢？ 这就涉及到JVM的内存管理的细节了，JVM中的内存消耗包含Heap和Non-Heap两类；类似Class的元信息，JIT编译过的代码，线程堆栈(thread stack)，GC需要的内存空间等都属于Non-Heap内存，所以JVM还会根据CGroup的资源限制预留出部分内存给Non Heap，来保障系统的稳定。（在上面的示例中我们可以看到，tomcat启动后Non Heap占用了近32MB的内存） 在最新的JDK 10中，又对JVM在容器中运行做了进一步的优化和增强。 容器内部感知CGroup资源限制如果无法利用JDK 8/9的新特性，比如还在使用JDK6的老应用，我们还可以在容器内部利用脚本来获取容器的CGroup资源限制，并通过设置JVM的Heap大小。 Docker1.7开始将容器cgroup信息挂载到容器中，所以应用可以从 /sys/fs/cgroup/memory/memory.limit_in_bytes 等文件获取内存、 CPU等设置，在容器的应用启动命令中根据Cgroup配置正确的资源设置 -Xmx, -XX:ParallelGCThreads等参数 在 https://yq.aliyun.com/articles/18037?spm=a2c41.11181499.0.0 一文中已经有相应的示例和代码，本文不再赘述 总结本文分析了Java应用在容器使用中一个常见Heap设置的问题。容器与虚拟机不同，其资源限制通过CGroup来实现。而容器内部进程如果不感知CGroup的限制，就进行内存、CPU分配可能导致资源冲突和问题。 我们可以非常简单地利用JVM的新特性和自定义脚本来正确设置资源限制。这个可以解决绝大多数资源限制的问题。 关于容器应用中资源限制还有一类问题是，一些比较老的监控工具或者free/top等系统命令，在容器中运行时依然会获取到宿主机的CPU和内存，这导致了一些监控工具在容器中运行时无法正常计算资源消耗。社区中常见的做法是利用 lxcfs 来让容器在资源可见性的行为和虚机保持一致，后续文章会介绍其在Kubernetes上的使用方案。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Kubernetes</tag>
        <tag>yml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全盘掌控堆空间的大小]]></title>
    <url>%2F2019%2F01%2F09%2Fblog%2F%E5%85%A8%E7%9B%98%E6%8E%8C%E6%8E%A7%E5%A0%86%E7%A9%BA%E9%97%B4%E7%9A%84%E5%A4%A7%E5%B0%8F%2F</url>
    <content type="text"><![CDATA[描述 操作系统及JVM类型 Xms Xmx Linux 32位 Client 16MB 256MB Linux 32位 Server 64MB 取1GB和物理内存大小1/4二者中的最小值 Linux 64位 Server 取512MB和物理内存大小1/64二者中的最小值 取32GB和物理内存大小1/4二者中的最小值 MacOS 64位 Server 64MB 取1GB和物理内存大小1/4二者中的最小值 Window 32位 Client 16MB 256MB Window 64位 Server 64MB 取1GB和物理内存大小1/4二者中的最小值 堆的默认大小依据机器的内存配置确定，不过也可以通过参数-XX:MaxRAM=N与-XX:MaxRAMFraction=N设置。通常情况下，这个值是由JVM检测机器的物理内存计算得出。 MaxRam的最大值 操作系统及JVM类型 MaxRam 32 位 client 1 GB 32 位 server 4 GB 64 位 server 128 GB 默认最大堆的计算实际采用下面的公式：1Default Xmx = MaxRAM / MaxRAMFraction 而MaxRAMFraction的默认值为4，即堆的最大容量是MaxRAM值的四分之一。 JVM还提供了另一个参数调整最大堆的默认值，这个参数是-XX:ErgoHeapSizeLimit=N。该参数默认值为0（表示忽略该标志），如果设置的限制值比MaxRAM/MaxRAMFraction还小，就使用该参数指定的值。 另一方面，如果机器配置的物理内存非常少，JVM还要确保预留足够的内存给操作系统使用。这个值的计算是基于-XX:MinRAMFraction=N参数，默认值为2。123if ((96 MB * MinRAMFraction) &gt; Physical Memory) &#123; Default Xmx = Physical Memory / MinRAMFraction;&#125; 这就是为什么堆的默认大小在不同的机器上会有不同的原因：如果机器的物理内存比MaxRAM的值小，默认堆的大小就是物理内存的1/4。即使机器配置了数百GB的内存，JVM能使用的最大堆容量也不会超过默认值32GB，即128GB的1/4。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[harbor搭建使用]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fharbor%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[描述Docker容器应用的开发和运行离不开可靠的镜像管理，虽然Docker官方也提供了公共的镜像仓库，但是从安全和效率等方面考虑，部署我们私有环境内的Registry也是非常必要的。Harbor是由VMware公司开源的企业级的Docker Registry管理项目，它包括权限管理(RBAC)、LDAP、日志审核、管理界面、自我注册、镜像复制和中文支持等功能。 环境、软件准备123Docker：version 17.06.0-ceDocker-compose： version 1.18.0Harbor： version 1.4.0 docker 安装请参考我之前写的文章http://mooon.top/2018/03/01/blog/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85docker/ docker-compose安装12345671、下载指定版本的docker-compose$ curl -L https://github.com/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose2、对二进制文件赋可执行权限$ sudo chmod +x /usr/local/bin/docker-compose3、测试下docker-compose是否安装成功$ docker-compose --versiondocker-compose version 1.18.0, build 1719ceb Harbor 服务搭建1、下载Harbor安装文件1234561、在线安装包 $ wget https://github.com/vmware/harbor/releases/download/v1.4.0/harbor-online-installer-v1.4.0.tgz $ tar xvf harbor-online-installer-v1.4.0.tgz2、离线安装包 $ wget https://github.com/vmware/harbor/releases/download/v1.4.0/harbor-offline-installer-v1.4.0.tgz $ tar xvf harbor-offline-installer-v1.4.0.tgz 说明：本文采用离线安装包 2.配置Harbor解压缩之后，目录下会生成harbor.conf文件，该文件就是Harbor的配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253## Configuration file of Harbor# hostname设置访问地址，可以使用ip、域名，不可以设置为127.0.0.1或localhosthostname = 10.236.63.76# 访问协议，默认是http，也可以设置https，如果设置https，则nginx ssl需要设置onui_url_protocol = http# mysql数据库root用户默认密码root123，实际使用时修改下db_password = root123max_job_workers = 3 customize_crt = onssl_cert = /data/cert/server.crtssl_cert_key = /data/cert/server.keysecretkey_path = /dataadmiral_url = NA# 邮件设置，发送重置密码邮件时使用email_identity = email_server = smtp.mydomain.comemail_server_port = 25email_username = sample_admin@mydomain.comemail_password = abcemail_from = admin &lt;sample_admin@mydomain.com&gt;email_ssl = false# 启动Harbor后，管理员UI登录的密码，默认是Harbor12345harbor_admin_password = Harbor12345# 认证方式，这里支持多种认证方式，如LADP、本次存储、数据库认证。默认是db_auth，mysql数据库认证auth_mode = db_auth# LDAP认证时配置项#ldap_url = ldaps://ldap.mydomain.com#ldap_searchdn = uid=searchuser,ou=people,dc=mydomain,dc=com#ldap_search_pwd = password#ldap_basedn = ou=people,dc=mydomain,dc=com#ldap_filter = (objectClass=person)#ldap_uid = uid #ldap_scope = 3 #ldap_timeout = 5# 是否开启自注册self_registration = on# Token有效时间，默认30分钟token_expiration = 30# 用户创建项目权限控制，默认是everyone（所有人），也可以设置为adminonly（只能管理员）project_creation_restriction = everyoneverify_remote_cert = on 说明：这是主要是修改hostname选项，特别说明，如果要改HARBOR默认的80端口。这个hostname也要改为ip:port 修改完之后在当前目录执行12345./prepare./install安装完之后执行：docker images查看镜像docker-compose ps 查看服务 3、访问harbor控制台即可http://ip:port 4、修改端口harbor 默认的是80端口，现在改为5500只需要修改docker-compose.yml和harbor.cfg 的hostname=ip:port12345678910111213141516image: vmware/nginx-photon:v1.4.0container_name: nginxrestart: alwaysvolumes:- ./common/config/nginx:/etc/nginx:znetworks:- harborports:- 5500:80- 443:443- 4443:4443depends_on:- mysql- registry- ui- log 5、启动1234$ sudo docker-compose down -v$ vim harbor.cfg$ sudo prepare$ sudo docker-compose up -d 所有配置请参考：https://github.com/vmware/harbor/blob/v1.4.0/docs/installation_guide.md]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在Kubernetes集群中使用Sysctls]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E5%A6%82%E4%BD%95%E5%9C%A8Kubernetes%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%BD%BF%E7%94%A8Sysctls%2F</url>
    <content type="text"><![CDATA[描述在Linux中，Sysctl接口允许管理员在内核运行时修改内核参数。这些可用参数都存在于虚拟进程文件系统中的/proc/sys/目录。这些内核参数作用于各种子系统中，例如： 内核 (通用前缀：kernel.)网络 (通用前缀：net.)虚拟内存 (通用前缀：vm.)设备专用 (通用前缀：dev.) 命名空间级vs.节点级Sysctls在今天的Linux内核系统中有一些Sysctls是 命名空间级 的。这意味着他们在同节点的不同pod间是可配置成独立的。在kubernetes里，命名空间级是Sysctls的一个必要条件，以使其在一个pod语境里易于理解。 以下列出了Sysctls中已知的 命名空间级 ： kernel.shm*（内核中共享内存相关参数）， kernel.msg*（内核中SystemV消息队列相关参数）， kernel.sem（内核中信号量参数）， fs.mqueue.*（内核中POSIX消息队列相关参数）， net.*（内核中网络配置项相关参数）。 Sysctls中非命名空间级的被称为 节点级 ，其必须由集群管理员手动设置，要么通过节点的底层Linux分布方式(例如，通过 /etc/sysctls.conf)，亦或在特权容器中使用Daemonset。 注意: 这是很好的做法，考虑在一个集群里给有特殊sysctl的节点设置为 污点 ，并且给他们安排仅需要这些sysctl设置的pods。 安全的 vs. 不安全的 SysctlsSysctls被分为 安全的 和 不安全的 sysctls。同一节点上的pods间除了适当命名空间命名一个 安全的 sysctl，还必须适当的 隔离 。 这意味着给一个pod设置一个 安全的 sysctl 不能对相同节点上其他pod产生任何影响 不能对节点的健康造成损害 不能在pod资源限制以外获取更多的CPU和内存资源 目前看来，大多数的 命名空间级 sysctls 不一定被认为是 安全的 。 在Kubernetes 1.4版本中，以下sysctls提供了 安全的 配置： kernel.shm_rmid_forced, net.ipv4.ip_local_port_range, net.ipv4.tcp_syncookies. 该列表在未来的Kubernetes版本里还会继续扩充，当kubelet提供更好的隔离机制时。 所有 安全的 sysctls 都是默认启用的。 所有 不安全的 sysctls 默认是关闭的，且必须通过每个节点基础上的集群管理手动开启。禁用不安全的sysctls的Pods将会被计划，但不会启动。 警告: 由于他们的本质是 不安全的 ，使用 不安全的 sysctls是自担风险的，并且会导致严重的问题，例如容器的错误行为，资源短缺或者是一个节点的完全破损。 开启不安全的Sysctls牢记上面的警告， 在非常特殊的情况下，例如高性能指标或是实时应用程序优化，集群管理员可以允许 不安全的 sysctls。 不安全的 sysctls 会打上kubelet标识，在逐节点的基础上被启用，例如： $ kubelet --experimental-allowed-unsafe-sysctls &apos;kernel.msg*,net.ipv4.route.min_pmtu&apos; 只有 命名空间级 sysctls 可以使用该方法启用。 注意：每个NODE都要启动 在deployment中设置使用在Kubernetes 1.4版本中，sysctl特性是一个alpha API。因此，sysctls被设置为在pods上使用注释。它们适用于同一个pod上的所有容器。 这里列举了一个例子， 安全的 和 不安全的 sysctls使用不同的注释: Kubectl edit deploy/tomcat 一定要记得是在template下的metadata增加：annotations: security.alpha.kubernetes.io/sysctls: kernel.shm_rmid_forced=1 注意: 1、安全和不安全在pod中设置了之后，都是以pod的为准，但不安全的可能会影响内核造成不预知的问题。 2、不安全的是可以允许在节点上进行手动修改的。 3、安全的只在容器级别。 4、不安全的会形象到内核，也可是会影响到主机。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>sysctl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins配置docker流水线]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fjenkins%E9%85%8D%E7%BD%AEdocker%E6%B5%81%E6%B0%B4%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[描述开发同学通过git push上传代码，经Git和Jenkins配合，自动完成程序部署、发布，全程无需运维人员参与。这是一种真正的容器级的实现，这个带来的好处，不仅仅是效率的提升，更是一种变革：开发人员第一次真正为自己的代码负责——终于可以跳过运维和测试部门，自主维护运行环境（首先是测试/开发环境）。 配置gitlab代码仓库配置gitlab仓库，把开发代码放到仓库中。具体搭建仓库自行解决常用命令如下：12345678910111213141516171819202122#设定本机用户名，绑定邮箱，让远程服务器知道机器的身份git config --global user.name "#######"git config --global user.email "XXXXX@XX.com"#如果你没有最新的代码，希望从头开始，下面展示在你希望pull过来的文件夹下Create a new repository//这里是项目的地址（可从项目主页复制），将远程服务器的内容完全复制过来git clone http://192.168.100.10/jenkins/test-docker.git //clone 之后进入该项目的文件夹cd test-docker //新建readme文件touch README.md //将新的文件添加到git的暂存区git add README.md // 将暂存区的文件提交到某一个版本保存下来，并加上注释git commit-m ‘Its note：add a readme file’ //将本地的更改提交到远程服务器git push -u origin master 配置jenkins1、配置好JDK2、配置好MAVEN3、配置好GIT 新建自由风格软件项目GIT仓库配置 构建配置 保存即可 其中还可以配置把打好的镜像文件推送到仓库中去，此处忽略 配置文件说明Dockerfile1234567FROM tomcat:6ADD target/Docker.war /usr/local/tomcat/webapps/Docker.warRUN unzip -q /usr/local/tomcat/webapps/Docker.war -d /usr/local/tomcat/webapps/DockerEXPOSE 8080CMD ["/usr/local/tomcat/bin/catalina.sh","run"] &amp;&amp; tail -f /usr/local/tomcat/logs/catalina.out check.sh123456docker ps -a |grep docker:v1 | awk '&#123;print $1&#125;' |xargs docker stopdocker ps -a |grep docker:v1 | awk '&#123;print $1&#125;' |xargs docker rm docker images |grep docker |xargs docker rmiecho '****************************'echo successecho '****************************' pom.xml123456789101112131415161718192021222324252627&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.zyzx&lt;/groupId&gt; &lt;artifactId&gt;Docker&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;Docker Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;Docker&lt;/finalName&gt; &lt;/build&gt;&lt;/project&gt;]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubeadm 踩坑记]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fkubeadm%20%E8%B8%A9%E5%9D%91%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[描述Kubeadm 是个让我爱恨交加的东西，一方面，我不认为一个生产集群应该使用这样一个第三方工具进行在线安装，尤其是在目前这种网络环境之下；而另外一方面，Kubeadm 这一工具是随 Kubernetes 同步更新的，其中包含了大量的集群配置方面的最佳实践，是追新的最佳参考，所以这个讨厌的东西的运行是必须需要得到保障的。kubeadm 的执行过程沉默到令人发指，因此下面分享几个使用过程中遇到的一些问题和解决的思路和方法，希望对同行们有所帮助。 写入 yum repo 并进行安装之后，利用 systemctl enable kubelet 启用 kubelet 服务之后，只要运行一下 systemctl daemon-reload即可，这一服务的启动需要 kubeadm 生成的证书和配置文件等的支持，因此无需进行启动。 kubeadm init过程首先会检查代理服务器，确定跟 kube-apiserver 的 https 连接方式，如果有代理设置，会提出警告。 接下来会对 sysctl 进行检查，我这里需要执行 sysctl net.bridge.bridge-nf-call-iptables=1，对这一参数进行调整，解决他的警告。 接下来进入最抓狂的一个等待时间，屏幕显示为[apiclient] Created API client, waiting for the control plane to become ready，这一过程中会遇到大多数的坑，我一般会另外启动一个连接或者 tmux 窗口，进行观察和除错： 这里已经做好运行 kubelet 服务的准备，因此这一时间内，我们可以利用systemctl statusl -l kubelet对服务的启动状况进行检查，目前比较容易遇到的是 kubectl 和 docker 两个服务的cgroup-driver不一致的问题，这里编辑文件/etc/systemd/system/kubelet.service.d/10-kubeadm.conf，修改这一参数值为跟 docker 一致的cgroupfs即可。这一步可以在 kubeadm init 之前执行完成kubelet 启动之后，会尝试运行系统组件的 Pod，这里我们可以通过观察docker images的镜像列表来观察是否能够顺利进行下载。 镜像下载完成之后就会开始运行各个系统组件，因此也是事故最为集中的阶段，我们可以使用docker ps、docker logs、docker inspect几个命令，逐个查看组件的运行情况，对失败组件的原因进行排除，之前提过的resolv.conf的故障就是在这一阶段发现并排除的。 大家可以比较参数名称的变化, 当我们启动时, 会出现错误. 他会检测系统网桥的配置, 这个时候我们需要进行简单的修改123456789# 创建文件vi /etc/sysctl.d/k8s.conf# 添加如下内容net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1# 使配置生效sysctl -p /etc/sysctl.d/k8s.conf 这个是K8S v1.6.x的一个变化, 文件驱动默认由systemd改成cgroupfs, 而我们安装的docker使用的文件驱动是systemd, 造成不一致, 导致镜像无法启动现在有两种方式, 一种是修改docker, 另一种是修改kubelet, 这里我建议大家选择第二种, 修改kubelet的文件驱动, 因为我试着修改docker, 发现镜像无法拉取, 导致初始化不能成功12# 查看docker的文件驱动docker info 修改kubelet的文件驱动123进入kubelet启动配置文件cd /etc/systemd/system/kubelet.service.d/vi 10-kubeadm.conf 修改docker的Cgroup Driver在第二种安装方式中，如果我们要修改docker的Cgroup Driver可以使用如下命令：123vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd –exec-opt native.cgroupdriver=systemd 修改默认docker仓库地址docker安装完毕后，默认是从https://registry-1.docker.io仓库地址下载镜像的。 由于众所周知的原因，从docker hub下载镜像比较慢的。我们可以使用国内网易的docker仓库。 修改/usr/lib/systemd/system/docker.service文件，如下：123vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd –registry-mirror=http://hub.c.163.com -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock 重启docker服务，如下：12345systemctl daemon-reloadsystemctl restart dockersystemctl status docker 卸载DOCKER12yum history list dockeryum history undo 2 镜像拉取策略ImagePullPolicy支持三种ImagePullPolicy Always：不管镜像是否存在都会进行一次拉取。 Never：不管镜像是否存在都不会进行拉取 IfNotPresent：只有镜像不存在时，才会进行镜像拉取。 注意： 默认为IfNotPresent，但:latest标签的镜像默认为Always。 拉取镜像时docker会进行校验，如果镜像中的MD5码没有变，则不会拉取镜像数据。 生产环境中应该尽量避免使用:latest标签，而开发环境中可以借助:latest标签自动拉取最新的镜像。 资源限制Kubernetes通过cgroups限制容器的CPU和内存等计算资源，包括requests（请求，调度器保证调度到资源充足的Node上）和limits（上限）等：12345spec.containers[].resources.limits.cpu：CPU上限，可以短暂超过，容器也不会被停止spec.containers[].resources.limits.memory：内存上限，不可以超过；如果超过，容器可能会被停止或调度到其他资源充足的机器上spec.containers[].resources.requests.cpu：CPU请求，可以超过spec.containers[].resources.requests.memory：内存请求，可以超过；但如果超过，容器可能会在Node内存不足时清理 比如nginx容器请求30%的CPU和56MB的内存，但限制最多只用50%的CPU和128MB的内存： 1234567891011121314151617apiVersion: v1kind: Podmetadata: labels: app: nginx name: nginxspec: containers: - image: nginx name: nginx resources: requests: cpu: "300m" memory: "56Mi" limits: cpu: "500m" memory: "128Mi" 注意，CPU的单位是milicpu，500mcpu=0.5cpu；而内存的单位则包括E, P, T, G, M, K, Ei, Pi, Ti, Gi, Mi, Ki等。 kubernetes对象简称1234567891011121314151617181920212223242526272829303132333435363738* all * certificatesigningrequests (aka 'csr') * clusterrolebindings * clusterroles * clusters (valid only for federation apiservers) * componentstatuses (aka 'cs') * configmaps (aka 'cm') * controllerrevisions * cronjobs * daemonsets (aka 'ds') * deployments (aka 'deploy') * endpoints (aka 'ep') * events (aka 'ev') * horizontalpodautoscalers (aka 'hpa') * ingresses (aka 'ing') * jobs * limitranges (aka 'limits') * namespaces (aka 'ns') * networkpolicies (aka 'netpol') * nodes (aka 'no') * persistentvolumeclaims (aka 'pvc') * persistentvolumes (aka 'pv') * poddisruptionbudgets (aka 'pdb') * podpreset * pods (aka 'po') * podsecuritypolicies (aka 'psp') * podtemplates * replicasets (aka 'rs') * replicationcontrollers (aka 'rc') * resourcequotas (aka 'quota') * rolebindings * roles * secrets * serviceaccounts (aka 'sa') * services (aka 'svc') * statefulsets * storageclasses * thirdpartyresources 格式化输出要以特定的格式向终端窗口输出详细信息，可以在 kubectl 命令中添加 -o 或者 -output 标志。 123456789输出格式 描述-o=custom-columns=&lt;spec&gt; 使用逗号分隔的自定义列列表打印表格-o=custom-columns-file=&lt;filename&gt; 使用 文件中的自定义列模板打印表格-o=json 输出 JSON 格式的 API 对象-o=jsonpath=&lt;template&gt; 打印 jsonpath 表达式中定义的字段-o=jsonpath-file=&lt;filename&gt; 打印由 文件中的 jsonpath 表达式定义的字段-o=name 仅打印资源名称-o=wide 以纯文本格式输出任何附加信息，对于 Pod ，包含节点名称-o=yaml 输出 YAML 格式的 API 对象 Kubectl 详细输出和调试使用 -v 或 –v 标志跟着一个整数来指定日志级别。这里 描述了通用的 kubernetes 日志约定和相关的日志级别。 123456789详细等级 描述--v=0 总是对操作人员可见。--v=1 合理的默认日志级别，如果您不需要详细输出。--v=2 可能与系统的重大变化相关的，有关稳定状态的信息和重要的日志信息。这是对大多数系统推荐的日志级别。--v=3 有关更改的扩展信息。--v=4 调试级别详细输出。--v=6 显示请求的资源。--v=7 显示HTTP请求的header。--v=8 显示HTTP请求的内容。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>kubernates</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从google服务器拉取镜像]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E4%BB%8Egoogle%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[镜像从哪来没错，gcr.io 就是 Google 的域名，服务器更不用提，所以在进行 kubeadm init 操作时如果不先把这些镜像 load 进去绝对会卡死不动。这些镜像有两种办法可以获取： 第一种是利用一台国外的服务器，在上面 pull 下来，然后再 save 成 tar 文件，最后 scp 到本地 load 进去； 相对于第一种方式比较坑的是取决于服务器速度，每次搞起来也很蛋疼，第二种方式就是利用 docker hub 做中转，简单的说就是利用 docker hub 的自动构建功能，在 Github 中创建一个 Dockerfile，里面只需要 FROM xxxx 这些 gcr.io 的镜像即可，最后 pull 到本地，然后再 tag 一下。首先创建一个 github 项目，可以直接 fork 漠然的docker-library即可 其中每个 Dockerfile 只需要 FROM 一下即可 最后在 Docker Hub 上创建自动构建项目 最后要手动触发一下，然后 Docker Hub 才会开始给你编译 等待完成即可直接 pull 了]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>kubernates</tag>
        <tag>镜像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python获取当前日期前后N天或N月的日期]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fpython%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E6%97%A5%E6%9C%9F%E5%89%8D%E5%90%8EN%E5%A4%A9%E6%88%96N%E6%9C%88%E7%9A%84%E6%97%A5%E6%9C%9F%20%2F</url>
    <content type="text"><![CDATA[描述Python获取当前时间的前(后)N天，前(后)N周，前（后）N月你别想得太复杂，先理一下思路：1、weekday会根据某个日期返回0到6的一个数字来表示星期几对吧，0==星期一我们来列一个表：[0,1,2,3,4,5,6] 2、知道了星期几之后，你可以计算出那一周相对于这个0到6的数字的差值（比如你确定一个比较值0，那么取得该日期的weekday值假设为n，那么这个差值就是0-n对吧，针对第一条发现的列表，假设我们指定的日期是星期二，weekday数值为112[0,1,2,3,4,5,6] n 就是说n在列表中1的位置，数值也是1，那么前面星期一是否就刚好是0-1的相对位置了呢？理解了么？0-n就刚好是星期一所代表的相对位置。那么星期二呢？是不是就是0-n+1？自然的，星期三就是0-n+20-n+30-n+40-n+50-n+6，就是星期日 作者：石头三颗链接：https://www.zhihu.com/question/48603972/answer/111745346来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169# -*- coding: utf-8 -*-'''获取当前日期前后N天或N月的日期'''from time import strftime, localtimefrom datetime import timedelta, dateimport calendaryear = strftime("%Y",localtime())mon = strftime("%m",localtime())day = strftime("%d",localtime())hour = strftime("%H",localtime())min = strftime("%M",localtime())sec = strftime("%S",localtime())def today(): ''''' get today,date format="YYYY-MM-DD" ''''' return date.today()def todaystr(): ''' get date string, date format="YYYYMMDD" ''' return year+mon+daydef datetime(): ''''' get datetime,format="YYYY-MM-DD HH:MM:SS" ''' return strftime("%Y-%m-%d %H:%M:%S",localtime())def datetimestr(): ''''' get datetime string date format="YYYYMMDDHHMMSS" ''' return year+mon+day+hour+min+secdef get_day_of_day(n=0): ''''' if n&gt;=0,date is larger than today if n&lt;0,date is less than today date format = "YYYY-MM-DD" ''' if(n&lt;0): n = abs(n) return date.today()-timedelta(days=n) else: return date.today()+timedelta(days=n)def get_days_of_month(year,mon): ''''' get days of month ''' return calendar.monthrange(year, mon)[1] def get_firstday_of_month(year,mon): ''''' get the first day of month date format = "YYYY-MM-DD" ''' days="01" if(int(mon)&lt;10): mon = "0"+str(int(mon)) arr = (year,mon,days) return "-".join("%s" %i for i in arr) def get_lastday_of_month(year,mon): ''''' get the last day of month date format = "YYYY-MM-DD" ''' days=calendar.monthrange(year, mon)[1] mon = addzero(mon) arr = (year,mon,days) return "-".join("%s" %i for i in arr) def get_firstday_month(n=0): ''''' get the first day of month from today n is how many months ''' (y,m,d) = getyearandmonth(n) d = "01" arr = (y,m,d) return "-".join("%s" %i for i in arr) def get_lastday_month(n=0): ''''' get the last day of month from today n is how many months ''' return "-".join("%s" %i for i in getyearandmonth(n)) def getyearandmonth(n=0): ''''' get the year,month,days from today befor or after n months ''' thisyear = int(year) thismon = int(mon) totalmon = thismon+n if(n&gt;=0): if(totalmon&lt;=12): days = str(get_days_of_month(thisyear,totalmon)) totalmon = addzero(totalmon) return (year,totalmon,days) else: i = totalmon/12 j = totalmon%12 if(j==0): i-=1 j=12 thisyear += i days = str(get_days_of_month(thisyear,j)) j = addzero(j) return (str(thisyear),str(j),days) else: if((totalmon&gt;0) and (totalmon&lt;12)): days = str(get_days_of_month(thisyear,totalmon)) totalmon = addzero(totalmon) return (year,totalmon,days) else: i = totalmon/12 j = totalmon%12 if(j==0): i-=1 j=12 thisyear +=i days = str(get_days_of_month(thisyear,j)) j = addzero(j) return (str(thisyear),str(j),days) def addzero(n): ''''' add 0 before 0-9 return 01-09 ''' nabs = abs(int(n)) if(nabs&lt;10): return "0"+str(nabs) else: return nabs def get_today_month(n=0): ''''' 获取当前日期前后N月的日期 if n&gt;0, 获取当前日期前N月的日期 if n&lt;0, 获取当前日期后N月的日期 date format = "YYYY-MM-DD" ''' (y,m,d) = getyearandmonth(n) arr=(y,m,d) if(int(day)&lt;int(d)): arr = (y,m,day) return "-".join("%s" %i for i in arr) if __name__=="__main__": print today() print todaystr() print datetime() print datetimestr() print get_day_of_day(20) print get_day_of_day(-3) print get_today_month(-3) print get_today_month(3)]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>日期</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[圣经的特征——清晰性]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E5%9C%A3%E7%BB%8F%E7%9A%84%E7%89%B9%E5%BE%81%E2%80%94%E2%80%94%E6%B8%85%E6%99%B0%E6%80%A7%2F</url>
    <content type="text"><![CDATA[问题：只有圣经学者才能正确明白圣经吗？一、 前言当大部分人都认为圣经整体是难以明白的，这是一项目错误的认知。彼得说保罗的书信不是不可能明白的，只是不容易明白。需要反复读经，才能更好明白。二、圣经常申明其清晰性申6：6-7 上帝期望他的百姓能更好明白圣经并教训他们的儿女。该教训不是机械性的，而是他的百姓在谈论的时候也能够合宜地运用到生活当中。诗1：2 昼夜思想上帝话语的人是有福的。通过每日的默想，使自己能够更好的明白圣经圣经多次提到愚人都能明白他的话语，诗19：7 119：130愚：不是指一个人缺少智性的能力，而是指缺少正确的判断，易于犯错，易被人误入歧途这一点给我们很大的鼓舞新约圣经，耶稣也没有抱怨说旧学圣经有不清楚的地方，福音书中，门徒多次问耶稣，耶稣给出的确实你们没有念过吗，你们没有读过吗，你们错了因为你们不明白圣经，也不晓得他的能力。还有一点新约书信大部分是写给整个教会的会众的，他们是相当新的基督徒，没有任何的基督教社团背景，对以色列文化和历史也几乎没有什么了解，但是，他们都能正确明白圣经罗4：1-25;15:4林前10：1-11三、人需要有道德和属灵的品格才能正确明白圣经圣经本身是很清晰的，但对那些不愿意接受教训的人，也不会正确的明白圣经，唯有诚恳之心来寻求救恩，和求神帮助以明白圣经的人，都会明白圣经。因为有圣灵的工作。四、清晰性的定义（什么是圣经的清晰性）首先确定一点：圣经把我们在救恩、基督徒灵明与成长等方面有必要知道的事都清楚的写进去了定义：圣经在其写作上，能使所有愿意阅读他以寻求神的帮助、且愿意顺服他的人，都能够明白他的教训。五、人为何误解圣经1、有时需要等候救赎历史的下一事件出现2、缺少信心或心里刚硬3、有些教义是需要一个过程来逐渐了解的（许多有争议的教义解决起来缓慢）因为以上原因出现了：解经原则释经学：是一门研究正确解释法的学问（尤其指圣经）解经：是解释一段圣经的过程当一个人在研究解释的原则进是释经学，当一个人在应用原则而实际地解释一段经文时，就是解经重点：清晰性并不是指所有信徒在所有圣经教训上都会有一致的看法。问题不是出在圣经上，而是出在我们自己身上六、此教义所带来的激励在教义和伦理方面的争议，只有两个可能的原因：1、可能是因为我们在寻求肯定一些圣经本身静默不语的答案2、可能是我们错误的解释了圣经。出现这种问题有可能是我们的参考资料有问题或我们自己个人的问题在我们面对这些问题的时候，我们就应当诚心的寻求神的帮助，也尽力读经以寻求答案，并相信神会使我们正确的明白所以我们要每天读经渴慕读经，每天自己钻研圣经。七、学者的角色他们的任务：1、能够清楚的教导圣经2、能够发掘了解圣经的新领域3、能够辩护圣经的教训，不容别人攻击圣经4、能够补充圣经的研究，以造福教会合为一个整体就是：使教会受益处 个人思考与应用：]]></content>
      <categories>
        <category>信仰文章</category>
      </categories>
      <tags>
        <tag>信仰文章</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四层、七层负载均衡的区别]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E5%9B%9B%E5%B1%82%E3%80%81%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[一、简介1、所谓四层就是基于IP+端口的负载均衡；七层就是基于URL等应用层信息的负载均衡；同理，还有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。 换句换说，二层负载均衡会通过一个虚拟MAC地址接收请求，然后再分配到真实的MAC地址；三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址；四层通过虚拟IP+端口接收请求，然后再分配到真实的服务器；七层通过虚拟的URL或主机名接收请求，然后再分配到真实的服务器。2、所谓的四到七层负载均衡，就是在对后台的服务器进行负载均衡时，依据四层的信息或七层的信息来决定怎么样转发流量。 比如四层的负载均衡，就是通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。七层的负载均衡，就是在四层的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。 3、负载均衡器通常称为四层交换机或七层交换机。四层交换机主要分析IP层及TCP/UDP层，实现四层流量负载均衡。七层交换机除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息。 4、负载均衡分为L4 switch（四层交换），即在OSI第4层工作，就是TCP层啦。此种Load Balance不理解应用协议（如HTTP/FTP/MySQL等等）。例子：LVS，F5。 5、另一种叫做L7 switch（七层交换），OSI的最高层，应用层。此时，该Load Balancer能理解应用协议。例子： haproxy，MySQL Proxy。 注意：上面的很多Load Balancer既可以做四层交换，也可以做七层交换。 二、区别技术原理上 所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。 区别所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。 应用场景七层应用负载的好处，是使得整个网络更智能化。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，例如Nginx或者Apache上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。另外一个常常被提到功能就是安全性。网络中最常见的SYN Flood攻击，即黑客控制众多源客户端，使用虚假IP地址对同一目标发送SYN攻击，通常这种攻击会大量发送SYN报文，耗尽服务器上的相关资源，以达到Denial of Service(DoS)的目的。从技术原理上也可以看出，四层模式下这些SYN攻击都会被转发到后端的服务器上；而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营。另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文，例如SQL Injection等应用层面的特定攻击手段，从应用层面进一步提高系统整体安全。现在的7层负载均衡，主要还是着重于应用HTTP协议，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。 4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统。 三、Nginx、LVS及HAProxy负载均衡软件的优缺点负载均衡 （Load Balancing） 建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力，同时能够提高网络的灵活性和可用性。 Nginx/LVS/HAProxy是目前使用最广泛的三种负载均衡软件。 一般对负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术。具体的应用需求还得具体分析，如果是中小型的Web应用，比如日PV小于1000万，用Nginx就完全可以了；如果机器不少，可以用DNS轮询，LVS所耗费的机器还是比较多的；大型网站或重要的服务，且服务器比较多时，可以考虑用LVS。 一种是通过硬件来进行，常见的硬件有比较昂贵的F5和Array等商用的负载均衡器，它的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；另外一种就是类似于Nginx/LVS/HAProxy的基于 Linux的开源免费的负载均衡软件，这些都是通过软件级别来实现，所以费用非常低廉。 目前关于网站架构一般比较合理流行的架构方案：Web前端采用Nginx/HAProxy+ Keepalived作负载均衡器；后端采用 MySQL数据库一主多从和读写分离，采用LVS+Keepalived的架构。当然要根据项目具体需求制定方案。 下面说说各自的特点和适用场合。 Nginx的优点是： 1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是它目前广泛流行的主要原因之一，Nginx单凭这点可利用的场合就远多于LVS了。 2、Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；相反LVS对网络稳定性依赖比较大。 3、Nginx安装和配置比较简单，测试起来比较方便，它基本能把错误用日志打印出来。LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大。 4、可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些。 5、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而不满。 6、Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP也是近几年非常流行的web架构，在高流量的环境中稳定性也很好。 7、Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，可以考虑用其作为反向代理加速器。 8、Nginx可作为中层反向代理使用，这一层面Nginx基本上无对手，唯一可以对比Nginx的就只有 lighttpd了，不过 lighttpd目前还没有做到Nginx完全的功能，配置也不那么清晰易读，社区资料也远远没Nginx活跃。 9、Nginx也可作为静态网页和图片服务器，这方面的性能也无对手。还有Nginx社区非常活跃，第三方模块也很多。 Nginx的缺点是： 1、Nginx仅能支持http、https和Email协议，这样就在适用范围上面小些，这个是它的缺点。 2、对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。不支持Session的直接保持，但能通过ip_hash来解决。 3、LVS：使用Linux内核集群实现一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)。 LVS的优点是： 1、抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和cpu资源消耗比较低。 2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率。 3、工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如LVS+Keepalived。 4、无流量，LVS只分发请求，而流量并不从它本身出去，这点保证了均衡器IO的性能不会受到大流量的影响。 5、应用范围比较广，因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、在线聊天室等等。 LVS的缺点是： 1、软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。 2、如果是网站应用比较庞大的话，LVS/DR+Keepalived实施起来就比较复杂了，特别后面有 Windows Server的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。 HAProxy的特点是： 1、HAProxy也是支持虚拟主机的。 2、HAProxy的优点能够补充Nginx的一些缺点，比如支持Session的保持，Cookie的引导；同时支持通过获取指定的url来检测后端服务器的状态。 3、HAProxy跟LVS类似，本身就只是一款负载均衡软件；单纯从效率上来讲HAProxy会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。 4、HAProxy支持TCP协议的负载均衡转发，可以对MySQL读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，大家可以用LVS+Keepalived对MySQL主从做负载均衡。 5、HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种：① roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的；② static-rr，表示根据权重，建议关注；③ leastconn，表示最少连接者先处理，建议关注；④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注；⑤ ri，表示根据请求的URI；⑥ rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name；⑦ hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；⑧ rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。 Nginx和LVS对比的总结： 1、Nginx工作在网络的7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下LVS并不具备这样的功能，所以Nginx单凭这点可利用的场合就远多于LVS了；但Nginx有用的这些功能使其可调整度要高于LVS，所以经常要去触碰触碰，触碰多了，人为出问题的几率也就会大。 2、Nginx对网络稳定性的依赖较小，理论上只要ping得通，网页访问正常，Nginx就能连得通，这是Nginx的一大优势！Nginx同时还能区分内外网，如果是同时拥有内外网的节点，就相当于单机拥有了备份线路；LVS就比较依赖于网络环境，目前来看服务器在同一网段内并且LVS使用direct方式分流，效果较能得到保证。另外注意，LVS需要向托管商至少申请多一个ip来做Visual IP，貌似是不能用本身的IP来做VIP的。要做好LVS管理员，确实得跟进学习很多有关网络通信方面的知识，就不再是一个HTTP那么简单了。 3、Nginx安装和配置比较简单，测试起来也很方便，因为它基本能把错误用日志打印出来。LVS的安装和配置、测试就要花比较长的时间了；LVS对网络依赖比较大，很多时候不能配置成功都是因为网络问题而不是配置问题，出了问题要解决也相应的会麻烦得多。 4、Nginx也同样能承受很高负载且稳定，但负载度和稳定度差LVS还有几个等级：Nginx处理所有流量所以受限于机器IO和配置；本身的bug也还是难以避免的。 5、Nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。目前LVS中 ldirectd也能支持针对服务器内部的情况来监控，但LVS的原理使其不能重发请求。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而恼火。 6、Nginx对请求的异步处理可以帮助节点服务器减轻负载，假如使用 apache直接对外服务，那么出现很多的窄带链接时apache服务器将会占用大 量内存而不能释放，使用多一个Nginx做apache代理的话，这些窄带链接会被Nginx挡住，apache上就不会堆积过多的请求，这样就减少了相当多的资源占用。这点使用squid也有相同的作用，即使squid本身配置为不缓存，对apache还是有很大帮助的。 7、Nginx能支持http、https和email（email的功能比较少用），LVS所支持的应用在这点上会比Nginx更多。在使用上，一般最前端所采取的策略应是LVS，也就是DNS的指向应为LVS均衡器，LVS的优点令它非常适合做这个任务。重要的ip地址，最好交由LVS托管，比如数据库的 ip、webservice服务器的ip等等，这些ip地址随着时间推移，使用面会越来越大，如果更换ip则故障会接踵而至。所以将这些重要ip交给 LVS托管是最为稳妥的，这样做的唯一缺点是需要的VIP数量会比较多。Nginx可作为LVS节点机器使用，一是可以利用Nginx的功能，二是可以利用Nginx的性能。当然这一层面也可以直接使用squid，squid的功能方面就比Nginx弱不少了，性能上也有所逊色于Nginx。Nginx也可作为中层代理使用，这一层面Nginx基本上无对手，唯一可以撼动Nginx的就只有lighttpd了，不过lighttpd目前还没有能做到 Nginx完全的功能，配置也不那么清晰易读。另外，中层代理的IP也是重要的，所以中层代理也拥有一个VIP和LVS是最完美的方案了。具体的应用还得具体分析，如果是比较小的网站（日PV小于1000万），用Nginx就完全可以了，如果机器也不少，可以用DNS轮询，LVS所耗费的机器还是比较多的；大型网站或者重要的服务，机器不发愁的时候，要多多考虑利用LVS。 现在对网络负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术： 第一阶段：利用Nginx或HAProxy进行单点的负载均衡，这一阶段服务器规模刚脱离开单服务器、单数据库的模式，需要一定的负载均衡，但是仍然规模较小没有专业的维护团队来进行维护，也没有需要进行大规模的网站部署。这样利用Nginx或HAproxy就是第一选择，此时这些东西上手快， 配置容易，在七层之上利用HTTP协议就可以。这时是第一选择。 第二阶段：随着网络服务进一步扩大，这时单点的Nginx已经不能满足，这时使用LVS或者商用Array就是首要选择，Nginx此时就作为LVS或者Array的节点来使用，具体LVS或Array的是选择是根据公司规模和预算来选择，Array的应用交付功能非常强大，本人在某项目中使用过，性价比也远高于F5，商用首选，但是一般来说这阶段相关人才跟不上业务的提升，所以购买商业负载均衡已经成为了必经之路。 第三阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。 最终形成比较理想的基本架构为：Array/LVS — Nginx/Haproxy — Squid/Varnish — AppServer。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM系统性能监控工具]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2FJVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[描述uptime12[root@kube-master ~]# uptime 20:36:04 up 1 day, 20:57, 5 users, load average: 0.02, 0.08, 0.10 系统时间 主机运行时间 连接数：每一个终端算一个连接数 1，5，15分钟内系统的平均负载 pidstat细致观察进程，主要监控CPU/IO/内存pidstat 除最开头一行显示内核版本、主机名、日期和cpu架构外，主要列含义如下： 11:37:19: pidstat获取信息时间点 PID: 进程pid %usr: 进程在用户态运行所占cpu时间比率 %system: 进程在内核态运行所占cpu时间比率 %CPU: 进程运行所占cpu时间比率 CPU: 指示进程在哪个核运行 Command: 拉起进程对应的命令 1234567pidstat -p pid -u 1 3 -t# -p 进程ID# -u cpu信息# -t 显示线程信息# -r 内存使用信息# -d 磁盘IO# 1 3 采样频率 内存使用例子1234567[tomcat@kube-master bin]$ pidstat -p 17490 -r 1 2Linux 3.10.0-229.el7.x86_64 (kube-master) 10/10/2017 _x86_64_ (1 CPU)09:11:00 PM UID PID minflt/s majflt/s VSZ RSS %MEM Command09:11:01 PM 1002 17490 0.00 0.00 1191956 68868 4.85 java09:11:02 PM 1002 17490 0.00 0.00 1191956 68868 4.85 javaAverage: 1002 17490 0.00 0.00 1191956 68868 4.85 java 以上各列输出的含义如下： minflt/s: 每秒次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数majflt/s: 每秒主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时，相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生VSZ: 该进程使用的虚拟内存(以kB为单位)RSS: 该进程使用的物理内存(以kB为单位)%MEM: 该进程使用内存的百分比Command: 拉起进程对应的命令 IO使用情况的例子1234567[tomcat@kube-master bin]$ pidstat -d 1 2 -p 17490Linux 3.10.0-229.el7.x86_64 (kube-master) 10/10/2017 _x86_64_ (1 CPU)09:14:07 PM UID PID kB_rd/s kB_wr/s kB_ccwr/s Command09:14:08 PM 1002 17490 0.00 0.00 0.00 java09:14:09 PM 1002 17490 0.00 0.00 0.00 javaAverage: 1002 17490 0.00 0.00 0.00 java 以上主要输出的含义如下： kB_rd/s: 每秒进程从磁盘读取的数据量(以kB为单位)kB_wr/s: 每秒进程向磁盘写的数据量(以kB为单位)Command: 拉起进程对应的命令 jps列出java进程，类似于ps命令参数 -q可以指定jps只输出进程ID ，不输出类的短名称参数 -m可以用于输出传递给Java进程（主函数）的参数参数 -l可以用于输出主函数的完整路径参数 -v可以显示传递给JVM的参数说明： 多个参数可以配合使用12[tomcat@kube-master bin]$ jps -l -m -v| grep -v Jps17490 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=/home/tomcat/apache-tomcat-7.0.50/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/home/tomcat/apache-tomcat-7.0.50/endorsed -Dcatalina.base=/home/tomcat/apache-tomcat-7.0.50 -Dcatalina.home=/home/tomcat/apache-tomcat-7.0.50 -Djava.io.tmpdir=/home/tomcat/apache-tomcat-7.0.50/temp jinfo可以用来查看正在运行的Java应用程序的扩展参数，甚至支持在运行时，修改部分参数-flag ：打印指定JVM的参数值-flag [+|-]：设置指定JVM参数的布尔值-flag =：设置指定JVM参数的值123456789101112131415[tomcat@kube-master bin]$ jinfo -flag MaxPermSize 20109-XX:MaxPermSize=85983232[tomcat@kube-master bin]$ jinfo -flag MaxTenuringThreshold 20109-XX:MaxTenuringThreshold=15#显示是否打印GC详细信息[tomcat@kube-master bin]$ jinfo -flag PrintGCDetails 20109-XX:+PrintGCDetails#运行时修改参数，控制是否输出GC日志[tomcat@kube-master bin]$ jinfo -flag -PrintGCDetails 20109[tomcat@kube-master bin]$ jinfo -flag PrintGCDetails 20109-XX:-PrintGCDetails[tomcat@kube-master bin]$ jinfo -flag +PrintGCDetails 20109[tomcat@kube-master bin]$ jinfo -flag PrintGCDetails 20109-XX:+PrintGCDetails[tomcat@kube-master bin]$ jmapjmap用来查看堆内存使用状况，一般结合jhat使用。 123jmap -histo 20109 &gt;heap.txt 生成Java应用程序的堆快照和对象的统计信息jmap -heap 20109 生成JAVA堆信息包括使用的GC算法、堆配置参数和各代中堆内存使用情况jmap -dump:&lt;live&gt;,format=b,file=heap.hprof 20109 生成heapdump文件 live为只打印存活对象，b为二进制文件保存 jstackjstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息，如果是在64位机器上，需要指定选项”-J-d64”，Windows的jstack使用方式只支持以下的这种方式：jstack [-l] pid如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。 打印线程dump-l 打印锁信息-m 打印java和native的帧信息-F 强制dump，当jstack没有响应时使用123456789101112131415Usage: jstack [-l] &lt;pid&gt; (to connect to running process) jstack -F [-m] [-l] &lt;pid&gt; (to connect to a hung process) jstack [-m] [-l] &lt;executable&gt; &lt;core&gt; (to connect to a core file) jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt; (to connect to a remote debug server)Options: -F to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung) -m to print both java and native frames (mixed mode) -l long listing. Prints additional information about locks -h or -help to print this help message 使用visual vm 监控TOMCAT匿名直接连首先需要在TOMCAT的catalina.sh配置文件中增加如下配置：12345-Djava.rmi.server.hostname=192.168.10.99 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false 认证配置连接1234567-Djava.rmi.server.hostname=192.168.10.99 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=true-Dcom.sun.management.jmxremote.password.file=../conf/jmxremote.password-Dcom.sun.management.jmxremote.access.file=../conf/jmxremote.access jmxremote.password 在jdk/jre/lib/management/下，jmxremote.password.template复制，去掉.template后缀12monitorRole QEDcontrolRole R&amp;D jmxremote.access1234monitorRole readonlycontrolRole readwrite \ create javax.management.monitor.*,javax.management.timer.* \ unregister 如果出现“Error: Password file read access must be restricted: ”需要执行：12chmod +w jmxremote.password chmod 0400 jmxremote.password 重启TOMCAT]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGINX入门]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2FNginx%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[egrep -v “#|^$” filename #不显示注释和空行 nginx -t #检查语法nginx -s reload # upstream 参数官方说明1）weight=number设置该服务器的权重，默认为1，这个数值越大，服务器会被转发的请求就更多注意：当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup2)max_fails=numberNginx尝试连接后端主机失败的次数，这个数值是配合proxy_next_upstream，fastcgi_next_upstream,and memcached_next_upstream这三个参数来使用的。当Nginx接受后端服务器返回这三个参数定义的状态码时，会将这个请求转发给正常工作的后端服务器，例如404,502,503.max_fails默认值为1 3）fail_timeout=time在max_fails定义的失败次数后，距离下次检查的时间间隔，默认为10S 4)backup这标志着这个服务器作为备份服务器，当主服务器全部宕机的时候，才会向他转发请求 反向代理根据目录跳转 反向代理根据扩展名跳转 反向代理根据移动客户端跳转]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM配置参数TOMCAT]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2FJVM%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[描述不管是YGC还是Full GC,GC过程中都会对导致程序运行中中断,正确的选择不同的GC策略,调整JVM、GC的参数，可以极大的减少由于GC工作，而导致的程序运行中断方面的问题，进而适当的提高Java程序的工作效率。但是调整GC是以个极为复杂的过程，由于各个程序具备不同的特点，如：web和GUI程序就有很大区别（Web可以适当的停顿，但GUI停顿是客户无法接受的），而且由于跑在各个机器上的配置不同（主要cup个数，内存不同），所以使用的GC种类也会不同(如何选择见GC种类及如何选择)。本文将注重介绍JVM、GC的一些重要参数的设置来提高系统的性能。 trace跟踪参数1、-XX:+PrintGCDetails 当JVM退出的时候，打印GC的详细信息 2、-Xloggc:log/gc.log指定GC的日志文件位置，以文件输出，帮助开发人员更高分析问题 3、-XX:+PrintHeapAtGC每一次GC后都打印堆信息，比较详细的堆日志 4、-XX:+TraceClassLoading监控类加载信息 5、-XX:+HeapDumpOnOutOfMemoryErrorOOM时导出堆到文件 6、-XX:+HeapDumpPath导出OOM的路径 7、-XX:OnOutOfMemoryError在OOM时执行一个脚本可以在OOM时发送邮件甚至重启程序 8、-Xss通常只有几百K 决定了函数调用的深度 每个线程都有独立的栈空间 局部变量参数分配在栈上函数调用层次太深 9、-Xmixed混合模式执行 (默认) 10、-Xmixed混合模式执行 (默认) 11、-Xint仅解释模式执行 12、-Xbootclasspath:&lt;用 ; 分隔的目录和 zip/jar 文件&gt; 设置搜索路径以引导类和资源13、-Xbootclasspath/a:&lt;用 ; 分隔的目录和 zip/jar 文件&gt; 附加在引导类路径末尾14、-Xbootclasspath/p:&lt;用 ; 分隔的目录和 zip/jar 文件&gt; 置于引导类路径之前-Xdiag显示附加诊断消息15、-Xnoclassgc禁用类垃圾收集16、-Xincgc启用增量垃圾收集17、-Xloggc:将 GC 状态记录在文件中 (带时间戳)18、-Xbatch禁用后台编译19、-Xms设置初始 Java 堆大小20、-Xmx设置最大 Java 堆大小21、-Xmn设置年轻代内存大小22、-Xss设置 Java 线程堆栈大小23、-Xprof输出 cpu 配置文件数据24、-Xfuture启用最严格的检查, 预期将来的默认值25、-Xrs减少 Java/VM 对操作系统信号的使用 (请参阅文档)26、-Xcheck:jni对 JNI 函数执行其他检查27、-Xshare:off不尝试使用共享类数据28、-Xshare:auto在可能的情况下使用共享类数据 (默认)29、-Xshare:on要求使用共享类数据, 否则将失败。30、-XshowSettings显示所有设置并继续31、-XshowSettings:all显示所有设置并继续32、-XshowSettings:vm显示所有与 vm 相关的设置并继续33、-XshowSettings:properties显示所有属性设置并继续 34、-Dcmos.instance.idngwfcore-tomcat1 35、-Dcmos.system.idngwf 36、-Ddubbo.registry.file/home/rhkf/ngwfcore/tomcat….. 37、-Dzk_addresszookeeper://ip:port?backup=ip:port,ip:port-Ddubbo_port31161 38、-DXXXX-Dcom.sun.management.jmxremote 39、-Dcom.sun.management.jmxremote.port3009940、-Dcom.sun.management.jmxremote.sslFALSE41、-Dcom.sun.management.jmxremote.authenticateFALSE tomcat启动参数，将JVM GC信息写入tomcat_gc.log1CATALINA_OPTS='-Xms512m -Xmx4096m -XX:PermSize=64M -XX:MaxNewSize=128m -XX:MaxPermSize=64m -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -Xloggc:/var/log/search/tomcat_gc.log' 各个参数含义，以及GC机制，参考下文： 一、相关概念基本回收算法 引用计数（Reference Counting） 比较古老的回收算法。原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只用收集计数为0的对象。此算法最致命的是无法处理循环引用的问题。 标记-清除（Mark-Sweep） 此算法执行分两阶段。第一阶段从引用根节点开始标记所有被引用的对象，第二阶段遍历整个堆，把未标记的对象清除。此算法需要暂停整个应用，同时，会产生内存碎片。 复制（Copying） 此 算法把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾回收时，遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。次算法每次只处理 正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不过出现“碎片”问题。当然，此算法的缺点也是很明显的，就是需要两倍 内存空间。 标记-整理（Mark-Compact） 此算法结合了“标记-清除”和“复 制”两个算法的优点。也是分两阶段，第一阶段从根节点开始标记所有被引用对象，第二阶段遍历整个堆，把清除未标记对象并且把存活对象“压缩”到堆的其中一 块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。 增量收集（Incremental Collecting） 实施垃圾回收算法，即：在应用进行的同时进行垃圾回收。不知道什么原因JDK5.0中的收集器没有使用这种算法的。 分代（Generational Collecting） 基于对对象生命周期分析后得出的垃圾回收算法。把对象分为年青代、年老代、持久代，对不同生命周期的对象使用不同的算法（上述方式中的一个）进行回收。现在的垃圾回收器（从J2SE1.2开始）都是使用此算法的。 分代垃圾回收详述 Young（年轻代） 年 轻代分三个区。一个Eden区，两个Survivor区。大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区 （两个中的一个），当这个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当这个Survivor去也满了的时候，从第一 个Survivor区复制过来的并且此时还存活的对象，将被复制“年老区(Tenured)”。需要注意，Survivor的两个区是对称的，没先后关 系，所以同一个区中可能同时存在从Eden复制过来 对象，和从前一个Survivor复制过来的对象，而复制到年老区的只有从第一个Survivor去过来的对象。而且，Survivor区总有一个是空 的。 Tenured（年老代） 年老代存放从年轻代存活的对象。一般来说年老代存放的都是生命期较长的对象。 Perm（持久代） 用 于存放静态文件，如今Java类、方法等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate等， 在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。持久代大小通过-XX:MaxPermSize=进行设置。 GC类型 GC有两种类型：Scavenge GC和Full GC。 Scavenge GC 一般情况下，当新对象生成，并且在Eden申请空间失败时，就好触发Scavenge GC，堆Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。 Full GC 对整个堆进行整理，包括Young、Tenured和Perm。Full GC比Scavenge GC要慢，因此应该尽可能减少Full GC。有如下原因可能导致Full GC：Tenured被写满 Perm域被写满 System.gc()被显示调用 上一次GC之后Heap的各域分配策略动态变化 二、垃圾回收器目前的收集器主要有三种：串行收集器、并行收集器、并发收集器。 串行收集器 使用单线程处理所有垃圾回收工作，因为无需多线程交互，所以效率比较高。但是，也无法使用多处理器的优势，所以此收集器适合单处理器机器。当然，此收集器也可以用在小数据量（100M左右）情况下的多处理器机器上。可以使用-XX:+UseSerialGC打开。 并行收集器 对年轻代进行并行垃圾回收，因此可以减少垃圾回收时间。一般在多线程多处理器机器上使用。使用-XX:+UseParallelGC.打开。并行收集器在J2SE5.0第六6更新上引入，在Java SE6.0中进行了增强–可以堆年老代进行并行收集。如果年老代不使用并发收集的话，是使用单线程进行垃圾回收，因此会制约扩展能力。使用-XX:+UseParallelOldGC打开。 使用-XX:ParallelGCThreads=设置并行垃圾回收的线程数。此值可以设置与机器处理器数量相等。 此收集器可以进行如下配置： 最大垃圾回收暂停:指定垃圾回收时的最长暂停时间，通过-XX:MaxGCPauseMillis=指定。为毫秒.如果指定了此值的话，堆大小和垃圾回收相关参数会进行调整以达到指定值。设定此值可能会减少应用的吞吐量。 吞吐量:吞吐量为垃圾回收时间与非垃圾回收时间的比值，通过-XX:GCTimeRatio=来设定，公式为1/（1+N）。例如，-XX:GCTimeRatio=19时，表示5%的时间用于垃圾回收。默认情况为99，即1%的时间用于垃圾回收。 并发收集器 可以保证大部分工作都并发进行（应用不停止），垃圾回收只暂停很少的时间，此收集器适合对响应时间要求比较高的中、大规模应用。使用-XX:+UseConcMarkSweepGC打开。 并 发收集器主要减少年老代的暂停时间，他在应用不停止的情况下使用独立的垃圾回收线程，跟踪可达对象。在每个年老代垃圾回收周期中，在收集初期并发收集器会 对整个应用进行简短的暂停，在收集中还会再暂停一次。第二次暂停会比第一次稍长，在此过程中多个线程同时进行垃圾回收工作。 并发收集器使用处理器换来短暂的停顿时间。在一个N个处理器的系统上，并发收集部分使用K/N个可用处理器进行回收，一般情况下1&lt;=K&lt;=N/4。 在只有一个处理器的主机上使用并发收集器，设置为incremental mode模式也可获得较短的停顿时间。 浮动垃圾：由于在应用运行的同时进行垃圾回收，所以有些垃圾可能在垃圾回收进行完成时产生，这样就造成了“Floating Garbage”，这些垃圾需要在下次垃圾回收周期时才能回收掉。所以，并发收集器一般需要20%的预留空间用于这些浮动垃圾。 Concurrent Mode Failure：并发收集器在应用运行时进行收集，所以需要保证堆在垃圾回收的这段时间有足够的空间供程序使用，否则，垃圾回收还未完成，堆空间先满了。这种情况下将会发生“并发模式失败”，此时整个应用将会暂停，进行垃圾回收。 启动并发收集器：因为并发收集在应用运行时进行收集，所以必须保证收集完成之前有足够的内存空间供程序使用，否则会出现“Concurrent Mode Failure”。通过设置-XX:CMSInitiatingOccupancyFraction=指定还有多少剩余堆时开始执行并发收集 小结 串行处理器： –适用情况：数据量比较小（100M左右）；单处理器下并且对响应时间无要求的应用。 –缺点：只能用于小型应用 并行处理器： –适用情况：“对吞吐量有高要求”，多CPU、对应用响应时间无要求的中、大型应用。举例：后台处理、科学计算。 –缺点：应用响应时间可能较长 并发处理器： –适用情况：“对响应时间有高要求”，多CPU、对应用响应时间有较高要求的中、大型应用。举例：Web服务器/应用服务器、电信交换、集成开发环境。 三、常见配置举例堆大小设置 JVM 中最大堆大小有三方面限制：相关操作系统的数据模型（32-bt还是64-bit）限制；系统的可用虚拟内存限制；系统的可用物理内存限制。32位系统 下，一般限制在1.5G~2G；64为操作系统对内存无限制。我在Windows Server 2003 系统，3.5G物理内存，JDK5.0下测试，最大可设置为1478m。 典型设置： java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -Xmx3550m：设置JVM最大可用内存为3550M。 -Xms3550m：设置JVM促使内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 -Xmn2g：设置年轻代大小为2G。整个堆大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 -Xss128k： 设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内 存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0-XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5 -XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6 -XX:MaxPermSize=16m:设置持久代大小为16m。 -XX:MaxTenuringThreshold=0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。回收器选择 JVM给了三种选择：串行收集器、并行收集器、并发收集器，但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行判断。 吞吐量优先的并行收集器 如上文所述，并行收集器主要以到达一定的吞吐量为目标，适用于科学技术和后台处理等。 典型配置： java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20123456789101112-XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。-XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20 -XX:+UseParallelOldGC-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100-XX:MaxGCPauseMillis=100:设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100 -XX:+UseAdaptiveSizePolicy -XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。 响应时间优先的并发收集器 如上文所述，并发收集器主要是保证系统的响应时间，减少垃圾收集时的停顿时间。适用于应用服务器、电信领域等。 典型配置： java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC123456789101112131415161718192021222324252627282930-XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了，原因不明。所以，此时年轻代大小最好用-Xmn设置。-XX:+UseParNewGC:设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=5 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。-XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除碎片辅助信息 JVM提供了大量命令行参数，打印信息，供调试使用。主要有以下一些：-XX:+PrintGC 输出形式：[GC 118250K-&gt;113543K(130112K), 0.0094143 secs] [Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs]-XX:+PrintGCDetails 输出形式：[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs] [GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs] -XX:+PrintGCTimeStamps -XX:+PrintGC：PrintGCTimeStamps可与上面两个混合使用 输出形式：11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] -XX:+PrintGCApplicationConcurrentTime:打印每次垃圾回收前，程序未中断的执行时间。可与上面混合使用 输出形式：Application time: 0.5291524 seconds -XX:+PrintGCApplicationStoppedTime：打印垃圾回收期间程序暂停的时间。可与上面混合使用 输出形式：Total time for which application threads were stopped: 0.0468229 seconds -XX:PrintHeapAtGC:打印GC前后的详细堆栈信息 12345678910111213141516171819202122232425输出形式： 34.702: [GC &#123;Heap before gc invocations=7: def new generation total 55296K, used 52568K [0x1ebd0000, 0x227d0000, 0x227d0000) eden space 49152K, 99% used [0x1ebd0000, 0x21bce430, 0x21bd0000) from space 6144K, 55% used [0x221d0000, 0x22527e10, 0x227d0000) to space 6144K, 0% used [0x21bd0000, 0x21bd0000, 0x221d0000) tenured generation total 69632K, used 2696K [0x227d0000, 0x26bd0000, 0x26bd0000) the space 69632K, 3% used [0x227d0000, 0x22a720f8, 0x22a72200, 0x26bd0000) compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000) the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000) ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000) rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000) 34.735: [DefNew: 52568K-&gt;3433K(55296K), 0.0072126 secs] 55264K-&gt;6615K(124928K)Heap after gc invocations=8: def new generation total 55296K, used 3433K [0x1ebd0000, 0x227d0000, 0x227d0000) eden space 49152K, 0% used [0x1ebd0000, 0x1ebd0000, 0x21bd0000) from space 6144K, 55% used [0x21bd0000, 0x21f2a5e8, 0x221d0000) to space 6144K, 0% used [0x221d0000, 0x221d0000, 0x227d0000) tenured generation total 69632K, used 3182K [0x227d0000, 0x26bd0000, 0x26bd0000) the space 69632K, 4% used [0x227d0000, 0x22aeb958, 0x22aeba00, 0x26bd0000) compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000) the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000) ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000) rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000) &#125; , 0.0757599 secs] -Xloggc:filename:与上面几个配合使用，把相关日志信息记录到文件以便分析。常见配置汇总 堆设置 -Xms:初始堆大小 -Xmx:最大堆大小 -XX:NewSize=n:设置年轻代大小 -XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4 -XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5 -XX:MaxPermSize=n:设置持久代大小 收集器设置 -XX:+UseSerialGC:设置串行收集器 -XX:+UseParallelGC:设置并行收集器 -XX:+UseParalledlOldGC:设置并行年老代收集器 -XX:+UseConcMarkSweepGC:设置并发收集器 垃圾回收统计信息 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:filename 并行收集器设置 -XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数。 -XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间 -XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n) 并发收集器设置 -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。 -XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。 四、调优总结年轻代大小选择 响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。 吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。年老代大小选择 响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得： 并发垃圾收集信息 持久代并发收集次数 传统GC信息 花在年轻代和年老代回收上的时间比例 减少年轻代和年老代花费的时间，一般会提高应用的效率 吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。 较小堆引起的碎片问题 因 为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间 较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出 现“碎片”，可能需要进行如下配置： -XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。 -XX:CMSFullGCsBeforeCompaction=0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>TOMCAT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell实例手册]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fshell%E5%AE%9E%E4%BE%8B%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[描述今天想谈谈“运维”这一行，分析一下目前Linux这个行业的现状以及如何学好Linux、成为专业运维人员和云服务对运维的影响! 文件123456789101112131415161718192021222324252627282930313233343536touch file # 创建空白文件rm -rf 目录名 # 不提示删除非空目录(-r:递归删除 -f强制)dos2unix # windows文本转linux文本 unix2dos # linux文本转windows文本enca filename # 查看编码 安装 yum install -y enca md5sum # 查看md5值ln 源文件 目标文件 # 硬链接ln -s 源文件 目标文件 # 符号连接readlink -f /data # 查看连接真实目录cat file | nl |less # 查看上下翻页且显示行号 q退出head # 查看文件开头内容head -c 10m # 截取文件中10M内容split -C 10M # 将文件切割大小为10Mtail -f file # 查看结尾 监视日志文件file # 检查文件类型umask # 更改默认权限uniq # 删除重复的行uniq -c # 重复的行出现次数uniq -u # 只显示不重复行paste a b # 将两个文件合并用tab键分隔开paste -d'+' a b # 将两个文件合并指定'+'符号隔开paste -s a # 将多行数据合并到一行用tab键隔开chattr +i /etc/passwd # 设置不可改变位more # 向下分面器locate 字符串 # 搜索wc -l file # 查看行数cp filename&#123;,.bak&#125; # 快速备份一个文件\cp a b # 拷贝不提示 既不使用别名 cp -irev # 将行中的字符逆序排列comm -12 2 3 # 行和行比较匹配iconv -f gbk -t utf8 原.txt &gt; 新.txt # 转换编码rename 原模式 目标模式 文件 # 重命名 可正则watch -d -n 1 'df; ls -FlAt /path' # 实时某个目录下查看最新改动过的文件cp -v /dev/dvd /rhel4.6.iso9660 # 制作镜像diff suzu.c suzu2.c &gt; sz.patch # 制作补丁patch suzu.c &lt; sz.patch # 安装补丁 123456789101112131415161718192021222324252627sort排序&#123; -t # 指定排序时所用的栏位分隔字符 -n # 依照数值的大小排序 -r # 以相反的顺序来排序 -f # 排序时，将小写字母视为大写字母 -d # 排序时，处理英文字母、数字及空格字符外，忽略其他的字符 -c # 检查文件是否已经按照顺序排序 -b # 忽略每行前面开始处的空格字符 -M # 前面3个字母依照月份的缩写进行排序 -k # 指定域 -m # 将几个排序好的文件进行合并 +&lt;起始栏位&gt;-&lt;结束栏位&gt; # 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。 -o # 将排序后的结果存入指定的文 n # 表示进行排序 r # 表示逆序 sort -n # 按数字排序 sort -nr # 按数字倒叙 sort -u # 过滤重复行 sort -m a.txt c.txt # 将两个文件内容整合到一起 sort -n -t' ' -k 2 -k 3 a.txt # 第二域相同，将从第三域进行升降处理 sort -n -t':' -k 3r a.txt # 以:为分割域的第三域进行倒叙排列 sort -k 1.3 a.txt # 从第三个字母起进行排序 sort -t" " -k 2n -u a.txt # 以第二域进行排序，如果遇到重复的，就删除 &#125; 12345678910111213141516171819202122232425262728find查找&#123; # linux文件无创建时间 # Access 使用时间 # Modify 内容修改时间 # Change 状态改变时间(权限、属主) # 时间默认以24小时为单位,当前时间到向前24小时为0天,向前48-72小时为2天 # -and 且 匹配两个条件 参数可以确定时间范围 -mtime +2 -and -mtime -4 # -or 或 匹配任意一个条件 find /etc -name http # 按文件名查找 find . -type f # 查找某一类型文件 find / -perm # 按照文件权限查找 find / -user # 按照文件属主查找 find / -group # 按照文件所属的组来查找文件 find / -atime -n # 文件使用时间在N天以内 find / -atime +n # 文件使用时间在N天以前 find / -mtime -n # 文件内容改变时间在N天以内 find / -mtime +n # 文件内容改变时间在N天以前 find / -ctime +n # 文件状态改变时间在N天前 find / -ctime -n # 文件状态改变时间在N天内 find / -size +1000000c -print # 查找文件长度大于1M字节的文件 find /etc -name "passwd*" -exec grep "xuesong" &#123;&#125; \; # 按名字查找文件传递给-exec后命令 find . -name 't*' -exec basename &#123;&#125; \; # 查找文件名,不取路径 find . -type f -name "err*" -exec rename err ERR &#123;&#125; \; # 批量改名(查找err 替换为 ERR &#123;&#125;文件 find 路径 -name *name1* -or -name *name2* # 查找任意一个关键字 &#125; 12345678910111213141516171819202122232425262728vim编辑器&#123; gconf-editor # 配置编辑器 /etc/vimrc # 配置文件路径 vim +24 file # 打开文件定位到指定行 vim file1 file2 # 打开多个文件 vim -O2 file1 file2 # 垂直分屏 vim -on file1 file2 # 水平分屏 sp filename # 上下分割打开新文件 vsp filename # 左右分割打开新文件 Ctrl+W [操作] # 多个文件间操作 大写W # 操作: 关闭当前窗口c 屏幕高度一样= 增加高度+ 移动光标所在屏 右l 左h 上k 下j 中h 下一个w :n # 编辑下一个文件 :2n # 编辑下二个文件 :N # 编辑前一个文件 :rew # 回到首文件 :set nu # 打开行号 :set nonu # 取消行号 200G # 跳转到200 :nohl # 取消高亮 :set autoindent # 设置自动缩进 :set ff # 查看文本格式 :set binary # 改为unix格式 ctrl+ U # 向前翻页 ctrl+ D # 向后翻页 %s/字符1/字符2/g # 全部替换 X # 文档加密 &#125; 123456789101112131415161718192021222324252627282930归档解压缩&#123; tar zxvpf gz.tar.gz -C 放到指定目录 包中的目录 # 解包tar.gz 不指定目录则全解压 tar zcvpf /$path/gz.tar.gz * # 打包gz 注意*最好用相对路径 tar zcf /$path/gz.tar.gz * # 打包正确不提示 tar ztvpf gz.tar.gz # 查看gz tar xvf 1.tar -C 目录 # 解包tar tar -cvf 1.tar * # 打包tar tar tvf 1.tar # 查看tar tar -rvf 1.tar 文件名 # 给tar追加文件 tar --exclude=/home/dmtsai -zcvf myfile.tar.gz /home/* /etc # 打包/home, /etc ，但排除 /home/dmtsai tar -N "2005/06/01" -zcvf home.tar.gz /home # 在 /home 当中，比 2005/06/01 新的文件才备份 tar -zcvfh home.tar.gz /home # 打包目录中包括连接目录 zgrep 字符 1.gz # 查看压缩包中文件字符行 bzip2 -dv 1.tar.bz2 # 解压bzip2 bzip2 -v 1.tar # bzip2压缩 bzcat # 查看bzip2 gzip A # 直接压缩文件 # 压缩后源文件消失 gunzip A.gz # 直接解压文件 # 解压后源文件消失 gzip -dv 1.tar.gz # 解压gzip到tar gzip -v 1.tar # 压缩tar到gz unzip zip.zip # 解压zip zip zip.zip * # 压缩zip # rar3.6下载: http://www.rarsoft.com/rar/rarlinux-3.6.0.tar.gz rar a rar.rar *.jpg # 压缩文件为rar包 unrar x rar.rar # 解压rar包 7z a 7z.7z * # 7z压缩 7z e 7z.7z # 7z解压 &#125; 软件1234567891011121314rpm&#123; rpm -ivh lynx # rpm安装 rpm -e lynx # 卸载包 rpm -e lynx --nodeps # 强制卸载 rpm -qa # 查看所有安装的rpm包 rpm -qa | grep lynx # 查找包是否安装 rpm -ql # 软件包路径 rpm -Uvh # 升级包 rpm --test lynx # 测试 rpm -qc # 软件包配置文档 rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6 # 导入rpm的签名信息 &#125; 123456789101112131415161718192021222324252627282930313233343536373839yum&#123; yum list # 查找所有列表 yum install 包名 # 安装包和依赖包 yum -y update # 升级所有包版本,依赖关系，系统版本内核都升级 yum -y update 软件包名 # 升级指定的软件包 yum -y upgrade # 不改变软件设置更新软件，系统版本升级，内核不改变 yum search mail # yum搜索相关包 yum grouplist # 软件包组 yum -y groupinstall "Virtualization" # 安装软件包组 &#125; yum扩展源&#123; # 包下载地址:http://download.fedoraproject.org/pub/epel # 选择版本 wget http://download.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm rpm -Uvh epel-release-5-4.noarch.rpm &#125; 自定义yum源&#123; find /etc/yum.repos.d -name "*.repo" -exec mv &#123;&#125; &#123;&#125;.bak \; vim /etc/yum.repos.d/yum.repo [yum] #http baseurl=http://10.0.0.1/centos5.5 #挂载iso #mount -o loop CentOS-5.8-x86_64-bin-DVD-1of2.iso /data/iso/ #本地 #baseurl=file:///data/iso/ enable=1 #导入key rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5 &#125; 123456789101112131415161718192021222324252627282930313233343536编译&#123; 源码安装&#123; ./configure --help # 查看所有编译参数 ./configure --prefix=/usr/local/ # 配置参数 make # 编译 make install # 安装包 make clean # 清除编译结果 &#125; perl程序编译&#123; perl Makefile.PL make make test make install &#125; python程序编译&#123; python file.py &#125; 编译c程序&#123; gcc -g hello.c -o hello &#125; &#125; &#125; 系统123456789101112131415161718192021222324252627wall # 给其它用户发消息 whereis ls # 查找命令的目录 which # 查看当前要执行的命令所在的路径 clear # 清空整个屏幕 reset # 重新初始化屏幕 cal # 显示月历 echo -n 123456 | md5sum # md5加密 mkpasswd # 随机生成密码 -l位数 -C大小 -c小写 -d数字 -s特殊字符 netstat -anlp | grep port # 是否打开了某个端口 ntpdate stdtime.gov.hk # 同步时间 tzselect # 选择时区 #+8=(5 9 1 1) # (TZ='Asia/Shanghai'; export TZ)括号内写入 /etc/profile /sbin/hwclock -w # 保存到硬件 /etc/shadow # 账户影子文件 LANG=en # 修改语言 vim /etc/sysconfig/i18n # 修改编码 LANG="en_US.UTF-8" export LC_ALL=C # 强制字符集 vi /etc/hosts # 查询静态主机名 alias # 别名 watch uptime # 监测命令动态刷新 ipcs -a # 查看Linux系统当前单个共享内存段的最大值 lsof |grep /lib # 查看加载库文件 ldconfig # 动态链接库管理命令 dist-upgrade # 会改变配置文件,改变旧的依赖关系，改变系统版本 /boot/grub/grub.conf # grub启动项配置 sysctl -p # 修改内核参数/etc/sysctl.conf，让/etc/rc.d/rc.sysinit读取生效 mkpasswd -l 8 -C 2 -c 2 -d 4 -s 0 # 随机生成指定类型密码 echo 1 &gt; /proc/sys/net/ipv4/tcp_syncookies # 使TCP SYN Cookie 保护生效 # "SYN Attack"是一种拒绝服务的攻击方式 12345678开机启动脚本顺序&#123; /etc/profile /etc/profile.d/*.sh ~/bash_profile ~/.bashrc /etc/bashrc &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134进程管理&#123; ps -eaf # 查看所有进程 kill -9 PID # 强制终止某个PID进程 kill -15 PID # 安全退出 需程序内部处理信号 cmd &amp; # 命令后台运行 nohup cmd &amp; # 后台运行不受shell退出影响 ctrl+z # 将前台放入后台(暂停) jobs # 查看后台运行程序 bg 2 # 启动后台暂停进程 fg 2 # 调回后台进程 pstree # 进程树 vmstat 1 9 # 每隔一秒报告系统性能信息9次 sar # 查看cpu等状态 lsof file # 显示打开指定文件的所有进程 lsof -i:32768 # 查看端口的进程 renice +1 180 # 把180号进程的优先级加1 ps aux |grep -v USER | sort -nk +4 | tail # 显示消耗内存最多的10个运行中的进程，以内存使用量排序.cpu +3 top&#123; 前五行是系统整体的统计信息。 第一行: 任务队列信息，同 uptime 命令的执行结果。内容如下： 01:06:48 当前时间 up 1:22 系统运行时间，格式为时:分 1 user 当前登录用户数 load average: 0.06, 0.60, 0.48 系统负载，即任务队列的平均长度。 三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。 第二、三行:为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下： Tasks: 29 total 进程总数 1 running 正在运行的进程数 28 sleeping 睡眠的进程数 0 stopped 停止的进程数 0 zombie 僵尸进程数 Cpu(s): 0.3% us 用户空间占用CPU百分比 1.0% sy 内核空间占用CPU百分比 0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比 98.7% id 空闲CPU百分比 0.0% wa 等待输入输出的CPU时间百分比 0.0% hi 0.0% si 第四、五行:为内存信息。内容如下： Mem: 191272k total 物理内存总量 173656k used 使用的物理内存总量 17616k free 空闲内存总量 22052k buffers 用作内核缓存的内存量 Swap: 192772k total 交换区总量 0k used 使用的交换区总量 192772k free 空闲交换区总量 123988k cached 缓冲的交换区总量。 内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖， 该数值即为这些内容已存在于内存中的交换区的大小。 相应的内存再次被换出时可不必再对交换区写入。 进程信息区,各列的含义如下: # 显示各个进程的详细信息 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比 l TIME 进程使用的CPU时间总计，单位秒 m TIME+ 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态。 D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 sched.h &#125; linux操作系统提供的信号&#123; kill -l # 查看linux提供的信号 trap "echo aaa" 2 3 15 # shell使用 trap 捕捉退出信号 # 发送信号一般有两种原因: # 1(被动式) 内核检测到一个系统事件.例如子进程退出会像父进程发送SIGCHLD信号.键盘按下control+c会发送SIGINT信号 # 2(主动式) 通过系统调用kill来向指定进程发送信号 # 进程结束信号 SIGTERM 和 SIGKILL 的区别: SIGTERM 比较友好，进程能捕捉这个信号，根据您的需要来关闭程序。在关闭程序之前，您可以结束打开的记录文件和完成正在做的任务。在某些情况下，假如进程正在进行作业而且不能中断，那么进程可以忽略这个SIGTERM信号。 # 如果一个进程收到一个SIGUSR1信号，然后执行信号绑定函数，第二个SIGUSR2信号又来了，第一个信号没有被处理完毕的话，第二个信号就会丢弃。 SIGHUP 1 A # 终端挂起或者控制进程终止 SIGINT 2 A # 键盘终端进程(如control+c) SIGQUIT 3 C # 键盘的退出键被按下 SIGILL 4 C # 非法指令 SIGABRT 6 C # 由abort(3)发出的退出指令 SIGFPE 8 C # 浮点异常 SIGKILL 9 AEF # Kill信号 立刻停止 SIGSEGV 11 C # 无效的内存引用 SIGPIPE 13 A # 管道破裂: 写一个没有读端口的管道 SIGALRM 14 A # 闹钟信号 由alarm(2)发出的信号 SIGTERM 15 A # 终止信号,可让程序安全退出 kill -15 SIGUSR1 30,10,16 A # 用户自定义信号1 SIGUSR2 31,12,17 A # 用户自定义信号2 SIGCHLD 20,17,18 B # 子进程结束自动向父进程发送SIGCHLD信号 SIGCONT 19,18,25 # 进程继续（曾被停止的进程） SIGSTOP 17,19,23 DEF # 终止进程 SIGTSTP 18,20,24 D # 控制终端（tty）上按下停止键 SIGTTIN 21,21,26 D # 后台进程企图从控制终端读 SIGTTOU 22,22,27 D # 后台进程企图从控制终端写 缺省处理动作一项中的字母含义如下: A 缺省的动作是终止进程 B 缺省的动作是忽略此信号，将该信号丢弃，不做处理 C 缺省的动作是终止进程并进行内核映像转储(dump core),内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。 D 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用） E 信号不能被捕获 F 信号不能被忽略 &#125; &#125; 123456789101112131415日志管理&#123; history # 历时命令默认1000条 HISTTIMEFORMAT="%Y-%m-%d %H:%M:%S " # 让history命令显示具体时间 history -c # 清除记录命令 cat $HOME/.bash_history # 历史命令记录文件 last # 查看登陆过的用户信息 who /var/log/wtmp # 查看登陆过的用户信息 lastlog # 用户最后登录的时间 lastb -a # 列出登录系统失败的用户相关信息 /var/log/btmp # 登录失败二进制日志记录文件 tail -f /var/log/messages # 系统日志 tail -f /var/log/secure # ssh日志 &#125;]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux配置yum源]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2FLinux%E9%85%8D%E7%BD%AEyum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[描述挂接命令(mount) 首先，介绍一下挂接(mount)命令的使用方法，mount命令参数非常多，这里主要讲一下今天我们要用到的。 命令格式：mount [-t vfstype] [-o options] device dir其中： 1.-t vfstype 指定文件系统的类型，通常不必指定。mount 会自动选择正确的类型。常用类型有： 光盘或光盘镜像：iso9660 DOS fat16文件系统：msdos Windows 9x fat32文件系统：vfat Windows NT ntfs文件系统：ntfs Mount Windows文件网络共享：smbfs UNIX(LINUX) 文件网络共享：nfs 2.-o options 主要用来描述设备或档案的挂接方式。常用的参数有： loop：用来把一个文件当成硬盘分区挂接上系统 ro：采用只读方式挂接设备 rw：采用读写方式挂接设备 iocharset：指定访问文件系统所用字符集 3.device 要挂接(mount)的设备。 4.dir设备在系统上的挂接点(mount point)。 虚拟机下配置YUM源123456789101112131415161718192021222324252627282930313233虚拟机下配置yun源[root@localhost ~]# mkdir /mnt/cdrommount -o loop /home/was/rhel-server-7.2-x86_64-dvd.iso /mnt/cdromcd /mnt/cdromll[root@localhost iso]# cd /etc/yum.repos.d/[root@localhost yum.repos.d]# lsrhel-source.repo[root@localhost yum.repos.d]# cp rhel-source.repo base.repo[root@localhost yum.repos.d]# cat base.repo #yun源的名字，做到全局唯一不重复[rhel-iso]#注释信息name=Red Hat Enterprise Linux $releasever - $basearch - Source#yum源的路径，支持三种协议：http、ftp、file，其中file表示本地文件，/iso才是真实路径#baseurl=file:///mnt/cdrom#apache HTTP的源baseurl=http://192.168.10.53/1#1表示启用，0表示禁用enabled=1#指纹校验，为0表示不校验gpgcheck=0[root@localhost yum.repos.d]# pwd/etc/yum.repos.d[root@localhost yum.repos.d]# lltotal 8-rw-r--r--. 1 root root 173 Jul 23 19:09 iso.repo-rw-r--r--. 1 root root 529 Apr 28 2011 rhel-source.repo]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下安装部署Ansible]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2FLinux%E4%B8%8B%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Ansible%2F</url>
    <content type="text"><![CDATA[描述介绍Ansible是一种批量部署工具，现在运维人员用的最多的三种开源集中化管理工具有：puppet,saltstack,ansible，各有各的优缺点，其中saltstack和ansible都是用python开发的。ansible其实准确的说只提供了一个框架，它要基于很多其他的python模块才能工作的，所以在安装ansible的时候你要再装很多其他的依赖包的。 好处之一是使用者可以开发自己的模块，放在里面使用。第二个好处是无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可。第三个好处是批量任务执行可以写成脚本，而且不用分发到远程就可以执行。 正文注意：强烈建议升级python版本到2.7以上，不然运行会出错或者有些功能会没有，在编译安装其他包的时候也会因为兼容问题报错。 python2.7 非root用户安装123456https://www.python.org/ftp/python/2.7.8/Python-2.7.8.tgz# tar xvzf Python-2.7.8.tgz# cd Python-2.7.8# ./configure --prefix=/home/test/python# make # make install 配置环境变量，把PYTHON的BIN目录加入到 PATH目录即可 setuptools模块安装1234https://pypi.python.org/packages/source/s/setuptools/setuptools-7.0.tar.gz# tar xvzf setuptools-7.0.tar.gz# cd setuptools-7.0# python setup.py install 安装好setuptools后就可以利用easy_install这个工具安装下面的python模块了，但我的电脑是虚拟机，配置太低了，所以基本无法安装，所以只好一个一个下载下来再安装了。 注意：一定要安装zlib和zlib-devel pycrypto模块安装1234https://pypi.python.org/packages/source/p/pycrypto/pycrypto-2.6.1.tar.gz# tar xvzf pycrypto-2.6.1.tar.gz# cd pycrypto-2.6.1# python setup.py install PyYAML模块安装1234https://pypi.python.org/packages/source/P/PyYAML/PyYAML-3.11.tar.gz# tar xvzf PyYAML-3.11.tar.gz# cd PyYAML-3.11# python setup.py install Jinja2模块安装12345678910https://pypi.python.org/packages/source/M/MarkupSafe/MarkupSafe-0.9.3.tar.gz# tar xvzf MarkupSafe-0.9.3.tar.gz# cd MarkupSafe-0.9.3# python setup.py installhttps://pypi.python.org/packages/source/J/Jinja2/Jinja2-2.7.3.tar.gz# tar xvzf Jinja2-2.7.3.tar.gz# cd Jinja2-2.7.3# python setup.py install paramiko模块安装12345678910https://pypi.python.org/packages/source/e/ecdsa/ecdsa-0.11.tar.gz# tar xvzf ecdsa-0.11.tar.gz# cd ecdsa-0.11# python setup.py installhttps://pypi.python.org/packages/source/p/paramiko/paramiko-1.15.1.tar.gz# tar xvzf paramiko-1.15.1.tar.gz# cd paramiko-1.15.1# python setup.py install 注意：该模块我没有安装，ansible已然可以用 simplejson模块安装1234https://pypi.python.org/packages/source/s/simplejson/simplejson-3.6.5.tar.gz# tar xvzf simplejson-3.6.5.tar.gz# cd simplejson-3.6.5# python setup.py install ansible安装1234https://github.com/ansible/ansible/archive/v1.7.2.tar.gz# tar xvzf ansible-1.7.2.tar.gz# cd ansible-1.7.2# python setup.py install SSH免密钥登录设置12345## 生成公钥/私钥# ssh-keygen -t rsa -P ''## 写入信任文件（将/root/.ssh/id_rsa_storm1.pub分发到其他服务器，并在所有服务器上执行如下指令）：# cat /root/.ssh/id_rsa_storm1.pub &gt;&gt; /root/.ssh/authorized_keys# chmod 600 /root/.ssh/authorized_keys 拷贝，生成ansible配置文件12345678a 配置文件/etc/ansible/ansible.cfg# mkdir -p /etc/ansible#cp ansible-1.7.2/examples/ansible.cfg /etc/ansible/b 配置文件/etc/ansible/hosts# vim /etc/ansible/hosts[test]192.168.110.20192.168.110.30]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】Ansible5：常用模块]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91Ansible5%EF%BC%9A%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[描述根据zs官方的分类，将模块按功能分类为：云模块、命令模块、数据库模块、文件模块、资产模块、消息模块、监控模块、网络模块、通知模块、包管理模块、源码控制模块、系统模块、单元模块、web设施模块、windows模块 ，具体可以参看官方页面。这里从官方分类的模块里选择最常用的一些模块进行介绍。 一、ping模块测试主机是否是通的，用法很简单，不涉及参数：1ansible test -m ping 二、setup模块setup模块，主要用于获取主机信息，在playbooks里经常会用到的一个参数gather_facts就与该模块相关。setup模块下经常使用的一个参数是filter参数，具体使用示例如下：123ansible 10.212.52.252 -m setup -a 'filter=ansible_*_mb' //查看主机内存信息ansible 10.212.52.252 -m setup -a 'filter=ansible_eth[0-2]' //查看地接口为eth0-2的网卡信息ansible all -m setup --tree /tmp/facts //将所有主机的信息输入到/tmp/facts目录下，每台主机的信息输入到主机名文件中（/etc/ansible/hosts里的主机名） 三、file模块file模块主要用于远程主机上的文件操作，file模块包含如下选项： force：需要在两种情况下强制创建软链接，一种是源文件不存在但之后会建立的情况下；另一种是目标软链接已存在,需要先取消之前的软链，然后创建新的软链，有两个选项：yes|no group：定义文件/目录的属组 mode：定义文件/目录的权限 owner：定义文件/目录的属主 path：必选项，定义文件/目录的路径 recurse：递归的设置文件的属性，只对目录有效 src：要被链接的源文件的路径，只应用于state=link的情况 dest：被链接到的路径，只应用于state=link的情况 state： directory：如果目录不存在，创建目录 file：即使文件不存在，也不会被创建 link：创建软链接 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件 使用示例：123ansible test -m file -a "src=/etc/fstab dest=/tmp/fstab state=link"ansible test -m file -a "path=/tmp/fstab state=absent"ansible test -m file -a "path=/tmp/test state=touch" 四、copy模块复制文件到远程主机，copy模块包含如下选项： backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no content：用于替代”src”,可以直接设定指定文件的值 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 directory_mode：递归的设定目录的权限，默认为系统默认权限 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes others：所有的file模块里的选项都可以在这里使用 src：要复制到远程主机的文件在本地的地址，可以是绝对路径，也可以是相对路径。如果路径是一个目录，它将递归复制。在这种情况下，如果路径使用”/“来结尾，则只复制目录里的内容，如果没有使用”/“来结尾，则包含目录在内的整个内容全部复制，类似于rsync。 validate ：The validation command to run before copying into place. The path to the file to validate is passed in via ‘%s’ which must be present as in the visudo example below. 示例如下：123ansible test -m copy -a "src=/srv/myfiles/foo.conf dest=/etc/foo.conf owner=foo group=foo mode=0644"ansible test -m copy -a "src=/mine/ntp.conf dest=/etc/ntp.conf owner=root group=root mode=644 backup=yes"ansible test -m copy -a "src=/mine/sudoers dest=/etc/sudoers validate='visudo -cf %s'" 五、service模块用于管理服务 该模块包含如下选项： arguments：给命令行提供一些选项 enabled：是否开机启动 yes|no name：必选项，服务名称 pattern：定义一个模式，如果通过status指令来查看服务的状态时，没有响应，就会通过ps指令在进程中根据该模式进行查找，如果匹配到，则认为该服务依然在运行 runlevel：运行级别 sleep：如果执行了restarted，在则stop和start之间沉睡几秒钟 state：对当前服务执行启动，停止、重启、重新加载等操作（started,stopped,restarted,reloaded） 使用示例：123ansible test -m service -a "name=httpd state=started enabled=yes"asnible test -m service -a "name=foo pattern=/usr/bin/foo state=started"ansible test -m service -a "name=network state=restarted args=eth0" 六、cron模块用于管理计划任务包含如下选项： backup：对远程主机上的原任务计划内容修改之前做备份 cron_file：如果指定该选项，则用该文件替换远程主机上的cron.d目录下的用户的任务计划 day：日（1-31，，/2,……） hour：小时（0-23，，/2，……） minute：分钟（0-59，，/2，……） month：月（1-12，，/2，……） weekday：周（0-7，*，……） job：要执行的任务，依赖于state=present name：该任务的描述 special_time：指定什么时候执行，参数：reboot,yearly,annually,monthly,weekly,daily,hourly state：确认该任务计划是创建还是删除 user：以哪个用户的身份执行 示例：1234ansible test -m cron -a 'name="a job for reboot" special_time=reboot job="/some/job.sh"'ansible test -m cron -a 'name="yum autoupdate" weekday="2" minute=0 hour=12 user="rootansible test -m cron -a 'backup="True" name="test" minute="0" hour="5,2" job="ls -alh &gt; /dev/null"'ansilbe test -m cron -a 'cron_file=ansible_yum-autoupdate state=absent' 七、yum模块使用yum包管理器来管理软件包，其选项有： config_file：yum的配置文件 disable_gpg_check：关闭gpg_check disablerepo：不启用某个源 enablerepo：启用某个源 name：要进行操作的软件包的名字，也可以传递一个url或者一个本地的rpm包的路径 state：状态（present，absent，latest） 示例如下：123ansible test -m yum -a 'name=httpd state=latest'ansible test -m yum -a 'name="@Development tools" state=present'ansible test -m yum -a 'name=http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm state=present' 八、user模块与group模块user模块是请求的是useradd, userdel, usermod三个指令，goup模块请求的是groupadd, groupdel, groupmod 三个指令。 1、user模块 home：指定用户的家目录，需要与createhome配合使用 groups：指定用户的属组 uid：指定用的uid password：指定用户的密码 name：指定用户名 createhome：是否创建家目录 yes|no system：是否为系统用户 remove：当state=absent时，remove=yes则表示连同家目录一起删除，等价于userdel -r state：是创建还是删除 shell：指定用户的shell环境 使用示例：1234user: name=johnd comment="John Doe" uid=1040 group=adminuser: name=james shell=/bin/bash groups=admins,developers append=yes user: name=johnd state=absent remove=yesuser: name=james18 shell=/bin/zsh groups=developers expires=1422403387user: name=test generate_ssh_key=yes ssh_key_bits=2048 ssh_key_file=.ssh/id_rsa #生成密钥时，只会生成公钥文件和私钥文件，和直接使用ssh-keygen指令效果相同，不会生成authorized_keys文件。 注：指定password参数时，不能使用明文密码，因为后面这一串密码会被直接传送到被管理主机的/etc/shadow文件中，所以需要先将密码字符串进行加密处理。然后将得到的字符串放到password中即可。1234567echo "123456" | openssl passwd -1 -salt $(&lt; /dev/urandom tr -dc '[:alnum:]' | head -c 32) -stdin$1$4P4PlFuE$ur9ObJiT5iHNrb9QnjaIB0#使用上面的密码创建用户ansible all -m user -a 'name=foo password="$1$4P4PlFuE$ur9ObJiT5iHNrb9QnjaIB0"' 不同的发行版默认使用的加密方式可能会有区别，具体可以查看/etc/login.defs文件确认，centos 6.5版本使用的是SHA512加密算法。 2、group示例1ansible all -m group -a 'name=somegroup state=present' 九、synchronize模块使用rsync同步文件，其参数如下： archive: 归档，相当于同时开启recursive(递归)、links、perms、times、owner、group、-D选项都为yes ，默认该项为开启 checksum: 跳过检测sum值，默认关闭 compress:是否开启压缩 copy_links：复制链接文件，默认为no ，注意后面还有一个links参数 delete: 删除不存在的文件，默认no dest：目录路径 dest_port：默认目录主机上的端口 ，默认是22，走的ssh协议 dirs：传速目录不进行递归，默认为no，即进行目录递归 rsync_opts：rsync参数部分 set_remote_user：主要用于/etc/ansible/hosts中定义或默认使用的用户与rsync使用的用户不同的情况 mode: push或pull 模块，push模的话，一般用于从本机向远程主机上传文件，pull 模式用于从远程主机上取文件 使用示例：1234src=some/relative/path dest=/some/absolute/path rsync_path="sudo rsync"src=some/relative/path dest=/some/absolute/path archive=no links=yessrc=some/relative/path dest=/some/absolute/path checksum=yes times=nosrc=/tmp/helloworld dest=/var/www/helloword rsync_opts=--no-motd,--exclude=.git mode=pull 十、filesystem模块在块设备上创建文件系统 选项： dev：目标块设备 force：在一个已有文件系统 的设备上强制创建 fstype：文件系统的类型 opts：传递给mkfs命令的选项 示例：12ansible test -m filesystem -a 'fstype=ext2 dev=/dev/sdb1 force=yes'ansible test -m filesystem -a 'fstype=ext4 dev=/dev/sdb1 opts="-cc"' 十一、mount模块配置挂载点 选项： dump fstype：必选项，挂载文件的类型 name：必选项，挂载点 opts：传递给mount命令的参数 src：必选项，要挂载的文件 state：必选项 present：只处理fstab中的配置 absent：删除挂载点 mounted：自动创建挂载点并挂载之 umounted：卸载 示例：1234567name=/mnt/dvd src=/dev/sr0 fstype=iso9660 opts=ro state=presentname=/srv/disk src='LABEL=SOME_LABEL' state=presentname=/home src='UUID=b3e48f45-f933-4c8e-a700-22a159ec9077' opts=noatime state=presentansible test -a 'dd if=/dev/zero of=/disk.img bs=4k count=1024'ansible test -a 'losetup /dev/loop0 /disk.img'ansible test -m filesystem 'fstype=ext4 force=yes opts=-F dev=/dev/loop0'ansible test -m mount 'name=/mnt src=/dev/loop0 fstype=ext4 state=mounted opts=rw' 十二、get_url 模块该模块主要用于从http、ftp、https服务器上下载文件（类似于wget），主要有如下选项： sha256sum：下载完成后进行sha256 check； timeout：下载超时时间，默认10s url：下载的URL url_password、url_username：主要用于需要用户名密码进行验证的情况 use_proxy：是事使用代理，代理需事先在环境变更中定义 示例：12get_url: url=http://example.com/path/file.conf dest=/etc/foo.conf mode=0440get_url: url=http://example.com/path/file.conf dest=/etc/foo.conf sha256sum=b5bb9d8014a0f9b1d61e21e796d78dccdf1352f23cd32812f4850b878ae4944c 十三、unarchive模块用于解压文件，模块包含如下选项： copy：在解压文件之前，是否先将文件复制到远程主机，默认为yes。若为no，则要求目标主机上压缩包必须存在。 creates：指定一个文件名，当该文件存在时，则解压指令不执行 dest：远程主机上的一个路径，即文件解压的路径 grop：解压后的目录或文件的属组 list_files：如果为yes，则会列出压缩包里的文件，默认为no，2.0版本新增的选项 mode：解决后文件的权限 src：如果copy为yes，则需要指定压缩文件的源路径owner：解压后文件或目录的属主 示例如下：123- unarchive: src=foo.tgz dest=/var/lib/foo- unarchive: src=/tmp/foo.zip dest=/usr/local/bin copy=no- unarchive: src=https://example.com/example.zip dest=/usr/local/bin copy=no 本文出自 “无名小卒” 博客，请务必保留此出处http://breezey.blog.51cto.com/2400275/1555530]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>Ansible1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】Ansible3：ansible.cfg配置说明]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91Ansible3%EF%BC%9Aansible.cfg%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[描述Ansible默认安装好后有一个配置文件/etc/ansible/ansible.cfg，该配置文件中定义了ansible的主机的默认配置部分，如默认是否需要输入密码、是否开启sudo认证、action_plugins插件的位置、hosts主机组的位置、是否开启log功能、默认端口、key文件位置等等。 具体如下： 123456789101112131415161718192021222324252627282930313233[defaults]# some basic default values...hostfile = /etc/ansible/hosts \\指定默认hosts配置的位置# library_path = /usr/share/my_modules/remote_tmp = $HOME/.ansible/tmppattern = *forks = 5poll_interval = 15sudo_user = root \\远程sudo用户#ask_sudo_pass = True \\每次执行ansible命令是否询问ssh密码#ask_pass = True \\每次执行ansible命令时是否询问sudo密码transport = smartremote_port = 22module_lang = Cgathering = implicithost_key_checking = False \\关闭第一次使用ansible连接客户端是输入命令提示log_path = /var/log/ansible.log \\需要时可以自行添加。chown -R root:root ansible.logsystem_warnings = False \\关闭运行ansible时系统的提示信息，一般为提示升级# set plugin path directories here, separate with colonsaction_plugins = /usr/share/ansible_plugins/action_pluginscallback_plugins = /usr/share/ansible_plugins/callback_pluginsconnection_plugins = /usr/share/ansible_plugins/connection_pluginslookup_plugins = /usr/share/ansible_plugins/lookup_pluginsvars_plugins = /usr/share/ansible_plugins/vars_pluginsfilter_plugins = /usr/share/ansible_plugins/filter_pluginsfact_caching = memory[accelerate]accelerate_port = 5099accelerate_timeout = 30accelerate_connect_timeout = 5.0# The daemon timeout is measured in minutes. This time is measured# from the last activity to the accelerate daemon.accelerate_daemon_timeout = 30 如果在对之前未连接的主机进行连结时报错如下：123ansible test -a 'uptime' 192.168.1.1| FAILED =&gt;Using a SSH password instead of a key is not possible because HostKey checking is enabled and sshpass does not support this.Please add this host's fingerprint to your known_hosts file to manage this host. 192.168.1.2 | FAILED =&gt; Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this. Please add this host's fingerprint to your known_hosts file to manage this host. 是由于在本机的~/.ssh/known_hosts文件中并有fingerprint key串，ssh第一次连接的时候一般会提示输入yes 进行确认为将key字符串加入到 ~/.ssh/known_hosts 文件中。 方法1： 在进行ssh连接时，可以使用-o参数将StrictHostKeyChecking设置为no，使用ssh连接时避免首次连接时让输入yes/no部分的提示。通过查看ansible.cfg配置文件，发现如下行：1234567[ssh_connection]# ssh arguments to use# Leaving off ControlPersist will result in poor performance, so use# paramiko on older platforms rather than removing it#ssh_args = -o ControlMaster=auto -o ControlPersist=60s可以启用ssh_args 部分，使用下面的配置，避免上面出现的错误：ssh_args = -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking＝no 方法2： 在ansible.cfg配置文件中，也会找到如下配置：12# uncomment this to disable SSH key host checkinghost_key_checking = False 默认host_key_checking部分是注释的，通过找开该行的注释，同样也可以实现跳过ssh 首次连接提示验证部分。但在实际测试中，似乎并没有效果，建议使用方法1. 其他部分 默认ansible 执行的时候，并不会输出日志到文件，不过在ansible.cfg 配置文件中有如下行： log_path = /var/log/ansible.log默认log_path这行是注释的，打开该行的注释，所有的命令执行后，都会将日志输出到/var/log/ansible.log文件。 本文出自 “无名小卒” 博客，请务必保留此出处http://breezey.blog.51cto.com/2400275/1757635]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>Ansible1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】Ansible4：Ad-hoc与命令执行模块]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91Ansible4%EF%BC%9AAd-hoc%E4%B8%8E%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[描述Ad-Hoc 是指ansible下临时执行的一条命令，并且不需要保存的命令，对于复杂的命令会使用playbook。Ad-hoc的执行依赖于模块，ansible官方提供了大量的模块。 如：command、raw、shell、file、cron等，具体可以通过ansible-doc -l 进行查看 。可以使用ansible-doc -s module来查看某个模块的参数，也可以使用ansible-doc help module来查看该模块更详细的信息。 一、Ad-hoc1、命令说明 一个ad-hoc命令的执行，需要按以下格式进行执行： ansible 主机或组-m 模块名-a &apos;模块参数&apos; ansible参数 主机和组，是在/etc/ansible/hosts 里进行指定的部分，当然动态Inventory 使用的是脚本从外部应用里获取的主机；模块名，可以通过ansible-doc -l 查看目前安装的模块，默认不指定时，使用的是command模块，具体可以查看/etc/ansible/ansible.cfg 的“#module_name = command ” 部分，默认模块可以在该配置文件中进行修改；模块参数，可以通过 “ansible-doc -s 模块名” 查看具体的用法及后面的参数； ansible参数，可以通过ansible命令的帮助信息里查看到，这里有很多参数可以供选择，如是否需要输入密码、是否sudo等。 2、后台执行 当命令执行时间比较长时，也可以放到后台执行，使用-B、-P参数，如下：123ansible all -B 3600-a "/usr/bin/long_running_operation --do-stuff" #后台执行命令3600s，-B 表示后台执行的时间ansible all -m async_status -a "jid=123456789" #检查任务的状态ansible all -B 1800-P 60-a "/usr/bin/long_running_operation --do-stuff" #后台执行命令最大时间是1800s即30分钟，-P 每60s检查下状态，默认15s 二、命令执行模块命令执行模块包含如下 四个模块： command模块：该模块通过-a跟上要执行的命令可以直接执行，不过命令里如果有带有如下字符部分则执行不成功 “ “&lt;”, “&gt;”, “|”, “&amp;” ； shell 模块：用法基本和command一样，不过其是通过/bin/sh进行执行，所以shell 模块可以执行任何命令，就像在本机执行一样；raw模块：用法和shell 模块一样 ，其也可以执行任意命令，就像在本机执行一样； script模块：其是将管理端的shell 在被管理主机上执行，其原理是先将shell 复制到远程主机，再在远程主机上执行，原理类似于raw模块。 注：raw模块和comand、shell 模块不同的是其没有chdir、creates、removes参数，chdir参数的作用就是先切到chdir指定的目录后，再执行后面的命令，这在后面很多模块里都会有该参数 。 command模块包含如下选项： creates：一个文件名，当该文件存在，则该命令不执行 free_form：要执行的linux指令 chdir：在执行指令之前，先切换到该指定的目录 removes：一个文件名，当该文件不存在，则该选项不执行 executable：切换shell来执行指令，该执行路径必须是一个绝对路径 使用chdir的示例：123ansible 192.168.1.1 -m command -a 'chdir=/tmp/test.txt touch test.file'ansible 192.168.1.1 -m shell -a 'chdir=/tmp/test.txt touch test2.file'ansible 192.168.1.1 -m raw -a 'chdir=/tmp/text.txt touch test3.file' 三个命令都会返回执行成功的状态。不过实际上只有前两个文件会被创建成功。使用raw模块的执行的结果文件事实上也被正常创建了，不过不是在chdir指定的目录，而是在当前执行用户的家目录。 creates与removes示例： 12ansible 192.168.1.1 -a 'creates=/tmp/server.txt uptime' #当/tmp/server.txt文件存在时，则不执行uptime指令ansible 192.168.1.1 -a 'removes=/tmp/server.txt uptime' #当/tmp/server.txt文件不存在时，则不执行uptime指令 script模块示例：要执行的脚本文件script.sh内容如下：1234#/bin/bashifconfigdf -hT执行ansible指令：ansible 10.212.52.252 -m script -a 'script.sh' |egrep '&gt;&gt;|stdout' 本文出自 “无名小卒” 博客，请务必保留此出处http://breezey.blog.51cto.com/2400275/1757588]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>Ansible1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】Ansible1：简介与基本安装]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91Ansible1%EF%BC%9A%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[描述 Ansible是一个综合的强大的管理工具,他可以对多台主机安装操作系统,并为这些主机安装不同的应用程序,也可以通知指挥这些主机完成不同的任务.查看多台主机的各种信息的状态等,ansible都可以通过模块的方式来完成。 1、Ansible特性No agents：不需要再被管理节点上安装客户端，只要有sshd即可 No server：在服务端不需要启动任何服务，只需要执行命令就行 No additional PKI：由于不基于ssl，所以也不基于PKI工作 Modules in any language：基于模块工作，ansible拥有众多的模块 YAML：支持YAML语法 SSH by default：默认使用ssh控制各节点 2、Ansible的基本组件核心：ansible 核心模块（Core Modules）：这些都是ansible自带的模块 扩展模块（Custom Modules）：如果核心模块不足以完成某种功能，可以添加扩展模块 插件（Plugins）：完成模块功能的补充 剧本（Playbooks）：把需要完成的多个任务定义在剧本中 连接插件（Connectior Plugins）：ansible基于连接插件连接到各个主机上，虽然ansible是使用ssh连接到各个主机的，但是它还支持其他的连接方法，所以需要有连接插件 主机群（Host Inventory）：ansible在管理多台主机时，可以选择只对其中的一部分执行某些操作 3、Ansible工作机制Ansible 在管理节点将 Ansible 模块通过 SSH 协议（或者 Kerberos、LDAP）推送到被管理端执 行，执行完之后自动删除，可以使用 SVN 等来管理自定义模块及编排。 4、Ansible的安装Ansible的安装方式有很多种，常用的安装方法是基于yum或者源码，如果是基于yum安装，需要配置epel源，然后直接执行yum -y install ansible即可。源码安装配置如下： 解决依赖关系：1yum -y install python-jinja2 PyYAML python-paramiko python-babel python-crypto 下载ansible： 1wget https://github.com/ansible/ansible/archive/release1.6.1.zip 解压安装123456unzip release1.6.1cd ansible-release1.6.1python setup.py buildpython setup.py installmkdir /etc/ansiblecp -r examples/* /etc/ansible 本文出自 “无名小卒” 博客，请务必保留此出处http://breezey.blog.51cto.com/2400275/1757645]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>Ansible1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】Ansible2：主机清单]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91Ansible2%EF%BC%9A%E4%B8%BB%E6%9C%BA%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[描述Ansible 通过读取默认的主机清单配置/etc/ansible/hosts,可以同时连接到多个远程主机上执行任务, 默认路径可以通过修改 ansible.cfg 的 hostfile 参数指定路径。 一、Hosts and Groups（主机与组）对于/etc/ansible/hosts最简单的定义格式像下面： 1、简单的主机和组1234567mail.yanruogu.com[webservers]web1.yanruogu.comweb2.yanruogu.com [dbservers]db1.yanruogu.comdb2.yanruogu.com a、中括号中的名字代表组名，可以根据自己的需求将庞大的主机分成具有标识的组，如上面分了两个组webservers和dbservers组； b、主机(hosts)部分可以使用域名、主机名、IP地址表示；当然使用前两者时，也需要主机能反解析到相应的IP地址，一般此类配置中多使用IP地址； 2、端口与别名如果某些主机的SSH运行在自定义的端口上，ansible使用Paramiko进行ssh连接时，不会使用你SSH配置文件中列出的端口，但是如果修改ansible使用openssh进行ssh连接时将会使用： 192.168.1.1:3091 假如你想要为某些静态IP设置一些别名，可以这样做：1web1 ansible_ssh_port = 3333 ansible_ssh_host = 192.168.1.2 上面的 web1别名就指代了IP为192.168.1.2，ssh连接端口为3333的主机。 3、指定主机范围1234[webservers]www[01:50].yanruogu.com[databases]db-[a:f].yanruogu.com 上面指定了从web1到web50，webservers组共计50台主机；databases组有db-a到db-f共6台主机。 4、使用主机变量以下是Hosts部分中经常用到的变量部分：1234567891011ansible_ssh_host #用于指定被管理的主机的真实IPansible_ssh_port #用于指定连接到被管理主机的ssh端口号，默认是22ansible_ssh_user #ssh连接时默认使用的用户名ansible_ssh_pass #ssh连接时的密码ansible_sudo_pass #使用sudo连接用户时的密码ansible_sudo_exec #如果sudo命令不在默认路径，需要指定sudo命令路径ansible_ssh_private_key_file #秘钥文件路径，秘钥文件如果不想使用ssh-agent管理时可以使用此选项ansible_shell_type #目标系统的shell的类型，默认shansible_connection #SSH 连接的类型： local , ssh , paramiko，在 ansible 1.2 之前默认是 paramiko ，后来智能选择，优先使用基于 ControlPersist 的 ssh （支持的前提）ansible_python_interpreter #用来指定python解释器的路径，默认为/usr/bin/python 同样可以指定ruby 、perl 的路径ansible_*_interpreter #其他解释器路径，用法与ansible_python_interpreter类似，这里"*"可以是ruby或才perl等其他语言 示例如下：1234[test]192.168.1.1 ansible_ssh_user=root ansible_ssh_pass='P@ssw0rd'192.168.1.2 ansible_ssh_user=breeze ansible_ssh_pass='123456'192.168.1.3 ansible_ssh_user=bernie ansible_ssh_port=3055 ansible_ssh_pass='456789' 上面的示例中指定了三台主机，三台主机的用密码分别是 P@ssw0rd、123456、45789，指定的ssh连接的用户名分别为root、breeze、bernie，ssh 端口分别为22、22、3055 ，这样在ansible命令执行的时候就不用再指令用户和密码等了。 5、组内变量变量也可以通过组名，应用到组内的所有成员：123456[test]host1host2[test:vars]ntp_server=192.168.1.10proxy=192.168.1.20 上面test组中包含两台主机，通过对test组指定vars变更，相应的host1和host2相当于相应的指定了ntp_server和proxy变量参数值 。 6、组的包含与组内变量123456789101112131415[wuhan]web1web2[suizhou]web4web3[hubei:children]wuhansuizhou[hubei:vars]ntp_server=192.168.1.10zabbix_server=192.168.1.10[china:children]hubeihunan 上面的示例中，指定了武汉组有web1、web2；随州组有web3、web4主机；又指定了一个湖北组，同时包含武汉和随州；同时为该组内的所有主机指定了2个vars变量。设定了一个组中国组，包含湖北、湖南。 注：vars变量在ansible ad-hoc部分中基本用不到，主要用在ansible-playbook中。 二、Patterns（主机与组正则匹配部分）把Patterns 直接理解为正则实际是不完全准确的，正常的理解为patterns意味着在ansible中管理哪些主机，也可以理解为，要与哪台主机进行通信。在探讨这个问题之前我们先看下ansible的用法：1ansible &lt;pattern_goes_here&gt; -m &lt;module_name&gt; -a &lt;arguments&gt; 直接上一个示例：1ansible webservers -m service -a "name=httpd state=restarted" 这里是对webservers 组或主机重启httpd服务 ，其中webservers 就是Pattern部分。而之所以上面说Pattern（模式）可以理解为正则，主要针对下面经常用到的用法而言的。 1、表示所有的主机可以使用all 或 *2、通配符与逻辑或利用通配符还可以指定一组具有规则特征的主机或主机名，冒号表示or－－－逻辑或1234web1.yanruogu.comweb1.yanruogu.com:web2.yanruogu.com192.168.1.1192.168.1.* 当然，这里的*通配符也可以用在前面，如：12345*.yanruogu.com*.com webservers1[0] #表示匹配 webservers1 组的第 1 个主机 webservers1[0:25] #表示匹配 webservers1 组的第 1 个到第 25 个主机（官网文档是":"表示范围，测试发现应该使用"-",注意不要和匹配多个主机组混淆） 上面的用法，在多个组之间同样适用 ，如：12webserverswebservers:dbservers #表示两个组中所有的主机 3、逻辑非与逻辑and非的表达式，如，目标主机必须在组webservers但不在phoenix组中 webserver:!phoenix 交集的表达式，如，目标主机必须即在组webservers中又在组staging中 webservers:&amp;staging 一个更复杂的示例： webserver:dbservers:&amp;staging:!phoenix 上面这个复杂的表达式最后表示的目标主机必须满足：在webservers或者dbservers组中，必须还存在于staging组中，但是不在phoenix组中 。 4、混合高级用法*.yanruogu.com:*.org 还可以在开头的地方使用”~”，用来表示这是一个正则表达式: ~(web|db).*\.yanruogu\.com 给两个ansible-playbook中具体可能用的用法： a、在ansible-palybook命令中，你也可以使用变量来组成这样的表达式，但是你必须使用“-e”的选项来指定这个表达式（通常我们不这样用）： ansible-palybook -e webservers:!{{excluded}}:&amp;{{required}} b、在ansible和ansible-playbook中，还可以通过一个参数”–limit”来明确指定排除某些主机或组： ansible-playbook site.yml --limit datacenter2 c、从Ansible1.2开始，如果想排除一个文件中的主机可以使用”@”： ansible-playbook site.yml --limit @retry_hosts.txt 本文出自 “无名小卒” 博客，请务必保留此出处http://breezey.blog.51cto.com/2400275/1757643]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>Ansible1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[威斯敏斯特大教理问答]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E5%A8%81%E6%96%AF%E6%95%8F%E6%96%AF%E7%89%B9%E5%A4%A7%E6%95%99%E7%90%86%E9%97%AE%E7%AD%94%2F</url>
    <content type="text"><![CDATA[导读威斯敏斯德会议在制定《威斯敏斯德信条》的同时，也起草、通过了两个教理问答.大教理问答于1648年7月完毕.斯卡福认为，根据当时欧洲大陆改革宗教会的习惯，大教理问答用于在教会讲坛上公开讲授，而小教理问答则用于在家庭里教育孩子. [1]陶论斯认为：“《大教理问答》主要用作牧师在主日教导改革宗教义时的参考指南.” [2]可惜，目前哪怕是在欧美教会中，最盛行的也是《威斯敏斯德小教理问答》，用于公共教育的大教理问答反倒很少有人过问.因此，关于小教理问答的诠释和讲道比比皆是，而关于大教理问答的，目前从图书馆中能够找到的只有两本，一是1855年版的托马斯?瑞格理（Thomas Ridgely，1667－1734）所著的多达1303页的《大教理问答释义》，二是2002年版的曾经到中国大陆宣教的魏司道博士所著的589页的注释.根据威斯敏斯德会议的记录，《大教理问答》的制定先于《小教理问答》，其中的每个问答都是在会议上逐个讨论通过的.主要作者是安东尼·塔可尼博士（Anthony Tuckney），他是当时剑桥大学的副校长、神学教授.这个教理问答是对信条的解释和补充，特别是在基督徒伦理方面，其详尽性超过宗教改革时期其他任何改革宗信条，是改革宗神学解释十诫的经典之作.解释教会史学家斯卡福认为：“在制定的艺术上，大教理问答是一个杰作，胜过其他任何类似的作品，并且是以当时普遍盛行的系统神学的形式阐明各项教义的.”[3]大教理问答是为那些信心上比较成熟的人预备的，在教义界定上更精确，更全面.《小教理问答》更多地集中于教导初信者明白基本要道，注重个人的层面；《大教理问答》主要是为比较成熟的基督徒预备的，更多地注重基督徒生活的群体性方面，多处谈及教会，都是《小教理问答》不曾涉及的.对于在教义和伦理方面都非常贫乏的中国教会而言，《大教理问答》可以说是一个百科全书式的指南.《大教理问答》与《小教理问答》架构相同，也分为三个部分.第一部分为序言部分，从第1问至第5问，论及人生的首要目的、上帝的存在、上帝的圣言.第二部分论及人当信什么，从第6问至第90问.第三部分论及人当怎样行，从第91问至最后196问.正文点击如下： 1：人生最重要、最崇高的目的是什么？回答：人生最重要、最崇高的目的就是荣耀上帝（罗11：36；林前10：31），完全以他为乐，直到永远（诗73：24－28；约17：21－23）。 2：如何显明有上帝存在呢？回答：人心中的本性之光，和上帝的作为，都在宣告上帝的存在（罗1：19，20；诗19：1－3；徒17：18）；但是，人要得救，惟独上帝的话和圣灵才能充分、有效地把他启示给人（林前2：9，10；提后3：15－17；赛59：21）。 3：上帝的话是什么？回答：新旧约圣经就是上帝的话（提后3：16；彼后1：19－21），是信仰与顺服的唯一准则（弗2：20；启22：18，19；赛8：20；路16：29，31；加1：8，9；提后3：15，16）。 4：为什么说圣经就是上帝的话呢？回答：圣经体裁的庄严（何8：12；林前2：6，7，13；诗119：18，129），教理的纯正（诗12：6；诗119：140），各部的契合（徒10：43；26：22），全体的范围（全归荣耀于上帝）（罗3：19，27）；使罪人知罪、归正，使信徒得安慰、得造就，以致最终得救的亮光和力量（徒28：28；来4：12；雅1：18；诗19：7－9；罗15：4；徒20：32），都证明圣经是上帝的话；但是，惟独上帝的圣灵，藉着并同着圣经在人心中的见证，才能完全使人信服圣经确实是上帝的话（约16：13，14；约壹2：20，27；约20：31）。 5：圣经对人主要的教训是什么？回答：圣经对人主要的教训是：人对上帝当信什么，以及上帝要人当尽什么责任（提后1：13）。 6：圣经显明上帝的什么方面？回答：圣经显明：上帝是怎样的上帝（来11：6），上帝的位格（约贰5：17），上帝的预旨（徒15：14－15，18）及其施行（徒4：27－28）。 7：上帝是怎样的上帝？回答：上帝是个灵（约4：24），他的生命（出3：14；伯11：7－9）、荣耀（徒7：2）、可赞（提前6：15）和完全（太5：48）都是无限的；上帝自足（创17：1）、永恒（诗90：2）、永不改变（玛3：6；雅1：17），不可测度（王上8：27），无所不在（诗139：1－13）、无所不能（启4：8）、无所不知（来4：13；诗147：5），极其智慧（罗16：27），极其圣洁（赛6：3；启15：4），极其公义（申32：4），极其怜悯，长久忍耐，有丰盛的恩慈和信实（出34：6）。 8：上帝是独一的吗？回答：上帝是独一无二，又真又活的（申6：4；林前8：4，6；耶10：10）。 9：上帝共有几个位格？回答：上帝共有三个位格：圣父，圣子，圣灵；这三个位格是同一信实、永恒的上帝，同体，同权，同荣；但各有不同的特性（约壹5：7；太3：16－17；28：19；林后13：14；约10：30）。 10：上帝的这三个位格各有什么特性？回答：圣父生圣子（来1：5－6，8），圣子由圣父受生（约1：14，18），圣灵由圣父与圣子自永世发出（约15：26；加4：6）。 11：如何证明圣子和圣灵与圣父同为上帝？回答：圣经把惟独属于上帝的名字（赛6：3，5，8；约12：41；徒28：25；约壹5：20；徒5：3－4）、属性（约1：1；赛9：6；约2：24－25；林前2：10－11）、作为（西1：16；创1：2）和敬拜（太28：19；林后13：14），归于圣子和圣灵，证明他们与圣父同为上帝。 12：上帝的预旨是什么？回答：上帝的预旨乃是他旨意的智慧、自由、圣洁的行动计划（弗1：11；罗11：33；9：14－15，18），即他从永世便为他自己的荣耀，不变地预定了历史中要发生的一切（弗1：4，11；罗9：22－23；诗33：11），特别是关于天使和人类之事。 13：关于天使和人类，上帝特别的预旨是什么？回答：上帝出于他自己的美意，为了使他荣耀的恩典得着称赞，在日期满足的时候，就藉着他永恒不变的预旨，拣选了一部分天使得荣耀（提前5：21）；并在基督里，拣选了一部分人得永生，且预定了得永生的方式（弗1：4－6；帖后2：13－14）；并因着他的主权，和不可测度的旨意（他随己意施与、收回恩典），置其余的人于不顾，预定他们受羞辱和震怒，为他们自身的罪而受苦，使他荣耀的公义得着称赞（罗9：17－18，21－22；太11：25－26；提后2：20；犹4；彼前2：8）。 14：上帝怎样实施他的预旨？回答：上帝根据他无谬的预知、自由且不变的旨意，在创造和救赎之工中，实施他的预旨（弗1：11）。 15：创造之工是什么？回答：创造之工就是：起初，上帝用他权能的话，为他自己，在六日之内，从无中创造了世界，及其中的万物，并且都是很好的（创1；来11：3；箴16：4）。 16：上帝怎样造天使？回答：上帝创造了所有的天使（西1：16），乃是灵体（诗104：4）、不朽（太22：30）、圣洁（太25：31）、卓有知识（撒下14：17；太24：36）、大有权能（帖后1：7），来执行上帝的吩咐，赞美他的圣名（诗103：20－21），但天使能够改变（彼后2：4）。 17：上帝怎样造人？回答：上帝在创造了其它各样受造物之后，就造男造女（创1：27）；用地上的泥土造了男人的身体（创2：7），用男人的肋骨造了女人的身体（创2：22），赋予他们活的、理性的、不朽的灵魂（创2：7；伯35：11；传12：7；太10：28；路23：43）；按他自己的形像造了他们（创1：27；），有知识（西3：10）、公义和圣洁（弗4：24）；把上帝的律法刻在他们的心中（罗2：14－15），并赐给他们遵行的力量（传7：29），能够治理万物（创1：28）；但也能够堕落（创3：6；传7：29）。 18：上帝的护理之工是什么？回答：上帝的护理之工是：他极其圣洁地（诗145：17）、智慧地（诗104：24；赛28：29）、有权能地，继续保守（来1：3），并治理（诗103：19）他所创造的万有；整顿它们，以及它们所有的行动（太10：29－31；创45：7），使他自己得荣耀（罗11：36；赛63：14）。 19：上帝对天使的护理是什么？回答：上帝藉其护理，容许某些天使，故意地、不可挽回地堕落在罪和毁灭之中（犹6；彼后2：4；来2：16；约8：44），并对他们所有的罪加以限制和整顿，使他自己得荣耀（伯1：12；太8：31）；使其余的天使在圣洁和喜乐之中得以坚固（提前5：21；可8：38；来12：22）；随他自己的美意使用他们（诗104：4），施行他的权柄、怜悯和公义（王下19：35；来1：14）。 20：上帝对起初受造之人有什么护理？回答：上帝对起初受造之人的护理是：把他安置在乐园里，吩咐他修理看守，赐给他吃地上各样果子的自由（创2：8，15－16）；把万物都置于他的治理之下（创1：28），并设立婚姻帮助他（创2：18）；为他提供与自身的交通（创1：26－29；创3：8）；制定安息日（创2：3）；与他立生命之约，以个人的、完全的、持续的顺服为条件（加3：12；罗10：5），生命树就是此约的信物（创2：9）；并用死的苦楚，禁止他吃分别善恶树上的果子（创2：17）。 21：我们的始祖守住了起初受造的状况吗？回答：我们的始祖既有意志的自由，因着撒但的诱惑，吃了禁果，违背了上帝的诫命；因而从起初受造的天真状况中堕落了（创3：6－8，13；传7：29；林后11：3）。 22：全人类都在亚当的首次犯罪中堕落了吗？回答：上帝与亚当立约，亚当作为众人的代表，不仅是为他，也是为他的后裔，所以那藉通常生殖由他传下的全人类（徒17：26），都在他里面犯了罪，在他的首次犯罪中与他一同堕落了（创2：16－17；罗5：12－20；林前15：21－22）。 23：堕落使人类处于什么状况之中？回答：堕落使人处于罪恶和愁苦的状况之中（罗5：12；3：23）。 24：罪是什么？回答：罪就是不遵行或违背上帝的一切律法。因为上帝赐下律法，是作为有理性的受造物的标准（约壹3：4；加3：10，12）。 25：人堕落后所处的那种有罪的状况是什么？回答：人堕落后所处的那种有罪的状况是：亚当第一次犯罪所负的罪债（罗5：12，19），受造时公义的丧失，和整个人性的败坏，由此而对一切属灵的善彻底嫌恶、无能为力，而且加以抵挡，一心倾向各样邪恶，并持续如此（罗3：10－19；弗2：1－3；罗5：6；8：7－8；创6：5）；这就是通常所说的原罪，并由此生发各样的本罪（雅1：14－15；太15：19）。 26：原罪如何从我们的始祖传递到他们的后裔？回答：原罪从我们的始祖传递到他们的后裔，是藉着自然的生殖，因此，所有以此方式从他们生出的人，都是在罪中受孕、出生的（诗51：5；伯14：4；15：14；约3：6）。 27：堕落给人带来什么愁苦？回答：堕落使人类丧失了与上帝的交通（创3：8，10，24），招致祂的不悦和咒诅；因此，我们生来就是可怒之子（弗2：2－3）、撒但的奴仆（提后2：26），当受今生和来世的一切惩罚（创2：17；哀3：39；罗6：23；太25：41，46；犹7）。 28：罪在今生的惩罚是什么？回答：罪在今生的惩罚有内在的：如理性的盲目（弗4：18），被弃的感觉（罗1：28），强烈的幻想（帖后2：11），心灵的刚硬（罗2：5），良知的恐怖（赛33：14；创4：13；太27：4），和情感的卑劣（罗1：26）。又有外在的：如上帝因我们的缘故咒诅世界（创3：17），有各样的邪恶临到我们的身体、名誉、财产、关系和职业（申28：15－18），还有死亡（罗6：21，23）。 29：罪在来生的惩罚是什么？回答：罪在来生的惩罚是，与上帝美好的同在永远隔绝，灵魂和身体遭受极难忍受的痛苦，从不止息，在地狱的烈火中直到永永远远（帖后1：9；可9：43－44，46，48；路16：24）。 30：上帝任凭全人类在罪恶和愁苦中灭亡吗？回答：不是。全人类都落入罪恶和愁苦的状态（帖前5：9），是因为违背第一个约，即通常所说的工作之约（加3：10，12）；但上帝并没有任凭他们在这一状态中灭亡；而是完全出于他的大爱和怜悯，藉着第二个约，即通常所说的恩典之约，把他的选民从中救拔出来，带他们进入得救的状态（多3：4－7；加3：21；罗3：20－22）。 31：上帝与谁立此恩典之约呢？回答：这恩典之约是与第二个亚当基督立的，并在他里面与作为其后裔的所有选民立的（加3：16；罗5：15；赛53：10－11）。 32：上帝的恩典是如何在第二个恩约中显明的？回答：上帝的恩典显明在第二个恩约之中，在此恩约里白白地向罪人提供了一位中保（创3：15；赛42：6；约6：27），靠他得生命和救赎（约壹5：11－12）；并要求以信心作为他们在他里面连结的条件（约3：16；1：12），应许并赐下圣灵（箴1：23）给他的选民，在他们心中生成这种信心（林后4：13），并赐下其它救赎的恩典（加5：22－23）；使他们能够虔敬顺服（节36：27），作为真信心（雅2：18，22）和对上帝感恩（林后5：14－15）的凭据，作为祂所命定的他们的得救之路（弗2：18）。 33：这恩典之约始终是以同一种方式施行吗？回答：这恩典之约并非始终是以同一种方式施行，在旧约之下的施行与在新约之下的施行并不相同（林后3：6－9）。 34：在旧约之下，这恩典之约是如何施行的？回答：在旧约之下，这恩典之约是藉着应许（罗15：8）、预言（徒3：20，24）、献祭（来10：1）、割礼（罗4：11）、逾越节（林前5：7）及其它预表和律例而施行的。这些都是以后来临的基督的预表，在那时足够建造选民的信心。他们是在应许的弥赛亚里（来8，9，10；11：13），并因着他而得永远的救赎，过犯得以完全赦免（加3：7－9，14）。 35：在新约之下，这恩典之约是如何施行的？回答：在新约之下，实体基督显明出来，这同一恩典之约过去是、仍然是藉着圣言的传讲（可16：15）、洗礼（太28：19－20）和圣餐（林前11：23－25）的施行而施行的；其中，恩典和救赎更丰盛、更显明、更有果效地向列国万民发出（林后3：6－9；来8：6，10－11；太28：19）。 36：谁是这恩典之约的中保？回答：这恩典之约的唯一中保就是主耶稣基督（提前2：5），他是上帝的永恒之子，与父同体同权（约1：1，14；10：30；腓2：6），及至时候满足，降世为人（加4：4），曾经是且继续是上帝和人，两性全然不同，存于一个位格之中，直到永远（路1：35；罗9：5；西2：9；来7：24－25）。 37：上帝之子基督是如何降世为人的？回答：上帝之子基督降世为人，是自己取了人实在的身体，和理性的灵魂，藉着圣灵的大能在童贞女马利亚腹中成孕，由她取了人性，从她出生，只是没有罪。 38：为什么这一中保必须是上帝呢？回答：这一中保必须是上帝，如此他才能维系并保持其人性，不至于在上帝的无限愤怒和死亡的权势之下沉沦（徒2：24－25；罗1：4；4：25；来9：14）；使他的受苦、顺服和代祷有价值和果效（徒20：28；来9：14；7：25－28）；满足上帝的公义（罗3：24－26），获得他的恩宠（弗1：6；太3：17），赎买一个特定的民族（多2：13－14），把他的灵赐给他们（加4：6），征服他们所有的仇敌（路1：68－69，71，74），使他们永远得救（来5：8－9；9：11－15）。 39：为什么这一中保必须是人呢？回答：这一中保必须是人，如此他才能增进我们的性情（来2：16），顺服律法（加4：4），在我们的性情中为我们受苦，并为我们代祷（来2：14；7：24－25），对我们的软弱有同样的感受（来4：15）；并使我们可以得儿子的名分（加4：5），得安慰，坦然无惧地来到施恩宝座前（来4：16）。 40：为什么这一中保必须同时是上帝与人，且在一个位格中呢？回答：这一中保，既然要使上帝与人和好，就必须自己同时是上帝与人，且在一个位格中，使每一性的正确工作，都可作为全人的工作为我们而被上帝悦纳（太1：21，23；3：17；来9：14），并且成为我们的依靠（彼前2：6）。 41：为什么我们的中保被称为耶稣呢？回答：我们的中保之所以被称为耶稣，是因为他要把他自己的百姓从罪中救拔出来（太1：21）。 42：为什么我们的中保被称为基督呢？回答：我们的中保之所以被称为基督，是因为他受圣灵无限量地膏抹（约3：34；诗45：7）；并分别出来，具备各样的权柄和能力（约6：27；太28：18－20），为其教会（腓2：6－11）执行先知（徒3：21－22；路4：18，21）、祭司（来5：5－7；4：14－15）与君王（诗2：6，太21：5；赛9：6－7）的职份，他处于升高和降卑中都是如此。 43：基督怎样履行先知的职份？回答：基督藉着他的圣灵和圣言（彼前1：10－12），在各个时代，以各种不同的施行方式（来1：1－2），在关乎他们的造就和救赎的一切事宜上（徒20：32；弗4：11－13；约20：31），向教会启示（约1：18）上帝全备的旨意（约15：15），如此便履行了先知的职份。 44：基督如何履行祭司的职份？回答：基督为他百姓的罪，将自己作为无瑕疵的祭品，一次向上帝献上（来9：14，28），使上帝与他们和好（来2：17），并为他们继续代祷（来7：25），如此就履行了祭司的职份。 45：基督如何履行君王的职份？回答：基督从世界中召出一个民族归他自己（徒15：14－16；赛55：4－5；创49：10；诗110：3），赐给他们圣职人员（弗4：11－12；林前12：28）、律法（赛33：22）和裁决，他以此有形的方式治理他们（太18：17－18；林前5：4－5）；把救赎恩典赐给选民（徒5：31），报偿他们的顺服（启22：12；2：10），纠正他们的过犯（启3：19），在各样的试探和苦难中保守并支持他们（撒63：9），抑制并战胜他们所有的仇敌（林前15：25；诗110：1－2），为他自己的荣耀（罗14：10－11），并为他们的益处（罗8：28），大有权能地吩咐万有；并报应其余那些不认识上帝，不顺服福音的人（帖后1：8－9；诗2：8－9）；如此就履行了君王的职份。 46：基督的降卑在于什么？回答：基督的降卑在于他为了我们的缘故，倒空自己的荣耀，取了奴仆的样式，受孕、降生、生活、受死，以及死后，直到复活，都处于卑微的状况中（腓2：6－8；路1：31；林后8：9；徒2：24）。 47：在他的受孕和降生中，基督是如何谦卑自己的？回答：基督在他的受孕和降生中谦卑自己，是在于他身为上帝的永恒之子，从父的怀中，在时候满足的时候，甘愿成为人子，由一位卑微的女人生成，且从她而生；其所处的各样环境，比一般的屈尊更甚（约1：14，18；加4：4；路2：7）。 48：在他的生活中，基督是如何谦卑自己的？回答：基督在他的生活中谦卑自己，是在于他自己顺服律法（加4：4），完美地成全律法（太5：17；罗5：19）；并且面对世上的各样侮辱（诗22：6；来12：2－3），撒但的试探（太4：1－12；路4：13），自己肉身的软弱，这些或是常见于人的性情，或是特别与他的降卑状态相伴（来2：17－18；4：15；赛52：13－14）。 49：在他的受死中，基督是如何谦卑自己的？回答：基督在他的受死中谦卑自己，是在于为犹大背叛（太27：4），被门徒离弃（太26：56），受世人的嘲弄和弃绝（赛53：2－3），被彼拉多定罪，遭执法人员的折磨（太27：26－50；约19：34）；为死亡的恐怖、黑暗的权势所苦，承受上帝的愤怒（路22：44；太27：46），为罪舍己，作为奉献（赛53：10），忍受十字架上痛苦的、羞耻的、受咒诅的死亡（腓2：8；来12：2；加3：13）。 50：基督死后的降卑在于什么？回答：基督死后的降卑是在于被埋藏（林前15：3－4），持续处于死亡的状态中，处在死亡的权势之下，直到第三日（诗16：10；徒2：24－27，31；罗6：9；太12：40）；用另外的词汇表达，就是他降在阴间。 51：基督的升高在于什么？回答：基督的升高在于他的复活（林前15：4）、升天（可16：19），坐在父的右边（弗1：20），将来再临，审判世界（徒1：11；17：31）。 52：在他的复活中，基督是如何升高的？回答：基督在他的复活中升高，在于他未在死亡中见朽坏，对他来说，这是不可能的（徒2：24，27），基督以他受苦时同样的身体，同样的属性（路24：39），但是没有必死性，其它凡人共有的软弱都有，真的与他的灵魂联合（罗6：9；启1：18），他第三天靠他自己的权柄从死里复活（约10：18）；因此，他宣告自己是上帝的儿子（罗1：4），满足了上帝的公义（罗8：34），征服了死亡和死亡权势的执掌者（来2：14），成为活人和死人的主（罗14：9）：他作为公仆（林前15：21－22），教会的元首（弗2：1，22－23；西2：12），行这些事，目的是为了使他们称义（罗4：25），在恩典中长进（弗2：1，5－6；西2：12），支持他们抵挡仇敌（林前15：25－27），并保证他们在末日的时候从死里复活（林前15：20）。 53：在他的升天中，基督是如何升高的？回答：基督在他的升天中升高，在于他复活之后，向门徒显现，并同他们说话，谈及上帝国度之事（徒1：2－3），赐给他们向列国传福音的使命（太28：19－20），在复活四十天之后，他以我们的性情，作为我们的元首（来6：20），胜过仇敌（弗4：8），在众目注视之下升上高天，为人领受诸多的恩赐（徒1：9－11；弗4：10；诗68：18），把我们的情感提升到彼处（西3：1－2），并为我们预备地方（约14：3），他自己也在那里，直到世界末日，他再次降临（徒3：21）。 54：基督坐在父的右边，他是如何在此事中升高的？回答：基督坐在父的右边，他的升高是在于作为神人，他臻达父上帝至高的恩宠（腓2：9），满有喜乐（徒2：28；诗16：11）、荣耀（约17：5），和胜过天上地上的一切的权柄（弗1：22；彼前3：22）；聚集并护卫他的教会，征服他们的仇敌；用各样的恩赐和恩典（弗4：10－12；诗110：1），装备他的仆人和子民，并为他们代祷（罗8：34）。 55：基督是如何代祷的？回答：基督为我们代祷，在于他以我们的性情，始终不渝地出现在天父面前（来9：12，24），因着他在地上顺服与献祭的功劳（来1：3），宣告他的旨意是要把这功劳应用到所有的信徒身上（约3：16；17：9，20，24）；回击一切对他们的控告（罗8：33－34），为他们达成良心的平安，尽管他们天天有失败之处（罗5：1－2；约壹2：1－2），仍使他们坦然无惧地来到施恩宝座前（来4：16），并使他们本人（弗1：6）和服事都蒙悦纳（彼前2：5）。 56：基督将来再临，审判世界，他是如何在此事中升高的？回答：基督将来再临，审判世界，他在此事中升高在于：他虽受到不义的审判，并被恶人定罪（徒3：14－15），却要在末日之时，大有权能地再临（太24：30），完全彰显他自己和父的荣耀，与千万的圣天使（路9：26；太25：31），在呼叫声中，随着天使长的声音，与上帝的角声（帖前4：16），以公义审判这个世界（徒17：31）。 57：藉其中保，基督促成了什么惠益？回答：藉其中保，基督促成了救赎（来9：12），以及其它所有的恩典之约的惠益（林后1：20）。 58：我们怎能分享基督所买来的惠益呢？回答：我们分享基督所买来的惠益，乃是藉着圣灵上帝特别的工作（多3：5－6），把这些惠益赐给我们（约1：11－12）。 59：谁与基督的救赎有份呢？回答：救赎是确定无疑地赐给，并有效地传递给所有基督买赎的人（弗1：13－14；约6：37，39；10：15－16）；乃至时候满足，圣灵就使他们能够照着福音归信基督（弗2：8；林后4：13）。 60：那些从未听过福音，既不认识，也不相信基督耶稣的人，根据自然之光生活，能够由此得救吗？回答：那些从未听过福音（罗10：14），因此既不认识基督耶稣（帖后1：8－9；弗2：12；约1：10－12），也不相信他的人，即使他们殷勤地根据自然之光（林前1：20－24），或他们所认信的宗教诫命，来调整自己的生活（约4：22；罗9：31－32；腓3：4－9），也不会得救（约8：24；可16：16）；耶稣之外，别无救赎（徒4：12），惟独他是教会全体的救主（弗5：23）。 61：那些听过福音，参加教会生活的人，是不是都得救了？回答：并不是所有听过福音，参加有形教会生活的人，都得救了；惟有那些无形教会的真成员才是得救的（约12：38－40；罗9：6；太22：14；太7：21；罗11：7）。 62：有形教会是什么？回答：有形教会就是由世上各个时代、各个地方认信真宗教的人（林前1：2；12：13；罗15：9－12；启7：9；诗2：8；诗22：27－31；诗45：17；太28：19-20；赛59：21），和他们的子女所（林前7：14；徒2：39；罗11：16；创17：7）组成的一个群体。 63：有形教会有什么特权？回答：有形教会的特权是：处于上帝的特别看顾和护理之下（赛4：5－6；提前4：10）；尽管有各种仇敌的抵挡，仍在各个时代中得蒙保守（诗115：1－2，9；赛31：4－5；亚12：2－4，8－9）；享有圣徒的交通，救赎的一般工具（徒2：39，42），耶稣在福音事奉中向其所有成员发出的恩典的招请，见证一切信他的人都会得救（诗147：19－20；罗9：4；弗4：11－12；可16：15－16），来到他面前的人，都不会被丢弃（约6：37）。 64：无形教会是什么？回答：无形教会包括过去、现在、未来，在元首基督名下聚集归一的所有选民（弗1：10，22－23；约10：16；11：52）。 65：藉着基督，无形教会的成员享有什么特殊的恩惠？回答：藉着基督，无形教会的成员在恩典与荣耀里享有与他的合一和交通（约17：21；弗2：5－6；约17：24）。 66：选民所享有与基督的合一是什么？回答：选民所享有的与基督的合一，是上帝恩典的作为（弗1：22，2：6－8），他们由此虽是属灵地、神秘地，却是真正地、不可分离地，与他们的元首和丈夫基督联合（林前6：17；约10：28；弗5：23，30）；这是在他们有效的恩召里成就的（彼前5：10；林前1：9）。 67：什么是有效的恩召？回答：有效的恩召是上帝的大能和恩典的作为（约5：25；弗1：18－20；提后1：8－9），他出于对其选民白白和特别的爱，并不是因为他们身上有什么促使他行动的东西（多3：4－5；弗2：4－5，7－9；罗9：11），在他所悦纳的日子，藉着他的圣言和圣灵，邀请并吸引他们归向基督耶稣（林后5：20；6：1－2；约6：44；帖后2：13－14）；救赎性地启迪他们的心思（徒26：18；林前2：10，12），更新并大有权能地决定他们的意志（结11：19；36：26－27；约6：45），使得已经死在罪恶之中的他们变得甘心乐意，能够自由爽快地回应他的呼召，领受其中所提供、传递的恩典（弗2：5；腓2：13；申30：6）。 68：惟独选民得蒙有效恩召吗回答：所有的选民，而且惟独他们，得蒙有效的恩召（徒13：48）；尽管其他人或许，也经常是，藉着上帝圣言的服事，蒙受外部的呼召（太22：14），并且有圣灵的普通运行（太7：22；13：20－21；来6：4－6）；但他们故意忽略、轻视向他们提供的恩典，就被公义地弃置于他们自己的不信之中，绝不会真正地归向耶稣基督（约12：38－40；徒28：25－27；约6：64－65；诗81：11－12）。 69：无形教会的成员在恩典里所享有的与基督的交通是什么？回答：无形教会的成员在恩典里所享有的与基督的交通，是在于与他中保的功劳有份，在称义（罗8：30），得儿子的名分（弗1：5），成圣，以及今生的一切事宜上，都显明他们与基督的合一（林前1：30）。 70：称义是什么？回答：称义是上帝的作为，他白白地把恩典赐予罪人（罗3：22，24－25；4：5），由此赦免他们所有的罪，接纳他们，并在他的眼中算他们为义（林后5：19，21；罗3：22，24－25，27－28）；并不是因为他们自己有什么，也不是因为他们作了什么（多3：5，7；弗1：7），而是惟独因为基督的完美的顺服和完全的补偿，由上帝归算在他们的身上（罗5：17－19；罗4：6－8），且是惟独藉着信心才能领受的（徒10：43；加2：16；腓3：9）。 71：为什么说称义是上帝白白恩典的作为呢？回答：尽管基督藉其顺服和受死，确实代表那些被称义之人，对上帝的公义，作出了适当的、真正的、完全的补偿（）；但是，因为上帝是从一个保证人接受补偿，这也是他可以要求他们的，而且上帝确实提供了这一保证人，就是他的独生子（提前2：5－6；来10：10；太20：28；但9：24，26；赛53：4－6，10－12；来7：22；罗8：32；彼前1：18－19），把他的义归算在他们身上（林后5：21），使他们惟独因信称义（罗3：24－25），向他们别无所求，这信心也是他的恩赐（弗2：8），所以，他们的称义是因着白白的恩典归给他们的（弗1：7）。 72：称义的信心是什么？回答：称义的信心是救赎的恩典（来10：39），由圣灵（林后4：13；弗1：17－19）和圣言（罗10：14，17）在罪人的心中做成，使他确知自己的罪和愁苦，自己和其他任何人都不能使他脱离失丧之境（徒2：37；徒16：30；约16：8－9；罗5：6），不仅赞同福音的应许（弗1：13），而且接受并信靠基督和他的义，罪得赦免（约1：12；徒16：31，10：43），从此在上帝的眼中，得蒙悦纳，被算为义人，以致得救（腓3：9；徒15：11）。 73：在上帝的眼中，信心如何使罪人称义呢？回答：在上帝的眼中，信心使罪人称义，并不是因为随之而来的其它恩惠，或信心所结的善行的果子（加3：33罗3：28），也不是说信心的恩典、或信心的行为算为他的义（罗4：5；罗10：10）；而是因为信心是器皿，由此他接受并支取基督和他的义（约1：12；腓3：9；加2：16）。 74：什么是得儿子的名分？回答：得儿子的名分是上帝的作为（约壹3：1），在他独生子耶稣基督里，且因着他的缘故（弗1：5；加4：4－5），白白赐下恩典，由此那些称义之人一概被纳入他众子的数目（约1：12），归入他的名下（林后6：18；启3：12），领受他所赐的圣灵（加4：6），处于父的眷顾之下（诗103：13；箴14：26；太6：32），得享上帝众子的自由和特权，承受各样的应许，并与基督在荣耀里同为后嗣（来6：12；罗8：17）。 75：成圣是什么？回答：成圣是上帝恩典的作为，由此，他们这些在创世之前就蒙拣选成为圣洁的人，在时间之中，藉着圣灵的大能大力（弗1：4；林前6：11；帖后2：13），把基督的受死和复活应用到他们的身上（罗6：4－6），按上帝的形像使他们的全人得以更新（弗4：23－24）；有悔改得生的种子，以及其它所有救赎的恩惠，安置在他们的心中（徒11：18；约壹3：9），而且这些恩典被挑旺，得增加，受坚固（犹20；来6：11－12；弗3：16－19；西1：10－11），使他们愈来愈能向罪而死，更有生命的新样式（罗6：4，6，14；加5：24）。 76：悔改得生是什么？回答，悔改得生是救赎的恩典（提后2：25），是圣灵（亚12：10）和圣言（徒11：18，20－21）在罪人的心中做成，由此，罪人不仅意识到罪的危险性（结18：28，30，32；路15：17－18；何2：6－7），也为罪的污秽和丑陋而痛悔（结36：31；赛30：22），同时领悟了上帝在基督里的怜悯（珥2：12－13），因此为自己的罪忧伤难过（耶31：18－19），并产生恨恶之情（林后7：11），所以转离罪，完全归向上帝（徒26：18；结14：6；王上8：47－48），立定心志，竭力以新的顺服，在各个方面与主同行（诗119：6，59，128；路1：6；王下23：25）。 77：称义与成圣有何不同？回答：虽然成圣与成圣不可分割地联在一起（林前6：11；1：30），但他们仍有不同之处。称义是基督的义的归算（罗4：6，8），而成圣则是他的灵注入恩典，使人得以行出（结36：7）；在前者中，罪得赦免（罗3：24－25）；在后者中，罪被征服（罗6：6，14）：前者把所有的信徒一概脱离上帝的报应之怒，在今生就达于完全，使他们不再被定罪了（罗8：33－34）；后者在所有的人身上并不相同（约壹2：12－14；来5：12－14），今生也没有任何人能达于完全（约壹1：8，10），而是向完全不断长进（林后7：1；腓3：12－14）。 78：为何信徒的成圣都不完全呢？回答：信徒的成圣都不完全，这是因为他们身上仍然有罪的残余，肉体的贪欲依然存在，常常与圣灵为敌；因此，他们经常为试探所击倒，陷落到许多罪中（罗7：18，23；可14：66；加2：11－12），各种服事常受拦阻（来12：1），即使最好的工作，在上帝的眼中也不完美，仍有污损（赛64：6；出28：38）。 79：真信徒既不完美，也被诸多的试探和罪压倒，他们会不会从蒙恩的状态中堕落呢？回答：不会。因着上帝的不变之爱（耶31：3），和他赐予他们恒忍的预旨和圣约（提后2：19；来13：20－21；撒下23：5），他们与基督联合，不可分离（林前1：8－9），基督也为他们持续代祷（来7：25；路22：32），圣灵和上帝的种子仍在他们心中（约壹3：9；2：27），所以，他们既不会完全，也不会最终从蒙恩的状态中堕落（耶32：40；约10：28），而是得蒙上帝的大能保守，由信得救（彼前1：5）。 80：真信徒是否能够毫无谬误地确信他们已经蒙恩，并且由此而恒忍，直到最终得救？回答：是的。真正归信基督，努力用无愧的良心行在他面前的人（约壹2：3），毋需另外的特别启示，藉着基于上帝应许之道的信心，藉着使他们能够分辨那些赐人生命应许的恩典（林前2：12；约壹3：14，18－19，21，24；4：13，16；来6：11－12），并与他们的灵同证他们是上帝的儿女的圣灵（罗8：16），他们可以毫无谬误地确信他们已经蒙恩，并由此恒忍，直到最终得救（约壹5：13）。 81：所有的真信徒都是一直确信自己目前已经蒙恩，并最终得救吗？回答：蒙恩得救的确信并不是信心的本质（弗1：13），在得到这一确信之前，真信徒或许要长期等候（赛50：10；诗88）；即使在享有这一确信之后，仍会因着种种混乱、罪、试探和遗弃而减弱或中断（诗77：1－12；51：8，12；31：22；22：1）；然而，圣灵的临在和扶持绝不会全然离开他们，必保守他们不至陷入绝望（约壹3：9；伯13：15；诗73：15，23；赛54：7－10）。 82：无形教会的成员在荣耀里所享有的与基督的交通是什么？回答：无形教会的成员在荣耀里所享有的与基督的交通，是在于今生(林后3：18)、死后（路23：43），以及最终在复活与审判日达于完全的交通（帖前4：17）。 83：无形教会的成员今生在荣耀里所享有的与基督的交通是什么？回答：无形教会的成员今生享有与基督一同得荣的初熟的果子，因基督是他们的元首，他们是他的肢体，所以在他里面享有他所有的荣耀（弗2：5－6）；作为真诚的信徒，由此而享有上帝的慈爱（罗5：5；林后1：22），良知的平安，圣灵里的喜乐，和荣耀的盼望（罗5：1－2；14：17）；而恶人则感受到上帝复仇的愤怒，良知的恐惧，对将来审判的畏惧，这些痛苦始于今生，并延续到死后（创4：13；太27：4；来10：27；罗2：9；可9：44）。 84：所有的人都会死吗？回答：死亡是罪的工价（罗6：23），按照定命，人人都有一死（来9：27）；因为所有的人都犯了罪（罗5：12）。 85：既然死是罪的工价，而义人的罪在基督里都蒙赦免，为什么他们没有脱离死亡呢？回答：义人在末日的时候脱离死亡，即使在死亡之时，也脱离了死亡的毒钩和咒诅（林前15：26，55－57；来2：15）；因此，虽然他们也死亡，但这是出于上帝的慈爱（赛57：1－2；王下22：20），使他们完全从罪和愁苦中释放出来（启14：13；弗5：27），使他们能够在即将进入的荣耀里，与基督有更深的交通（路23：43；腓1：23）。 86：无形教会的成员死后在荣耀里所享有的与基督的交通是什么？回答：无形教会的成员死后在荣耀里所享有的与基督的交通，在于他们的灵魂那时在圣洁上达于完全（来12：23），被接入高天（林后5：1；腓1：23；徒3：21；弗4：10），在光明和荣耀中得见上帝之面（约壹3：2；林前13：12），等候他们身体完全的得赎（罗8：23；诗16：9）。他们的身体即使在死亡中也与基督继续联合（帖前4：14），安息在坟墓里，如同安息在床上（赛57：2），直到末日与他们的灵魂再次联合（伯19：26－27）。而恶人的灵魂死时被抛进地狱之中，停留在痛苦和彻底的黑暗里，他们的身体则保留在坟墓里，如在监狱中，直到复活和大日的审判（路16：23－24；徒1：25；犹6－7）。 87：关于复活，我们当信什么？回答：我们当信，在末日的时候，死人都要复活，不管是义人，还是不义的人（徒24：15）：那时还活着的人在一刹那间都要改变；那些躺在坟墓中的身体要与他们的灵魂重新联合，不再分离，因着基督的大能而复活（林前15：21－23；帖前4：15－17；约5：28－29）。义人的身体，因着基督的灵，并藉着他们的元首基督的复活，大有权能地复活，成为属灵的、不朽坏的，与基督荣耀的身体一样（林前15：21－23，42－44；腓3：21）；而恶人的身体亦将由基督这被触怒的审判者，使其在羞辱中复活过来（约5：27－29；太25：33）。 88：复活之后，随即发生什么？回答：复活之后，随即所发生的就是最终的大审判，天使和人都要受到审判（彼后2：4犹6－7，14－15；太25：46）；没有人知道那日那时，致使所有的人都可清醒祷告，时刻预备主的到来（太24：36，42，44；路21：35－36）。 89：在审判之日，恶人会承受什么？回答：在审判之日，恶人将会被置于基督的左边（太25：33），基于确凿的证据，他们自己的良知完全伏罪（罗2：15－16），被公开定罪，承受可怕的，却公平的判决（太25：41－43）；随即被抛进地狱之中，脱离上帝恩惠的同在，以及与基督、他的圣徒，和所有圣天使的荣耀团契，身体灵魂都受惩罚，遭受无法言喻的痛苦，与魔鬼和属他的天使在一起，直到永永远远（路16：26；帖后1：8－9）。 90：在审判之日，义人会承受什么？回答：在审判之日，义人被提云中（帖前4：17），到基督面前，坐在他的右边，当众被承认，宣告无罪（太25：33；10：32），与基督一同审判被弃的天使和世人（林前6：2－3），并被接入天堂（太25：34，46），完全、永远地脱离所有的罪和痛苦（弗5：27；启14：13）；被无法想象的喜乐充满（诗16：11），在身体和灵魂上都达于完全的圣洁和幸福，与无数的圣徒和圣天使在一起（来12：22－23），特别是直接得见父上帝、主耶稣基督和圣灵，得此为乐，直到永远（约壹3：2；林前13：12；帖前4：17－18）。这就是无形教会的成员，在复活和审判日，在荣耀里与基督所享有的完美的交通。 91：上帝要人尽什么本分？回答：上帝要人所尽的本分是顺服他显明的旨意（罗12：1－2；弥6：8；撒上15：22）。 92：上帝起初向人显明了什么作为顺服他的标准？回答：上帝向处在天真状态中的亚当，以及在他里面的全人类，所显明的顺服准则，除了禁止吃分别善恶树上的果子这一特别的诫命之外，就是道德律（创1：26－27；罗2：14－15；10：5；创2：17）。 93：道德律是什么？回答：道德律是上帝对人类旨意的宣告，是人当向上帝和他人所尽的圣洁与公义的本分（路1：75；徒24：16），指导并约束每个人，亲自、完全、持续地予以遵行、顺服，灵魂与身体（申5：1－3，31，33；路10：26－27；加3：10；帖前5：23）全身心地践行：践行则有生命的应许，违背则有死亡的危险（罗10：5；加3：10，12）。 94：堕落之后，道德律对人还有什么作用呢？回答：堕落之后，没有人能靠道德律臻达公义和生命（罗8：3；加2：16）；但道德律仍然大有用处，不管是未重生的人，还是已重生的人，对所有的人都是如此（提前1：8）。 95：道德律对所有的人有什么用处吗？回答：道德律对所有的人都有用处，告诉他们上帝圣洁的属性和旨意（利11：44－45；利20：7－8；罗7：12）、他们的责任，并约束他们随之而行（弥6：8；雅2：10－11）；使他们知道自己没有能力遵行，自己的性情、心灵和生命都受到了罪的污染（诗19：11－12；罗3：20；7：7）；使他们意识到自己的罪和痛苦，从而谦卑自己（罗3：9，23），由此帮助他们更加清楚地认识到对基督的需要（加3：21－22），对基督的完全顺服的需要（罗10：4）。 96：对未重生的人，道德律有什么特别的用处？回答：对未重生的人，道德律的用处，是在于唤醒他们的良知，使他们逃离将来的愤怒（提前1：9－10），促使他们归向基督（加3：24）；如果他们继续处于罪境之中，继续行罪路，就使他们无可推诿（罗1：20；2：15），处于罪的咒诅之下（加3：10）。 97：对已重生的人，道德律有什么特别的用处？回答：虽然对于已经重生，归信基督之人，道德律对他们而言，已经不再是工作之约（罗6：14；罗7：4；加4：4－5），他们既不因之称义（罗3：20），也不因之定罪（加5：23；罗8：1）；但是，除了与所有人共同的用处之外，道德律还有特别的用处，向他们显明：基督为他们的益处成全道德律，替他们承受咒诅，他们与基督的联系是何等紧密（罗7：24－25；加3：13－14；罗8：3－4）；由此促使他们更有感恩之心，并且更加谨慎，使自己在遵行顺服之准则上，把这一感恩之心表达出来（路1：68－69，74－75；西1：12－14；罗7：22；多2：11－14）。 98：道德律总括在什么里面？回答：道德律总括在十诫之中，这是上帝在西奈山上用他的声音颁布的，并且亲自写在了两块石版上（申10：4；出34：1－4）；记录在《出埃及记》20章。前四诫是我们对上帝当尽的本分，后六诫是我们对人当尽的本分（太22：37－40）。 99：要正确理解十诫，应当遵守什么规则？回答：要正确理解十诫，以下的规则应予遵守：（1）律法是全备的，对每个人都有约束力，人人都要以全人完全遵行其中之义，人人都有责任完全顺服，直到永远；因此，律法要求人完备地履行每一当尽的责任，即使最微小的犯罪也予以禁止（诗19：7；雅2：10；太5：21－22）。（2）律法是属灵的，关涉到悟性、意志、情感，以及灵魂的其它能力，涵盖言语、工作和姿态（罗7：14；申6：5；太22：37－39’5：21－22，27－28，33－34，37－39，43－44）。（3）同样的事物，在不同的方面，在不同的诫命中有所要求或禁止（西3：5；摩8：5；箴1：19；提前6：10）。（4）吩咐某一责任，就是禁止与此相反的罪行（赛58：13；申6：13；太4：9－10；15：4－6）；禁止人犯一种罪，就是命令人去完成与该罪行相反的责任（太5：21－25；弗4：28）。因此，何处附加了应许，与之相反的威胁就排除了（出20：12；箴30：17）；何处附加了威胁，与之相反的应许就排除了（耶18：7－8；出20：7；诗15：1；诗24：4－5）。（5）凡上帝所禁止的，绝不要去行（伯13：7－8；罗3：8；伯36：21；来11：25）；凡上帝所吩咐的，则始终是我们的责任（申4：8－9）；但是，并不是在所有的时间，都要完成每一个责任（太12：7）。（6）在一个罪或责任之下，所有同类的罪也受到禁止，同类的责任也在所吩咐的范围之内；连同所有的原因、方式、场合、表现、挑衅都在内（太5：21－22，27－28；15：4－6；来10：24－25；帖前5：22；犹23；加5：26；西3：21）。（7）凡向我们所禁止或所吩咐的，我们都有责任根据自己的处境，努力使他人避免或遵行，根据他们所在处境的责任（处20：10；利19：17；创18：19；书24：15；申6：6－7）。（8）凡向他人所吩咐的，我们都有责任根据我们的处境和呼召，帮助他们实现（林后1：24）；凡禁止他们去行的，我们也要注意不要与他们同行（提前5：22；弗5：11）。 100：在十诫中，我们要考虑什么特别的事项？回答：在十诫中，我们要考虑序言，十诫本身的精义，某些诫命所附加的诸种缘由，以及应予遵行的其它原因。 101：十诫的序言是什么？回答：十诫的序言包含在这些话中：“我是耶和华你的上帝，曾将你从埃及地为奴之家领出来（出20：2）”。上帝从中显明了他的主权，他是耶和华，是永恒、不变、全能的上帝（赛44：6）；他是自有永有的（处3：14），他的话语（出6：3）和作为（徒17：24，28）都由他而出：他是立约的上帝，与过去的以色列人立约，也与他所有的子民立约（创17：7；罗3：29）；他带领他们摆脱了埃及地的捆绑，同样也把我们从属灵的奴役下释放出来（路1：74－75）；因此，我们视他为我们独一的上帝，遵行他一切的诫命，是义不容辞的（彼前1：15－18；利18：30，19：37）。 102：前四诫中所包含的我们对上帝的责任的精义是什么？回答：前四诫中所包含的我们对上帝的责任的精义，是在于尽心、尽性、尽力、尽意爱主我们的上帝（路10：27）。 103：第一条诫是什么？回答：第一条诫是：“在我面前，你不可有别的神（出20：3）”。 104：在第一条诫中，命令我们尽什么责任？回答：在第一条诫中命令我们：认识并承认上帝是独一的真上帝，我们的上帝（代上28：9；申26：17；赛43：10；耶14：22）；并要如此去崇拜、荣耀他（诗95：6－7；太4：10；诗29：2），思念（玛3：16）、默想（诗63：6）、记念（传12：1）、尊崇（诗71：19）、尊敬（玛1：6）、敬慕（赛45：23）、选择（书24：15，22）、挚爱（申6：5）、爱慕（诗73：25）、敬畏他（赛8：13）；相信他（出14：31），依靠他（赛26：4），仰望他（诗130：7），以他为乐（诗32：11）；为他而有忌邪之心（罗12：11；数25：11）；向他呼吁，把一切的赞美和感恩都归于他（腓4：6），并以全人顺服他（耶7：23；雅4：7）；在一切的事情上都留心得蒙他的悦纳（约壹3：22），为所有得罪他的事情而忧伤（耶31：18；诗119：136）；存谦卑的心与他同行（弥6：8）。 105：在第一条诫中所禁止的罪是什么？回答：在第一条诫中所禁止的罪是：否定上帝或主张上帝并不存在的无神论（诗14：1；弗2：12）；主张或崇拜多位神，或崇拜真上帝之外的任何神的偶像崇拜（耶2：27－28；帖前1：9）；不承认他为上帝，我们的上帝（诗81：11）；忽视在这一诫命中所吩咐的他所当得的任何事物（赛43：22－24）；无知（耶4：22；何4：1，6）、忘记（耶2：32）、误解（徒17：23，29）、谬见（赛40：18），与他不相配的邪恶思想（诗50：21）；肆无忌惮，窥探他的隐秘（申29：29）；各样的亵渎（多1：16；来12：16），对上帝的怨恨（罗1：30）；专顾自己（提后3：2），一心寻求自己的益处（腓2：21），以及其它所有放荡无节地把我们的心思、意志、情感置于其它事物上，全部或部分性地偏离他的事情（约壹2：15－16；撒上2：29；西3：2，5）；轻信（约壹4：1）、不信（来3：12）、异端（加5：20；多3：10）、误信（徒26：9）、怀疑（诗78：22）、失望（创4：13）、固执（耶5：3），在审判之下仍然麻木不仁（赛42：25），心里刚硬（罗2：5）、骄傲（耶13：15），任意妄为（诗19：13），自以为平安无事（番1：12），试探上帝（太4：7）；运用不法手段（罗3：8），倚靠不法手段（耶17：5）；爱宴乐（提后3：4）；虽有热心，但却败坏、盲目，没有分辨力（加4：17；约16：2；罗10：2；路9：54－55）；不冷不热（启3：16），在上帝的事情上是死的（启3：1）；疏离自我，背叛上帝（结14：5；赛1：4－5）；向圣徒、天使或其它任何受造物祷告，或崇拜他们（罗10：13－14；何4：12；徒10：25－26；启19：10；太4：10；西2：18；罗1：25）；与魔鬼结盟，交鬼求问（利20：6；撒上28：7，11；代上10：13－14），倾听它的建议（徒5：3）；使人成为我们信仰与良知之主（林后1：24；太23：9）；怠慢、藐视上帝及其诫命（申32：15；撒下12：9；箴13：13）；抵挡、消灭圣灵的感动（徒7：51；弗4：30），不满、厌烦上帝的安排，指责他行事愚昧，把各样恶事加诸我们身上（诗73：2－3，13－15，22；伯1：22）；把我们所具有的、所得来的、所能作的任何好事都归之于幸运（撒上6：7－9）、偶像（但5：23）、自己（申8：17；但4：30）或其它任何受造之物（来1：16）。 106：在第一条诫中说：“在我面前”，这对我们有什么特别的教导？回答：在第一条诫中说：“在我面前”，这些话语教导我们，上帝无所不见，他特别注意到人另有别神之罪，大为不悦：因此劝阻人脱离此罪，视此罪为放肆的挑衅，使其更显严重（结8：5－6；诗44：20－21）。同时，也使我们相信不管从事何种服事，都是行在他的眼中（代上28：9）。 107：第二条诫是什么？回答：第二条诫是：“你不可为自己雕刻偶像；也不可作什么形像，仿佛上天、下地和地底下、水中的百物。不可跪拜那些像；也不可事奉他，因为我耶和华你的上帝是忌邪的上帝。恨我的，我必追讨他的罪，自父及子，直到三四代；爱我守我诫命的，我必向他们发慈爱，直到千代”（出20：4-6；申5：8－10）。 108：在第二条诫中，命令我们尽什么责任？回答：在第二条诫中，命令我们所尽的责任是：对上帝在圣经中所指定的宗教崇拜和典章，要接受遵行，保持纯全（申32：46－47；太28：20；徒2：42；提前6：13－14）；特别是奉基督之名所作的祷告和感恩（腓4：6；弗5：20）；读经、讲道、听道（申17：18－19；徒15：21；提后4：2；雅1：21－22；徒10：33）；施行和接受圣礼（太28：19；林前11：23－30）；教会治理和惩戒（太18：15－17；16：19；林前5；12：28）；服事与维护（弗4：11－12；提前5：17－18；林前9：7－16）；宗教性禁食（珥2：12－13；林前7：5）；奉上帝的名宣誓（神6：13），向上帝许愿（赛19：21；诗76：11）：谴责、痛恨、反对各样的伪崇拜（徒17：16－17；诗16：4）；并根据自己的处境和呼召，清除伪崇拜，以及偶像崇拜的各种标记（申7：5；赛30：22）。 109：在第二条诫中，禁止什么罪行？回答：在第二条诫中，禁止的罪行有：以各种方式，发明（民15：39）、咨询（申13：6－8）、命令（何5：11；弥6：16）、使用（王上11：33；12：33）、认可非上帝所指定的任何宗教崇拜（申12：30－32）；宽容伪宗教（申13：6－12；番13：2－3；启2：2，14－15，20；17：12，16－17）；或在自己心中，或在外部，以任何受造物的形像和样式，制造三个位格或任一位格的上帝的象征（申4：15＝19；徒17：29；罗1：21－23，25）；崇拜此类象征（但3：18；加4：8），或者崇拜其中的上帝，或者藉着它崇拜上帝（出32：5）；制造假神之像（出32：8），予以崇拜并事奉（王上18：26，28；赛65：11）；以古风（彼前1：18）、习俗（耶44：17）、敬虔（赛65：3－5；加1：13－14）、好意或其它理由为借口（撒上13：11－12；15：21），或加或减（申4：2），或由自己杜撰，或由自己发起（诗106：39），或因传统受自他人（太15：9），设计各种迷信（徒17：22；西2：21－23），败坏对上帝的崇拜（玛1：7－8，14）；买卖圣职（徒8：18）；亵渎上帝（罗2：22；玛3：8）；忽略（出4：24－26）、轻蔑（太22：5；玛1：7，13）、拦阻（太23：13）、抵挡上帝所指定的敬拜和典章（徒13：44－45；帖前2：15－16）。 110：第二条诫所附加遵行的理由是什么？回答：第二条诫所附加的理由，以及遵行的其它理由，包含在以下的话中：“我耶和华你的上帝是忌邪的上帝。恨我的，我必追讨他的罪，自父及子，直到三四代；爱我守我诫命的，我必向他们发慈爱，直到千代”（出20：5－6）；上帝对我们拥有主权，我们是属他的（诗45：11；启15：3－4），他对自己的崇拜有强烈的忌邪之心（出34：13－14），所有的伪崇拜都是属灵的淫乱，必招致他复仇的震怒（林前10：20－22；耶7：18－20；结16：26－27；申32：16－20）；违背这一诫的人就是恨恶上帝的人，上帝威胁要惩罚他们，直到许多代（阿2：2－4）；遵守这一诫的人就是爱他守他诫命的人，会得到尊荣，上帝应许怜悯他们直到许多代（申5：29）。 111：第三条诫是什么？回答：第三条诫是：“你不可妄称主你上帝的名，因为妄称他名的，主必不以他为无罪”（出20：7） 。 112：在第三条诫中命令什么？回答：在第三条诫中命令，上帝的名字、尊称、属性（太6：9申28：58；诗24：2；98：4；启15：3－4）、典章（玛1：14；传5：1）、圣言（诗138：2）、圣礼（林前11：24－25，28－29）、祷告（提前2：8）、起誓（耶4：2）、许愿（传5：2－6）、拈阄（徒1：24，26）、作为（伯36：24），他所用以显明他自己的一切，都要在思想（玛3：16）、默想（诗8：1，3－4，9）、言语（西3：17；诗105：2，5）和著述（诗102：18）中，予以圣洁、敬畏地使用；藉着圣洁的表白（彼前3：15；弥4：5），行事为人与蒙召之恩相称（腓1：27），使上帝得荣耀（西10：31），我们（耶32：39）和他人都得益处（彼前2：12）。 113：在第三条诫中，禁止什么罪行？回答：在第三条诫中禁止的罪行是：不按要求使用上帝的名字（玛2：2）；愚昧（徒17：23）、虚妄（箴30：9）、不敬、亵渎（玛1：6－7；12；3：14）、迷信（撒上4：3－5；耶7：4，9－10，14，31；西2：20－22），或邪恶地提及，使用上帝的尊称、属性（王下18：30，35；出5：2；诗139：20）、典章（诗50：16－17）、作为（赛5：12），用于亵渎（王下19：22；利24：11）、伪证（亚5：4；8：17），因而滥用上帝的名字；一切恶毒的咒诅（撒上17：43；撒下16：5）、起誓（耶5：7；23：10）、许愿（申23：18；徒23：12，14）、掣签（斯3：7；9：24；诗22：18）；违背我们合法的宣誓和许愿（诗24：4；结17：16，18－19）；成全不合法的宣誓和许愿（可6：26；撒上25：22，32－34）；抱怨、抗拒（罗9：14，19－20）、窥探（申29：29）、误用上帝的预旨（罗3：5，7；6：1－2）和护理（传8：11；9：3；诗39）；误解（太5：21）、误用（结13：22），或以其它方式歪曲上帝的圣言，或其中的任何部分（彼后3：16；太22：24－31），用于亵渎性的戏谑（赛22：13；耶23：34，36，38）、好奇无益的问难、荒渺无凭的空谈，或坚持谬妄的教义（提前1：4，6－7；6：4－5，20；提后2：14；多3：9）；滥用上帝名下所包含的受造物、或任何事物，用为魔法符咒（申18：10－14；徒19：13），或邪恶的情欲和行为（提后4：3－4；罗13：13－14；王上21：9－10；犹4）；恶毒中伤（徒13：45；约壹3：12），懈慢讥诮（诗1：1；彼后3：3），肆意谩骂（彼前4：4），或以其它任何方式抵挡上帝的真理、恩典和道路（徒13：45－46，50；徒4：18；19：9；帖前2：16；来10：29）；假冒伪善，心怀不轨，谎称信主（提后3：5；太23：14；6：1－2，5，16）；因不顺从（诗73：14－15），无智慧（林前6：5－6；弗5：15－17），不结果子（赛5：4；彼后1：8－9），唐突冒犯（罗2：23－24），或冷淡退后（加3：1，3；来6：6），而以主名为耻（可8：38），羞辱主名。 114：第三条诫所附加的理由是什么？回答：第三条诫所附加的理由在以下的话语中：“因为妄称他名的，主必不以他为无罪”（出20：7）；因为他是主，我们的上帝，因此我们不应亵渎他的名，也不应以任何方式滥用（利19：12）；特别是因为触犯这一诫命的人，他必不会赦免、饶恕，即使许多人避开了人的鉴察和审判（撒上2：12，17，22，24；撒上3：13），但上帝却不容他逃避他公义的审判（结36：21－23；申28：58－59；亚5：2－4）。 115：第四条诫是什么？回答：第四条诫是：“当记念安息日，守为圣日。六日要劳碌作你一切的工；但第七日是向耶和华你上帝当守的安息日；这一日你和你的儿女、仆婢、牲畜，并你城里寄居的客旅，无论何工都不可作，因为六日之内，耶和华造天、地、海和其中的万物，第七日便安息，所以耶和华赐福与安息日，定为圣日”（出20：8－11）。 116：在第四条诫中命令什么？回答：在第四条诫中，命令所有的人将上帝在圣经中所指定的时间，都向他分别为圣，予以遵守，他特别指明七日中的一整天守为圣日；从世界之初到基督复活，这一日为一周的第七日；此后便以每周的第一日为圣日，直到世界的末了；这就是基督徒的安息日（申5：12－14；创2：2－3；林前16：1－2；徒20：7；太5：17－18；赛56：2，4，6－7），在新约圣经中称之为主日（启1：10）。 117：如何将安息日或主日守为圣日？回答：守安息日为圣，乃是整日合乎圣洁地安息（出20：8，10），不仅停止那些平常为罪的恶事，还要停止平日合法的属世职业和娱乐（出16：25－28；尼13：15－22；耶17：21－22）；并用全部时间，或与众人，或在家中，敬拜上帝（赛58：13；路4：16；徒20：7；林前16：1－2；诗92；赛66：23；利23：3），以此为赏心乐事；只有为着工作的必须和施行怜悯所占的时间例外（太12：1－13）。为此，我们要预备心灵，提前安排，殷勤作工，稳健节制，合乎时宜地迅速处理我们的世俗之事，使我们可以更自由、更适宜地尽此日当尽的本分（出20：8；路23：54，56；16：22，25－26，29；尼13：19）。 118：为什么说守安息日这一吩咐，特别指向家长和其他尊长呢？回答：守安息日这一吩咐，特别指向家长和其他尊长，这是因为他们不仅有责任自己遵守，还有责任监督那些处在他的负责范围之内的人予以遵守；而且，因为他们经常有占用他们的时间，拦阻他们守安息日的倾向（出20：10；书24：15；尼13：15－17；耶17：20－22；出23：12）。 119：在第四条诫中，禁止什么罪行？回答：在第四条诫中，禁止的罪行是，忽略当尽的本分（结22：26），虽予遵行，却漫不经心，粗心大意，不得益处，而且厌烦遵行（徒20：7，9；结33：30－32；摩8：5；玛1：13）；无所事事，或作奸犯科，亵渎此日（节23：38）；或对俗务和娱乐发生不必要的心思、言语或作为（耶17：24，27；赛58：13）。 120：第四条诫所附加的遵行理由是什么？回答：第四诫所附加的遵行理由是，内中有衡平，上帝让我们在一周之内有六日作自己的工，保留一日归他自己：“六日要劳碌作你一切的工”（出20：9）；上帝挑战我们这日特别归他：“第七日是向耶和华你上帝当守的安息日”（出20：10）；而且，上帝以身作则：“六日之内，主造天、地、海和其中的万物，第七日便安息”；上帝特别祝福此日，不仅把这日分别为圣，用于事奉他，而且指定，当我们守此日为圣的时候，此日便成为我们蒙福的器皿：“所以耶和华赐福与安息日，定为圣日”（出20：11） 。 121：为什么在第四诫的一开始就用了“记念”一词？回答：在第四诫的一开始就用了“记念”一词（出20：8），部分是因为：记念此日有极大的惠益，使我们由此得帮助，预备遵守（出16：23；路23：54，56；可15：42；尼13：19），而且，在遵守的时候，最好是遵行这一诫命的各个部分（诗92：13－14；结20：12，19－20），不断地以感恩的心记念创造与救赎的大德，这二者是宗教的总结（创2：2－3；诗118：22，24；徒4：10－11；启1：10）；部分是因为：我们容易忘却此日（结22：26），因为在自然之光中很少对此有所反映（尼9：14），而且守安息日限制了我们天然的自由，平日合法的事情此日却不能行（出34：21）；安息日七天内才有一天，中间世务繁多，使我们的心思意念无暇顾及此日，更不用说提前预备，守为圣日了（申5：14－15；摩8：5）；再者，撒但与他的器皿也是辛苦作工，妄图抹掉此日的荣耀，甚至想把此日从人的记忆中完全抹除，以便塞进各种各样的反宗教、不敬虔之事（哀1：7；耶17：21－23；尼13：15－23）。 122：后六诫包括我们对人的责任，其总纲是什么？回答：后六诫包括我们对人的责任，其总纲就是爱人如己（太22：39），我们愿意人怎样待我们，我们就要怎样待人（太7：12）。 123：第五条诫是什么？回答：第五条诫是：“当孝敬父母，使你的日子在耶和华你上帝所赐你的地上，得以长久”（ 出20：12） 。 124：在第五条诫中，“父母”是指谁？回答：在第五条诫中，“父母”一词所指的不仅是肉身的父母（箴23：22，25；弗6：1－2），还包括在年纪（提前5：1－2）和恩赐（创4：20－22；创45：8）上超过我们的一切长辈；特别是那些按照上帝的典章，在家庭（王下5：13）、教会（王下2：12；13：14；加4：19）、国家中（赛49：23），在我们之上有权柄的人。 125：为什么尊称尊长如父母呢？回答：尊称长辈如父母，因为他们正象肉身的父母一样，教导晚辈各样的责任，同时又根据他们各种不同的关系，向晚辈表达慈爱和温柔（弗6：4；林后12：14；帖前2：7－8，11；民11：11－12）；并使晚辈甘心乐意、欢欢喜喜地完成他们当向长辈所尽的责任，正如对父母一样（林前4：14－16；王下5：13）。 126：第五条诫的一般范围是什么？回答：第五条诫的一般范围是，作为晚辈、长辈、或同辈，在我们与他人的各种关系中，履行彼此当尽的那些责任（弗5：21；彼前2：17；罗12：10）。 127：晚辈当如何尊重长辈？回答：晚辈当尊重长辈，包括在心思（玛1：6；利19：3）、言语（箴31：28；彼前3：6）和行为（利19：32；王上2：19）上与其当得的敬重；为他们祷告感恩（提前2：1－2）；效法他们的德行和恩惠（来13：7；腓3：17）；甘心乐意地顺服他们合法的吩咐和建议（弗6：1－2，5－7；彼前2：13－14；罗13：1－5；来13：17；箴4：3－4；23：22；出18：19，24）；对于他们的责备，该顺服的就当顺服（来12：9；彼前2：18－20；）；根据他们的身份和地位（太22：21；罗13：6－7；提前5：17－18；加6：6；创45：11；47：12），忠于（多2：9－10）、保卫（撒上26：15－16；撒下18：3；斯6：2）、维护他们的人格和权威；担当他们的软弱，并以爱心遮盖他们（彼前2：18；箴23：22；创9：23），如此就可成为他们及其治理引以为荣的人（诗127：3－5；箴31：23）。 128：晚辈冒犯长辈的罪是什么？回答：晚辈冒犯长辈的罪是，忽略向他们当尽的责任（太15：4－6）；在他们合法的建议（撒上2：25）、吩咐和责备（申21：18－21）上，嫉妒（民11：28－29）、蔑视（撒上8：7；赛3：5）、反叛（撒下15：1－12）长辈的人格（出21：15）和地位（撒上10：27）；咒诅嘲笑（撒上2：25），冥顽不化，恶意中伤，如此成为他们及其治理上贻羞致辱之人（箴19：26）。 129：长辈当向晚辈尽什么责任？回答：长辈当向晚辈所尽的责任是，根据他们从上帝所受的权柄，以及他们所处的关系，爱护晚辈（西3：19；多2：4），为他们祷告（撒上12：23；伯1：5），祝福他们（王上8：55－56；来7：7；创49：28）；教训（申6：6－7），劝勉，提醒，告诫（弗6：4）；行的好的，鼓励赞助（彼前3：7），表扬称赞（彼前2：14；罗13：3），予以嘉奖（斯6：3）；行的坏的，不予赞同（罗13：3－4），予以责备，管教惩罚（箴29：15；彼前2：14）；对于他们灵魂（弗6：4）和身体（提前5：8）所必需的一切，善加保护（伯29：12－17；赛1：10，17），予以供应；严肃庄重，智慧通达，惟圣惟洁，以身作则，使上帝得荣耀（提前4：12；多2：3－5），自己受尊重（王上3：28），上帝所赐予的权柄得以保守（多2：15）。 130：长辈易犯的罪行是什么？回答：长辈易犯的罪行，除了忽略他们当尽的责任之外（结34：2－4），专求自己的事（腓2：21），追求自己的荣耀（约5：44；7：18）、舒适、好处和快乐（赛56：10－11；申17：17）；要求晚辈去行非法（但3：4－6；徒4：17－18），或超出他们权能之事（出5：10－18；太23：2，4）；对于行恶的，出谋划策（太14：8；可6：24），怂恿促进（撒下13：28），恩宠有加（撒上3：13）；对于行善的，横加拦阻，打击士气，不予嘉奖（约7：46－49；西3：21；出5：17）；责备不当（彼前2：18－20；来12：10；申25：3）；粗心大意，把晚辈置于谬误、诱惑和危险之中不管不顾（创38：11，26；徒18：17）；激怒他们（弗6：4）；以及任何因着不公义、不慎重、为人苛刻、疏忽职责所导致的羞辱自己、削弱自身权威之事（创9：21；王上12：13－16；1：6；撒上2：29－31）。 131：同辈之间的责任是什么？回答：同辈之间的责任是，彼此尊重对方的尊严和价值（彼前2：17），在他人面前把荣誉归给对方（罗12：10）；为对方的恩赐和进步而高兴欢喜，如同己有（罗12：15－16；腓2：3－4）。 132：同辈之间易犯的罪行是什么？回答：同辈之间易犯的罪行是，除了忽略当尽的责任之外（罗13：8），贬低对方的价值（提后3：3），嫉妒对方的恩赐（徒7：9；加5：26），因对方进步兴盛而心里难受（民12：2；斯6：12－13）；以及篡夺权柄，压制对方（约叁9；路22：24）。 133：对于履行第五条诫所附加的理由是什么？回答：对于履行第五条诫所附加的理由是，“使你的日子在耶和华你上帝所赐你的地上，得以长久”（出20：12），这是一个明确的长寿与兴盛的应许，适用于所有遵行这一诫命的人，只要是荣耀上帝，造福自己（申5：16；王上8：25；弗6：2－3）。 134：第六条诫是什么？回答：第六条诫是，“不可杀人”（出20：13） 。 135：在第六条诫中，命令什么责任？回答：在第六条诫中，命令我们用各样研究方法，和一切合法手段，保守我们自己（弗5：28－29）和他人（王上18：4）的生命，抵挡各样的思想和意图（耶26：15－16；徒23：12，16－17，21，27），制伏一切的情绪（弗4：26－27），避免导致不义地夺取任何人生命（撒上24：12；26：9－11；创37：21－22）的所有场景（撒下2：22；申22：8）、诱惑（太4：6－7；箴1：10－11，15－16），和作法；正当地抵御暴力（诗82：4；箴24：11－12；撒上14：45），忍耐上帝的管教（雅5：7－11；来12：9），追求心灵的安静（帖前4：11；彼前3：3－4；诗37：8－11）、灵魂的喜乐（箴17：22）；适度地吃肉（箴25：16，27），饮酒（提前5：23），服药（赛38：21），睡眠（诗127：2），劳动（传5：12；帖后3：10，12；箴16：26），娱乐（传3：4，11）；有恩惠（撒上19：4－5；22：13－14），有爱心（罗13：10），怜悯（路10：33－34），谦虚，温柔，仁慈（西3：12－13）；言语行为，温良柔顺（雅3：17），谦恭有节，寻求和睦（彼前3：8－11；箴15：1；士8：1－3）；凡事克制，乐意和好，恒久忍耐，饶恕伤害，以善报恶（太5：24；弗4：2，32；罗12：17，20－21）；安慰、救助受苦的人，保守、护卫无辜的人（帖前5：14；伯31：19－20；太25：35－36；箴31：8－9）。 136：在第六条诫中，禁止什么罪行？回答：在第六条诫中，禁止以各种形式夺去我们自身（徒16：28）和他人（创9：6）生命的行为，除非是在公共司法（民35：31，33）、合法战争（耶48：10；申20），或正当防卫中（出22：2－3）；忽略或不用合法的、必需的手段来保守生命（太25：42－43；雅2：15－16；传6：1－2）；不合道德的愤怒（太5：22）、仇恨（约壹3：15；利19：17）、嫉妒（箴14：30）、复仇的欲望（罗12：19）；一切过分的情绪（弗4：31）、使人烦乱的忧虑（太6：31，34）；无节制的吃肉、饮酒（路21：34；罗13：13）、劳作（传12：12；2：22－23），和娱乐（赛5：12）；触动怒气的言语（箴15：1；12：18）、苦待他人（结18：18；出1：14）、纷扰争竟（加5：15；箴23：29）、击打伤害（民35：16－18，21），以及任何倾向于毁坏人生命的行为（出21：18－36）。 137：第七诫是什么？回答：第七诫是，“不可奸淫”（出20：14） 。 138：在第七条诫中，命令什么责任？回答：在第七条诫中，命令我们在身体、意念、感情（帖前4：4；伯31：1；林前77：34）、言语（西4：6）和行为（彼前2：3）上，都要贞洁；并保守我们和他人的贞洁（林前7：2，35－36）；谨守我们的眼睛和其他所有感官（伯31：1）；自我克制（徒24：24－25），与贞洁的人为伴（箴2：16－20），以正派衣裳为装饰（提前2：9）；不要与那些不知自我节制（林前7：2，9）、夫妇之爱（箴5：19－20）和同居之乐（彼前3：7）的人结婚；在自己的呼召中要勤勉（箴31：11，27－28）；抵挡诱惑，避免各种不洁的场合（箴5：8；创39：8－10）。 139：在第七诫中，禁止什么罪行？回答：在第七诫中，禁止的罪行有，除了忽略当尽的责任之外（箴5：7），奸淫、污秽（来13：4；加5：19）、强奸、乱伦（撒下13：14；林前5：1）、同性恋，以及所有违反天性的色欲（罗1：24，26－27；利20：15－16）；各种不洁的想象、思想、意图和感情（太5：28；15：19；西3：5）；所有败坏的、肮脏的话语，连听都不要听（弗5：3－4；箴7：5，21－22）；淫荡的眼色（赛3：16；彼后2：14），轻浮的举止，不正派的服饰（箴7：10，13）；禁止合法的嫁娶（提前4：3），施行不合法的婚姻（里18：1－21；可6：18；玛2：11－22）；允许、宽容、保持妓院，到妓院游玩（王上15：12；王下23：7；申23：17－18；利19：29；耶5：7；箴7：24－27）；妨碍独身的誓言（太19：10－11），不合理地延迟结婚（林前7：7－9；创38：26）；多妻或多夫（玛2：14－15；太19：5）；不公义的离婚（玛2：16；太5：32），或离弃（林前7：12－13）；懒惰、贪食、醉酒（结16：49；箴23：30－33）、与淫荡的人为伴（创39：10；箴5：8）；黄色歌曲、书籍、图片、舞蹈、戏剧（弗5：4；结23：14－17；赛23：15－17；3：16；可6：22；罗13：13；彼前4：3）；以及其他一切导致我们自身和他人不洁的刺激或行动（王下9：30；耶4：30；结23：40）。 140.第八条诫是什么？回答：第八条诫是：“不可偷窃”（出20：15）。 141：在第八条诫中，命令什么责任？回答：在第八条诫中命令的责任是：在人与人的契约和生意中要讲究诚实、守信和公平（诗15：2，4；亚7：4，10；8：16－17）；凡人所当得的，就给他（罗13：7）；非法扣押正当所有人的财物，要予以赔偿（利6：2－5；路19：8）；根据自己的能力和他人的需要，慷慨施与、出借（路6：30，38；约壹3：17；弗4：28；加6：10）；对世上的财物，要有持中的判断、愿望和情感（提前6：6－9；加6：14）；对于那些供养我们肉身的东西，要审慎考虑，留心料理（提前5：8），根据我们自身的处境，加以获取、保守、使用和处理（箴27：23－27；传2：24；3：12－13；提前6：17－18；赛38：1；太11：8）；合法的职业要持守（林前7：20；创2：15；3：19），并要殷勤从事（弗4：28；箴10：4）；生活节俭（约6：12，箴21：20）；避免不必要的诉讼（林前6：1－9）、担保，以及其他类似的事宜（箴6：1－6；11：15）；努力运用一切公义的、合法的手段，获取、保守、增加他人以及我们自身的财富和产业（利25：35；申22：1－4；出23：4－5；创47：14，20；腓2：4；太22：39）。 142：在第八条诫中，禁止什么罪行？回答：在第八条诫中禁止的罪行是：忽略当今的本分（雅2：15－16；约壹3：17），偷窃（弗4：28），抢劫（诗4：28），抢人口（提前1：10），接受任何窃取得来的东西（箴29：24；诗50：18）；欺诈性行为（帖前4：6），虚假的度量衡（箴11：1；20：10），移动地界（申19：14；箴23：10），人与人之间定立契约时不公义、不守信（摩8：5；诗37：21），或在别人托付的事上如此（路16：10－12）；欺压亏负（结22：29；利25：17），敲榨勒索（太23：25；结22：12），行贿受贿（诗15：5；伯15：34），毫无根据的诉讼（林前6：6－8；箴3：29－30），非法圈地，灭绝人口（赛5：8；箴21：6）；囤积居奇（箴11：26），非法的职业（19：19，24－25），以及其他所有巧取豪夺，损人利己，违背公义，作奸犯科之事（伯20：19；雅5：4；箴21：6）；贪心（路12：15）；过分看重世上的财物（提前6：5；西3：2；箴23：5；诗62：10）；获取、保守、使用财物时，忧虑小信，无所适从（太6：25，31，34；传5：12）；见到他人兴盛就心怀不平（诗73：3；37：1，7）；作工懈怠（帖后3：11；箴18：9），挥霍财产，赌博浪费；以及不正当地损害我们的外部产业（箴21：17；23：20－21；28：19），不正当地使用和享受上帝所赐给我们的产业的各种作法（传4：8；6：2；提前5：8）。 143：第九条诫是什么？回答：第九条诫是：“不可作假见证陷害人”（出20：16）。 144：在第九条诫中，命令什么责任？回答：在第九条诫中，命令的责任是：保守并增进人与人之间的诚实（亚8：16），以及他人和我们自身的名誉（约三12）；为真理献身（箴言31：8－9）；在审判和公义之事上（利19：15，箴14：5，25），以及在其他各种事情上，实话实说，只讲真理（林后1：17－18；父4：25），发自内心（诗15：2）、忠心诚实（代上19：9），不计代价（撒上19：4－5），不加隐瞒（书7：19），不偏左右（撒下14：18－20）；以爱心尊重他人（来6：9；林前13：7）；爱护他们的名誉，愿意他们有好名声，并为之欢喜（罗1：8；约贰4；约叁3－4）；为他们的软弱难过（林后2：4；12：21），并加以遮掩（箴17：9；彼前4：8）；承认他们的恩赐和恩典（林前1：4－5，7；提后1：4－5），为他们的无辜辩护（撒上22：14）；关于他们的好消息，愿意接受（林前13：6－7），坏消息，不随意苟同（诗15：3）；不鼓励传舌者（箴25：23）、奉承者（箴26：24－25）、诽谤者（诗101：5）；珍惜自己的名誉，并在需要的时候予以辩护（箴22：1；约8：49）；遵守合法的誓言（诗15：4）；凡是真实的、诚实的、可爱的、有美名的，都要考察、遵行（腓4：8）。 145.在第九条诫中，禁止什么罪行？回答：在第九条诫中，禁止的罪行是：一切损害他人和我们自己的诚实与名誉的事（撒上17：28；撒下16：3；1：9－10，15－16），特别是在司法审判中（利19：15；来1：4）；提供伪证（箴19：5；6：16，19），唆使他人作假见证（徒6：13），故意为邪恶之事辩护，不顾事实，夸大其词（耶9：3，5；徒24：2，5；诗12：3－4；52：1－4）；作出不公义的判决（箴17：15；王上21：9－14）；称善为恶，称恶为善；把义人当得的归于恶人，把恶人当得的归于义人（赛5：23）；编造谎言（诗119：69；路19：8；16：5－7），掩盖事实真相，对正义之事不当地保持沉默（利5：1；申13：8；徒5：3，8－9；提后4：6），对罪恶应予指责时却不仗义直言（王上1：6；利19：17），也不向他人申诉（赛59：4）；虽说真话，却不合时宜（镇19：11），或心存恶意（撒上22：9－10；诗52：1－5），或颠倒黑白，故意歪曲（诗56：5；约2：19；太26：60－61），或言辞含糊，模棱两可，以致损害事实或公义（创3：5；26：7，9）；不说真话（赛59：13），说谎（利19：11；西3：9），诽谤（诗50：20），谗谤（诗15：3），毁损（雅4：11；耶38：4），搬弄是非（利19：16），传播谣言（罗1：29－30），嘲弄他人（创21：9；加4：29），辱骂他人（林前6：10），轻率论断（太7：1），言语苛刻（徒28：4），论断不公（创38：24；罗2：1）；曲解他人的目的、言语和行动（尼6：6－8；罗3：8；诗69：10；撒上1：13－15；撒下10：3）；油嘴滑舌（诗12：2－3），虚荣自夸（提后3：2），自高自大，高抬别人，或妄自菲薄，小看别人（路18：9，11；罗12：16；林前4：6；徒12：22；出4：10－14）；否定上帝的恩赐和恩典（伯27：5－6）；小罪看大（太7：3－5）；本该坦白认罪，却躲躲藏藏，寻找借口，减轻罪责（箴28：13；30：20；创3：12－13；耶2：35；王下5：25；创4：9）；泄漏人不该泄漏的软弱（创9：22；箴25：9－10）；散布谣言（出23：1），听信谎言（箴29：12），掩耳不听正当的辩护（徒7：56－57；伯31：13－14）；妄自猜疑（林前13：5；提前6：4）；对别人所当得的功劳，嫉妒恼怒（民11：29；太21：15），妄图予以削弱、损害（拉4：12－13），别人蒙羞受辱，则高兴欢喜（耶48：27）；蔑视别人，加以戏弄（诗35：15－16，21；太27：28－29），献媚他人（犹16；徒12：22）；违背合法的诺言（罗1：31；提后3：3）；对关涉美名之事，漫不经心（撒上2：24），对招致臭名之事，则去亲自践行，或不加回避，或未尽力拦阻自己，以致损害他人名誉（撒下13：12－13；箴35：8－9；6：33）。 146：第十条诫是什么？回答：第十条诫是：“不可贪恋人的房屋；也不可贪恋人的妻子、仆婢、牛驴，并他一切所有的。” 147：在第十条诫中，命令什么责任？回答：在第十条诫中，命令的责任是：对我们自己的处境完全知足（来13：5；提前6：6），用正直仁爱的精神对待我们的邻舍，我们一切的动机和情感都要以促进他人的好处为念（伯31：29；罗12：15；诗122：7－9；提前1：5；斯10：3；林前13：4－7）。 148：在第十条诫中，禁止什么罪行？回答：在第十条诫中，禁止的罪行是：对自己的现状不满（王上21：4；斯5：13；林前10：10）；对邻舍的善况嫉妒（加5：26；雅3：14，16）、难受（诗112：9－10；尼2：10），并对他所拥有的起贪心邪情（罗7：7－8；13：9；西3：5；申5：21）。 149：人能全守上帝的诫命吗？回答：今生今世，不管是靠自己（雅3：2；约15：5；罗8：3），还是靠所承受的任何恩典，均无人能全守上帝的诫命（传7：20；约壹1：8，10；罗7：18－19）；反倒天天在心思（创6：5；8：21）、言语和行为上（罗3：9－19；雅3：2－13），违背上帝的诫命。 150：一切违反上帝律法的事，就其本身，并在上帝的眼中，都是同样可憎吗？回答：一切违背上帝律法的事，都是同样可憎的；但是，有些罪就其本身，并因某些加重情节，在上帝的眼中，比别的罪更是可憎（约19：11；结8：6，13，15；约壹5：16；诗78：17，32，56）。 151：那些使某些罪加重，比其它罪更可憎的情节是什么？回答：罪的加重情节，（1）来自犯罪之人的情节如下（耶2：8）：假如他们的年龄已经相当成熟（伯32：7，9；传4：13），经验更丰富，所承受的恩典更多（王上11：4，9），在职业（撒下12：14；林前5：1）、恩赐（雅4：17；路12：47－48）、地位（耶5：4－5）、职份（撒下12：7－9；结8：11－12）上，处于尊贵，为人师表（罗2：17－24），是其他人所效法的榜样（加2：11－14）。（2）来自被侵害者的情节如下（太21：38－39）：直接冒犯上帝（撒上12：7－9）、他的特性（罗2：4）和敬拜（玛1：8，14）；直接冒犯基督和他的恩典（来2：2－3；12：25）；直接冒犯圣灵（来10：29；太12：31－32）、他的见证（弗4：30）和工作（来6：4－6）；直接冒犯尊长、处于尊位之人（士8；民12：8－9；赛3：5），以及和我们有特别关系与责任的人（箴30：17；林后12：15；诗55：12－15）；直接冒犯圣徒（番2：8，10－11；太18：6；林前6：8；启17：6），特别是那些软弱的弟兄（林前8：11－12；罗14：13，15，21），冒犯他们或其他任何人的灵魂（结13：19；林前8：12；启18：12－18；太23：15），以及伤害所有人或许多人的共同利益（帖前2：15－16；书22：20）。（3）来自冒犯之性质的情节如下（箴6：30－33）：直接违反律法的明确内容（拉9：10－12；王上11：9－10），违背多条诫命，本身包含诸多罪（西3：5；提前6：10；箴5：8－12）；不仅心中图谋，还在言语行为上（雅1：14－15；太5：22；弥2：1），诽谤他人（太18：7；罗2：23－24），并且不予补偿（申22：22，28－29；箴6：32－35）；不顾教训（太11：21－24；约15：22）、怜悯（赛1：3；申32：6）、审判（摩4：8－11；耶5：3）、自然之光（罗1：26－27）、良知的罪感（罗1：32；但5：22；多3：10－11）、公开或私下的劝诫（箴29：1）、教会的警戒（多3：10；太18：17）、国家的审判（箴27：22；23：35），以及违背我们的祷告、目的、允诺（诗78：34－37；耶2：20；42：5－6，20－21）、许愿（传5：4－6；箴20：25）、约（利26：25）、与上帝或他人的约定（箴2：17；结17：18－19）；蓄意（诗36：4）、故意（耶6：16）、任意（民15：30；出21：14）、无耻（耶3：3；箴7：13）、自夸（诗52：1）、恶意（约叁10）、屡次（民14：22）、顽固（亚7：11－12）行恶，在悔改之后（也34：8－11；彼后2：20－22），仍然是欢喜作恶（箴2：14），继续犯罪（赛57：17），故态复萌。（4）来自冒犯时间（王下5：26）与地点（耶7：10；赛26：10）的情节如下：在主日（结23：37－39），或其它敬拜上帝的时间（赛58：37），或恰在此前（林前11：20－21），或恰在此后（耶7：8－10；箴7：14－15；约13：27，30），不顾拦阻或纠正此类失败的帮助（拉9：13－14）；或在公共场所，或有他人在场，使其受到刺激或玷污（撒下16：22；撒上2：22－24）。 152：在上帝的手中，每一种罪该受什么处罚？回答： 每一种罪，哪怕是最小的犯罪，都是冒犯上帝的主权（雅2：10－11）、良善（出20：1－2）和圣洁（哈1：13；利10：3；11：44－45），冒犯上帝公义的律法（约壹3：4；罗7：12），当在今生（哀3：39；申28：15－68）和来世（太25：41）受他的愤怒和咒诅（弗5：6；加3：10）；不靠基督的宝血，就无法得以补偿（来9：22；彼前1：18－19）。 153：为叫我们可以逃避那因违背律法而当受的烈怒和咒诅，上帝要我们怎样行？回答：为叫我们可以逃避那因违背律法而当受的烈怒和咒诅，上帝要我们向他悔改，归信耶稣基督（徒20：21；太3：7－8；路13：3，5；徒16：30－31；约3：16，18），并且善用那些基督借以把他中保的恩惠传递给我们的外部工具（箴2：1－5；8：33－36）。 154：基督把他中保的恩惠传给我们，所凭借的外部工具是什么？回答：基督把他中保的恩惠传给我们，所凭借的外部的普通工具是他所有的律法，特别是圣经、圣礼和祷告；他叫这一切发生效力，使选民得救（太28：19－20；徒2：42，46－47）。 155：圣经怎样对救赎发生效力呢？回答：圣灵使读经，尤其是讲道，成为启迪罪人（尼8：8；徒26：18；诗19：8），使其知罪，谦卑下来（林前14：24－25；代下34：18－19，26－28）；驱使他们出离自我，吸引他们归向基督（徒2：37，41；8：27－39）；使他们合乎他的形状（林后3：18），顺服他的旨意（林后10：4－6；罗6：17）；坚固他们，抵挡各样的试探和败坏（太4：4，7，10；弗6：16－17；诗19：11；林前10：11）；在恩典中把他们建造起来（徒20：32；提后3：15－17），使他们的心因信成为圣洁，得着安慰，以致得救的有效工具（罗16：25；帖前3：2，10－11，13；罗15：4）。 156：是不是所有的人都要读经？回答：尽管并不是所有的人都可以公开向会众读经（申31：9，11－13。尼8：2－3；9：3－5），但各种人都应自己阅读圣经（申17：19；启1：3；约5：39；赛78：5－7），并与自己的家人一起阅读（申6：6－9；创18：17，19；诗78：5－7）；为了达成这一目的，要把圣经从原文翻译成各种通用的语言（林前14：6，9，11－12，15－16，24，27－28）。 157：应当如何读经？回答：应当以高度的敬畏之心读经（诗19：10；尼8：3－10；出24：7；代下34：27；赛66：2）；确信圣经就是上帝的话（彼前1：19－21），而且惟独上帝能使我们明白圣经（路24：45；林后3：13－16）；并愿意认识、相信、顺服上帝显明在圣经中的旨意（申17：10，20）；殷勤查考（徒17：11），留意圣经的内容和范围（徒8：30，34；路10：26－28）；并用默想（诗1：2；119：97）、应用（代下34：21）、舍己（箴3：5；申33：3）、祷告（箴2：1－6；诗119：18；尼7：6，8）之法读经。 158：谁可以讲道呢？回答：只有具备充分的恩赐（提前3：2；弗4：8－11；阿4：6；玛2：7；林后3：6），并得到适当的认可，蒙召从事这一职份的人（耶14：15；罗10：15；来5：4；林前12：28－29；提前3：10；4：14；5：22），才能讲道。 159：蒙召讲道的人应当如何讲道？回答：蒙召讲道的人，是上帝圣言的工人，应当传讲纯正的教义（多2：1，8），殷勤作工（徒18：25），无论得时不得时，总要专心（提后4：2）；表达清楚（林前14：19），不用人智慧委婉的言语，乃是用圣灵和大能的明证（林前2：4），把上帝各样的旨意传讲全备（徒20：27）；根据听众的需要和能力，用诸般的智慧（西1：28；提后2：15），把上帝的话应用出来（林前3：2；腓1：15－17）；心里火热（徒18：25），爱上帝（林前3：2；腓1：15－17），爱上帝的子民（西4：12；林后12：15）；诚诚实实（林后2：17；4：2），目的在于使上帝得荣耀（帖前2：4－6；约7：18），使上帝的子民悔改归正（林前9：19－22），得造就（林后12：19；弗4：12），得救赎（提前4：16；徒26：16－18）。 160：对听道的人有什么要求？回答：那些听道的人，要以勤勉（箴8：34；）、预备（彼前2：1－2；路8：18）和祷告（诗119：18；弗6：18－19）之心来听道；对于所听到的内容要考察圣经（徒17：11）；以信心（来4：2）、爱心（帖后2：10）、谦卑（雅1：21）和愿意的心（徒17：11），把所听到的真理作为上帝之道予以领受（帖前2：13）；默想（路9：44；来2：1），谈论（路24：14；申6：6－7）；藏在心里（箴2：1；诗119：11），并在自己的生命中结出果子来（路8：15；雅1：25）。 161：圣礼怎样成为救赎的有效工具？回答：圣礼成为救赎的有效工具，并非因其本身有什么权能，也不是因为源自施行者的敬虔或动机而发出的力量，而是惟独因着圣灵的运行，和基督的祝福，因他是圣礼的设立者（彼前3：21；徒8：13，23；林前3：6－7；12：13）。 162：圣礼是什么？回答：圣礼是基督在他的教会中所设立的圣约（创17：7，10；出12；太28：19；26：26－28），向那些在恩典之约中的人（罗15：8；出12：48），象征、引证、表明（罗4：11；林前11：24－25）他中保的恩惠（徒2：38；林前10：16）；坚固、增强他们的信心，以及其它各样的恩惠（罗4：11；加3：27）；约束他们顺服（罗6：3－4；林前10：21）；见证、分享他们彼此之间的爱心和交通（弗4：2－5；林前12：13）；并使他们与那些不得参与的人分别出来（弗2：11－12；创34：14）。 163：圣礼有哪几方面？回答：圣礼有两方面；一方面是外在的可见记号，是根据基督的吩咐而使用的；一是其所象征的内在属灵的恩惠（太3：11；彼前3：21；罗2：28－29）。 164：新约时代，基督在他的教会中设立了多少圣礼？回答：新约时代，基督在他的教会中只设立了两大圣礼，一是洗礼，一是圣餐（太28：19；林前11：23）。 165：洗礼是什么？回答：洗礼是新约的圣礼。基督吩咐奉父、子、圣灵的名为人用水施洗（太28：19），作为与基督联合（加3：27），因着他的宝血罪得赦免（可1：4；启1：5），因着他的圣灵而重生（多3：5；弗5：26）的标记与印证；也是得儿子的名分（加3：26－27），复活得永生（林前15：29；罗6：5）的标记与印证；由此受洗者庄严地归入有形教会（林前12：13），公开承认，与主有约，全人归主，且惟独属主（罗6：4）。 166：应当为谁施洗？回答：对那些处于有形教会之外，在应许之约上是局外人者，直到他们公开承认归信基督，并顺服他，才可为他们施洗（徒8：36－38），若父母双方，或其中一方，已公开承认归信基督并顺服他，则其婴孩亦在恩约之内，应予施洗（创17：7，9；加3：9，14；西2：11－12；徒2：38－39；罗4：11－12；林前7：14；太28：19；路18：15－16；罗11：16）。 167：如何增进我们的洗礼呢？回答：我们需要增进我们的洗礼，这一责任受到了很大的忽视。这是长达一生一世的事，特别是在受试探的时候，当我们出席他人受洗的时候，更要增进我们的洗礼（西2：11－12；罗6：4，6，11）；增进的方法就是：以感恩的心认真地思考洗礼的性质，基督设立洗礼的目的，洗礼所传递所印证的特权和恩惠，以及我们受洗时所发的庄重誓言（罗6：3－5）；要因我们的罪污，对洗礼之恩和责任的亏负、背离而谦卑下来（林前1：11－13；罗6：2－3）；逐渐长进，确信罪已蒙赦，以及其它在洗礼中所印证的各样福分（罗4：11－12；彼前3：21）；从基督的受死与复活中吸取力量，我们受洗是归入他，为要我们在罪中死去，在恩典里复活（罗6：3－5）；努力靠信心生活（加3：26－27），在圣洁与公义中相通（罗6：22），正如那些在洗礼中把自己的名字交托给基督的人一样（徒2：38）；弟兄姊妹彼此相爱，因为我们由同一圣灵受洗，归入同一身体（林前12：13，25－27）。 168：圣餐是什么？回答：圣餐是新约的圣礼。我们在其中照耶稣基督的吩咐，分发并领受饼酒，他的受死在其中显明出来（路22：20）；那些配领受的人吃喝他的体与血，得属灵的滋养，在恩典中长进（太26：26－28；林前11：23－26）；他们与基督的联合和交通得以坚固（林前10：16）；见证并更新他们的感恩（林前11：24）、与上帝的圣约（林前10：14－16，21）、彼此之间的爱与团契，同为奥秘身体的肢体（林前10：17）。 169：基督如何指定在圣餐中分发饼酒？回答：基督指定牧师，在圣餐这一圣礼之中，藉着宣读设立之道，感恩，并祷告，把饼酒从通常的用途中分别出来；拿起饼来，掰开，把饼与酒都分发给领受者，他们也同样根据基督的吩咐，拿起饼来吃下，再喝那酒，以感恩的心记念基督的身体为他们而舍，基督的宝血为他们而流（林前11：23－24；太26：26－28；可14：22－24；路22：19－20）。 170：在圣餐中，那些配领受的人如何吃喝基督的体与血呢？回答：在圣餐中，基督的体与血既非物质地或属肉体地临在于饼酒之中，也不是与饼酒同在，也不是在饼酒之下（徒3：21），而是属灵地向领受者的信心临在，这种临在的真实性正如饼酒本身对于他们的外部感官的真实性一样（太26：26，28）；所以，那些在圣餐中配领受的人，确实在其中吃喝基督的体与血，并不是以物质的属肉体的方式，而是以属灵的方式；他们虽是藉着信心，却也是真实地（林前11：24－29）领受钉十字架的基督，以及他受死的一切恩惠，并在自己的生命中运用出来（林前10：16）。 171：在来领受圣餐之前，那些来领受的人应当怎样预备自己？回答：在来领受圣餐之前，那些来领受的人，应当省察自己（林前11：28）是否有基督在心里（林后13：5），并省察自己的罪和亏欠（林前5：7；出12：15）；省察对真理的遵行、知识（林前11：29）、信心（林前13：5；太26：28）和悔改（亚12：10；林前11：31）的程度；对上帝的爱，对弟兄的爱（林前10：16－17；徒2：46－47），对众人的爱（林前5：8；11：18，20），是否饶恕了那些得罪自己的人（太5：23－24）；是否渴慕基督（赛55：1；约7：37），并有新的顺服（林前5：7－8）；重新操练这些恩典（林前11：25－26；来10：21，22，24；诗26：6），认真默想（林前11：24－25），恒切祷告（代下30：18－19；太26：26）。 172：怀疑自己不在基督里，或者怀疑自己没有作好正当的预备，这样的人可以来领受圣餐吗？回答：怀疑自己不在基督里，或者怀疑自己没有为领受圣餐作好正当的预备，这样的人或许是真的与基督有份，虽然他们对此还没有达到确信（赛1：10；约壹5：13；诗88；77：1－12；拿2：4，7）；假如他们真的是出于此种忧虑而受到影响（赛54：7－10；太5：3－4；诗31：22；73：13，22－23），确实渴慕自己是在基督里（腓3：8－9；诗10：17；42：1－2，5，11），并愿意脱离罪恶（提后2：19；赛50：10；诗66：18－20），就可能与上帝有份；因为有上帝的应许，而且上帝设立这一圣礼，就是要宽慰软弱有疑心的基督徒（赛40：11，29，31；太11：28；12：20；26：28），在这种情况下，他要为自己的不信忧伤（可9：24），努力消除自己的怀疑（徒2：37；16：30）；这样作之后，他可以并应当参加圣餐，使自己得以坚固（罗4：11；林前11：28）。 173：是不是所有公开承认信仰，并想参加圣餐的人，都可参加呢？回答：对信仰一无所知，肆意谤渎的人，尽管公开承认他们的信仰，并想参加圣餐，也可以并应当使用基督赐给其教会的权柄，禁止他们参加圣餐（林前11：27－31；太7：6；林前5；犹23；提前5：22），直到他们接受教训，有生命改变为止（林后2：7）。 174：在圣餐这一圣礼施行的时候，对那些领受的人有什么要求？回答：那些领受圣餐的人，在圣餐施行期间，要有至圣的敬畏之心，集中注意力，等候上帝（利10：3；来12：28；诗5：7；林前11：17，26－27），殷勤注视饼酒与动作（出24：8；太26：28），留心分辨主的身体（林前11：29），存爱心默想基督的受死和受苦（路22：19），由此激发自己更有力量地把他们所承受的恩典行出来（林前11：26；10：3－5，11，14）；分辨自己（林前11：31），为罪忧伤（亚12：10）；切切地渴慕基督（启22：17），藉着信心吃喝他（约6：35），领受他的丰满（约1：17），信靠他的慈爱（腓1：16），在他的大爱中欢喜（诗63：4－5；代下30：21），感谢他的恩典（诗22：26）；更新他们与上帝的圣约（耶50：5；诗50：5），并更新对众圣徒的爱（徒2：42）。 175：在领受圣餐之后，基督徒有什么责任？回答：在领受圣餐之后，基督徒有责任认真地思考：他们在领受圣餐时是怎样行的，哪些方面做到了（诗28：7；85：8；林前11：17，30－31）；若得到鼓励和安慰，就要为此而赞美上帝（王下30：21－23，25－26；徒2：42，46－47），求上帝继续施与（诗36：10；歌3：4；代下29：18），保持警醒，免得退步（林前10：3－5，12），完成自己所许的愿（诗51：4），勉励自己常常参加圣餐（林前11：25－26；徒2：42，46）；假如发现未得到什么恩惠，就要更加仔细地省察自己对圣餐的预备，和参加圣餐时的举动（歌5：1－6；传5：1－6）；在这两种情况下，假如他们对得起上帝和自己的良知，就当等待在一定的时候得着果子（诗123：1－2；42：5，8；43：3－5）；但是，假如他们在某个方面没有做到，就当谦卑下来（代下30：18－19；赛1：16，18），并在以后的日子更加慎重、殷勤地参加圣餐（林后7：11；代上15：12－14）。 176：洗礼和圣餐有什么共同的地方？回答：洗礼和圣餐的共同之处在于：二者都是由上帝设立的（太28：19；林前11：23）；其属灵的方面都是基督和他的恩惠（罗6：4－4；林前10：16）；都是同一恩典之约的标记（罗4：11；西2：12；太26：27－28），都由牧师施行，其他任何人都不得施行（约1：33太28：19；林前11：23；林前4：1；来5：4）；都要在基督的教会中一直延续下去，直到他再来（太28：19－20；林前11：26）。 177：洗礼和圣餐有何不同之处？回答：洗礼和圣餐的不同之处在于：洗礼只施行一次，是用水施洗，作为我们重生并与基督联合的标记和印证（太3：11；多3：5；加3：27），并且婴儿也当受洗（创17：7，9；徒2：38－39；林前7：14）；而圣餐则是经常施行的，是用饼与酒，来代表并显明基督就是灵魂属灵的滋养（林前11：23－26），坚固我们在他里面继续成长（林前10：16），并且只有年龄和能力达到能够自我省察的人才能领受(林前11：28－29)。 178：祷告是什么？回答：祷告就是奉基督之名（约16：23），藉着圣灵的帮助（罗8：26），把我们的愿望呈给上帝（诗62：8）；承认我们的罪（诗32：5－6；但9：4），并以感恩的心承认他的恩慈（腓4：6）。 179：我们只当向上帝祷告吗？回答：是的。惟独上帝鉴察人心（王上8：39；徒1：24；罗8：27），垂听呼求（诗65：2），赦免诸罪（弥7：18），并满足众人各样的心愿（诗145：18－19）；并且惟独上帝是可信的（罗10：14），惟独他能用宗教仪式加以崇拜（太4：10）；祷告也是崇拜的一个部分（林前1：2），只能向他祷告（诗50：15），不能向其他任何存在者祷告（罗10：14）。 180：奉基督的名祷告是什么意思？回答：奉基督的名祷告就是：顺服他的诫命，确信他的应许，并为基督的缘故请求怜悯（约14：13－14；16：24；但9：17）；不是空空地提及他的名字（太7：21），而是从基督和他的中保职份，得鼓励而祷告，并在祷告时，从中得勇气，得力量，得祷告蒙悦纳的确信（来4：14－16；约壹5：13－15）。 181：为什么我们要奉基督的名祷告？回答：人的罪性，以及因此而导致的与上帝的疏离，是如此之大，不借助一位中保，我们就无法来到上帝的面前（约14：6；赛59：2；弗3：12）；这一荣耀的工作，除了基督之外，天上地下无人担任，无人适合（约6：27；来7：25－27；提前2：5），所以我们不能奉任何人的名字祷告，而是惟独奉他的名祷告（西3：17；来13：15）。 182：圣灵怎样帮助我们祷告？回答：我们本不晓得当怎样祷告，圣灵帮助我们的软弱，使我们能够明白为谁祷告，祷告什么，如何祷告；他又在我们的心中动工，感动我们（虽然并不是在所有人的心中，也不是在所有的时候，也不是以同样的程度），使我们有完成这一本分所需要的悟性、感情和恩典（罗8：26－27；诗10：17；亚12：10）。 183：我们当为谁祷告？回答：我们当为基督在地上的整个教会祷告（弗6：18；诗28：9）；为民政长官（提前2：1－2），为传道人（西4：3）；为我们自己（创32：11），为我们的弟兄（雅5：16），也为我们的敌人（太5：44）；为各种活着的人（提前2：1－2），也为将要来到这个世界的人（约17：20；撒下7：29）；但是，不要为死人祷告（撒下12：21－23），也不要为那些已经知道犯了至于死的罪的人祷告（约壹5：16）。 184：我们当为何事祷告？回答：我们当为一切使上帝得荣耀（太6：9），教会得益处（诗51：18；122：6），我们自身（太7：11）或他人（诗125：4）得益处的事祷告；但不应为非法之事祷告（约壹5：14）。 185：我们当怎样祷告？回答：我们祷告时要深深晓得上帝的威严（传5：1），深深明了自己的不配（创18：27；32：10）、需要（路15：17－19）和罪过（路18：13－14）；要以悔改的心（诗51：17）、感恩的心（腓4：6）、宽广的心（撒上1：15；2：1）祷告；要以悟性（林前14：15）、信心（可11：24；雅1：6）祷告，真诚（诗145：18；17：1）、恳切（雅5：16），有爱心（提前2：8），有恒心（弗6：18），等候上帝（弥7：7），并谦卑地降服于他的旨意之下（太26：39）。 186：为要尽祷告的本分，上帝赐给了我们什么准则？回答：上帝所有的圣言都是用于指导我们尽祷告本分的（约壹5：14）；而特别的指导准则，则是我们的救主基督教导门徒祷告时所用的祷告形式，亦即通常所称的主祷文（太6：9－13；路11：2－4）。 187：如何使用主祷文？回答：主祷文不仅有指导作用，是一个祷告的模式，我们可以依此作其它的祷告；也可用作一个祷告，要以悟性、信心、敬畏，和其它所必需的恩典，来正确地尽祷告的本分，作如此的祷告（太6：9；路11：2）。 188：主祷文分几个部分？回答：主祷文分三个部分：序言、祈求和结束。 189：主祷文的序言教训我们什么？回答：主祷文的序言是：“我们在天上的父”（太6：9）。这教训我们，当祷告的时候，我们要就近上帝，确信他父般的慈爱，而且我们的好处不在他之外（路11：13；罗8：15）；要有敬畏之心，以及其它各种孩子般的性情（赛64：9），属天的情感（诗123：1；哀3：41），并正确地认识他的主权、威严和恩惠的临在（赛63：15－16；尼1：4－6）；同时，也教训我们要与他人一起祷告，并为他人祷告（徒12：5）。 190：我们在第一祈求中求什么？回答：我们在第一祈求“愿人都尊你的名为圣”中（太6：9），承认我们自身以及其他所有的人，要正确地荣耀上帝，既没有能力，也不愿意（林后3：5；诗51：15），因此我们祈求上帝，藉着他的恩典使我们和他人都能够晓得、承认，并高度尊崇他（诗67：2－3）、他的尊称（诗83：18）、属性（诗86：10－13，15）、法令、话语（帖后3：1；诗147：19－20；138：1－3；林后2：14－15）和作为，以及他乐意用于显明自身的一切（诗145；8）；在心思、言语（诗103：1；19：14），和行为（腓1：9，11）上荣耀他：求他拦阻、消除无神论（诗67：1－4），无知（弗1：17－18），偶像崇拜（诗97：7）、亵渎（诗74：18，22－23），以及一切不荣耀他的事（王下19：15－16）；并求他藉其统管万有的护理，引导并安排万事，使他自己得荣耀（代下20：6，10－12；诗83；140：4，8）。 191：我们在第二祈求中求什么？回答：我们在第二祈求 “愿你的国降临”中（太6：10），承认我们自身和全人类生来都处在罪恶和撒但的辖制之下（弗2：2－3），因此我们祈求，罪恶和撒但的国度毁灭（诗67：1，18；启12：1――11），福音在全世界得以广传（帖后3：1），犹太人被呼召（罗10：1），外邦人的日期满了（约17：9，20；罗11：25－26；诗67）；教会装备有各样的福音工人和典章（太9：38；帖后3：1），清除一切的腐败（太1：11；番3：9），得到民事政府的支持和保护（提前2：1－2）：使基督的律法得以纯正地执行，有效地使那些仍在罪中的人悔改归正，使那些已经悔改归正的人得坚固、安慰和建造（徒4：29－30；弗6：18－20；罗15：29－30，32；帖后1：11；2：16－17）；使基督在地上即在我们的心中掌权（弗3：14－20），使他的再来快快临到，我们与他一同作王，直到永永远远（启22：20）；祈求他按自己的美意在世上行使他的权柄，尽善尽美的成就这些目的（赛64：1－2；启4：8－11）。 192：在第三祈求中，我们为谁祷告？回答：我们在第三祈求“愿你的旨意行在天上，如同行在地上”中（太6：10），承认我们和所有的人，不仅天生就完全不能，也不愿意认识并遵行上帝的旨意（罗7：18；伯21：14；林前2：14），而且倾向于悖逆他的圣言（罗8：7），对上帝的护理牢骚满腹（出17：7；民14：2），一心想成就肉体和魔鬼的旨意（弗2：2），所以我们祷告，求上帝藉着他的圣灵，消除我们自身和他人的所有盲目（弗1：17－18）、软弱（弗3：16）、不情愿（太26：4－41），和心灵的悖逆（耶31：18－19）；求上帝藉着他的恩典，使我们能够，并且愿意在所有的事情上（诗119：1，8，35－36；徒21：14），都如天使在天上所作的那样（赛6：2－3；诗103：20－21；太18：10），谦卑（弥6：8）、喜乐（诗100：2；伯1：21；撒下15：25－26）、诚实（赛38：3）、勤勉（诗119：4－5）、热情（罗12：11）、认真（诗119：80）、持久（诗119：112），去认识、遵行、顺服上帝的旨意。 193：在第四祈求中，我们祷告什么？回答：在第四祈求“我们日用的饮食，今日赐给我们”中（太6：11），我们承认在亚当里，因着我们自己的罪，丧失了今生所有外界福分的权利，理当由上帝全部予以剥夺，我们在享用这些外界福分时，它们都已经受到了咒诅（创2：17；3：17；罗8：20－22；耶5：25；申28：15－68）；它们本身并不能维系我们的生命（申8：3），我们自己也无功劳可居（创32：10），而且靠我们自己的辛劳也无法取得它们（申8：17－18）；但我们都倾向于非法地追求（耶6：13；可7：21－22）、获取（何12：7）、享用这些福分（雅4：3）；因此我们为我们自身和他人祷告，求上帝使他们和我们等候上帝的护理，天天用合法的手段，靠他白白的恩赐，按他父般的智慧所看为最合适的，享受足够的部分（创43：12－14；创28：20；弗4：28；帖后3：11－12；腓4：6）；求上帝继续祝福我们，使我们得以圣洁、舒适地享用这些福分（提前4：3－5），并有知足之心（提前6：6－8）；求上帝使我们离开一切不利于今生养身和舒适的事物（箴30：8－9）。 194：在第五祈求中，我们祷告什么？回答：在第五祈求“免我们的债，如同我们免了人的债”中（太6：12），我们承认我们和其他所有人都有原罪和本罪的罪咎，因此对上帝的公义欠了债，而且不管是我们自己，还是其他任何受造物，都丝毫不能补偿此债（罗3：9－22；太18：24－25；诗130：3－4）；因此，我们为我们自身和他人祷告，祈求上帝出于他白白的恩典，藉着基督的顺服和补偿，由信心领悟并支取，免除罪给我们带来的罪咎和惩罚（罗3：24－26；来9：22），在他的爱子中接纳我们（弗1：6－7）；并祈求上帝继续恩待我们，（彼后1：2），饶恕我们天天的失败（何14：2；耶14：7），用平安和喜乐充满我们，天天赐给我们更大的罪得赦免的确信（罗15：13；诗51：7－10，12）；圣经鼓励我们这样祈求，并鼓励如此期望，当我们内心拥有此种印证的时候，我们就会发自内心地饶恕他人的过犯（路11：4；太6：14－15；太18：35）。 195：在第六祈求中，我们祷告什么？回答：在第六祈求“不叫我们遇见试探，救我们脱离凶恶”中（太6：13），我们承认，至智、至义、至慈的上帝，为了各种圣洁与公义的目的，或许吩咐万有，使我们受打击，遭挫折，一时陷于试探之中（代下32：31）；撒但（代上21：1）、世界（路21：34；可4：19）和肉体，时刻准备用力把我们拉到一边，陷害我们（雅1：14）；即使在我们罪得赦免之后，由于我们自身的败坏（加5：17）、软弱，不够警醒（太26：41），不仅易受试探，动辄就把自己暴露于试探之下（太26：69－72；加2：11－14；代下18：3；19：2），而且我们自身没有能力，也不愿意抵挡试探，脱离试探，善用试探（罗7：23－24；代上21：1－4；代下16：7－10）；因此，理当被弃置于试探的权势之下（诗81：11－12）。所以，我们祷告，祈求上帝制伏世界和其中的一切（约17：15），征服肉体（诗51：10；119：133），抑制撒但（林后12：7－8），治理万有（林前10：12－13），赐下并祝福各样蒙恩的工具（来13：20－21），激励我们警醒善用，使我们和他一切的子民，藉着他的护理蒙保守，不至受试探犯罪（太26：41；诗19：13）；即使受到试探，也求主藉着他的圣灵使我们得到强有力的扶持，能够在受试探的时候站立得稳（弗3：14－17；帖前3：13；犹24）；或者，即使跌倒，也再次站起，恢复过来（诗51：12），并予以圣洁地使用和改进（彼前5：8－10），使我们的成圣和救赎得以完全（林后13：7，9），使撒但被践踏在我们的脚下（罗16：20；亚3：2；路22：31－32），使我们完全从罪、试探及一切的邪恶中得释放，直到永远（约17：15；帖前5：23）。 196：在主祷文的结语中，教训我们什么？回答：在主祷文的结语“因为国度，权柄，荣耀，全是你的，直到永远”中（太6：13），教训我们在祈求中要竭力争辩（罗15：30），并不是因为我们自身有何价值，也不是因为其他任何受造物的缘故，而是出于上帝的缘故（但9：4，7－9，16－19）；也教训我们，在祷告中要赞美上帝（腓4：6），把永恒的主权、全能，与荣耀的尊称惟独归于他（代上29：10－13）；因为他能够并且愿意帮助我们（弗3：20－21；路11：13），所以，藉着信心，我们要坦然无惧地向他祈求（代下20：6，11），安静地依靠他，相信他会成全我们的请求（代下14：11）。为了表明这是我们的心愿，并是我们所确信的，我们就说“阿们”（林前14：16；启22：20－21）。 二零一七年八月九日]]></content>
      <categories>
        <category>信仰文章</category>
      </categories>
      <tags>
        <tag>信条</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[威斯敏斯特小教理问答]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E5%A8%81%E6%96%AF%E6%95%8F%E6%96%AF%E7%89%B9%E5%B0%8F%E6%95%99%E7%90%86%E9%97%AE%E7%AD%94%2F</url>
    <content type="text"><![CDATA[导读在韦斯敏斯德议会完成信条之后，又完成了大小两份《韦斯敏斯德问答》。大问答是在1648年完成，为了当时讲台信息的需要，依据信条的内容写成196个问答。其优点是完整、精确，并致力于圣经的原则解决道德的问题；而其缺点则是过于冗长而不够通俗，在律法的解释嫌教条化，因此较不著名。小问答虽是大问答的摘录，却较早完成（1647年）。此问答共有107条，内容简短易读，极受当时人的喜爱，本是为孩童及新信徒预备的；但在实际使用时，发现并不适用于儿童的学习，因为内容过于深奥，需要教导者加以解释说明。它不像《海德堡要理问答》那么温馨热情，但是它的字句清晰，逻辑清楚，可作为神学研究的入门。就如《韦斯敏斯德信条》一般，它也随英、苏的移民到达了美洲、澳洲、纽西兰及南非，成为英语体系长老会所遵奉的问答，甚至公理会也加以采用。此问答也曾以希伯来文、希腊文、拉丁文，及阿拉伯文出版，只是在欧洲大陆并不著名。尽管如此，它在复原教（Protestant）中，除了《小本基督徒要学》和《海德堡要理问答》之外，算是最通用的问答。 这两份问答的神学观点与《韦斯敏斯德信条》是一致的，在内容上可分为两个部分，第一部分的主题是神，包括神的特性，神的创造及救赎。第二部分则谈到人的责任，内容包括十诫的解释，信心及悔改的教义，以及人蒙恩的媒介，如：神的话、圣礼及祈祷。 正文：问1：人的主要目的是什么？答：人的主要目的就是荣耀神，永远以他为乐。 问2：神曾赐什么准则，指教我们怎样荣耀他，以他为乐？答：神的道，载于新旧两约圣经，就是唯一的准则，指教我们怎样荣耀神，以他为乐。 问3：圣经主要教导的是什么？答：圣经主要教导的就是人对于神所当信的真理，和神所要人当尽的本分。 第一部分：我们该信什么一、神是怎样的神问4：神是怎样的神？答：神是灵：他的本性，智慧，权能，圣洁，公义，恩慈，诚实，都是无限无量，无始无终，永无改变的。 问5：神是独一的吗？答：神是独一无二，又真又活的。 问6：神有几个位格？答：神有三个位格：就是圣父、圣子、圣灵：就是三位一体真神，本性相同，权能荣耀相等。 二、神曾作了什么问7：神的预旨是什么？答：神的预旨是他从永远所定的主意；根据他的美意，为了他自己的荣耀，预定一切将有的事。 问8：神怎样执行他的预旨？答：神用创造和护理之工来执行他的预旨。 三、创造问9：创造之工是什么？答：创造之工，是神用他全能的话，在六日之内，从无中造出万有，并且都甚好。 问10：神怎样造人？答：神以知识、公义、圣洁，并照着己的形象造男造女，并赐给他们制伏世界上一切被造之物的权柄。 四、护理问11：神的护理之工是什么？答：神的护理之工，就是用他至极的圣洁、智慧、权能，保护他所造的万物，并且管理他们一切的动作。 问12：神造人的时候，怎样突显护理之工？答：神既造了人，就以完全顺服为条件，与人立了生命之约，禁止人吃分别善恶树的果子，说明若吃，必受死亡的刑罚。 五、人如何犯罪问13：始祖守住他们被造的地位吗？答：始祖既靠自由意志得罪了神，就从被造的地位堕落了。1．传七29：神造人原是正直，但他们寻出许多巧计。 问14：罪是什么？答：凡不遵守或违背神的律法的，都是罪。1．约壹三4：凡犯罪的，就是违背律法：违背律法的就是罪。 问15：始祖犯了什么罪，就从被造的地位堕落了呢？答：始祖因吃了禁果，就从被造的地位堕落了。 六、人犯罪的结果问16：亚当初次犯罪，世人都和他一同堕落吗？答：神和亚当立的约，不是单为他自己，也是为他的后裔，所以凡从亚当按常例而主的人，都在亚当初次的过犯中和他一同犯了罪，一同堕落了。 问17：始祖堕落将世人陷在什么境况中？答：始祖堕落将世人陷在罪恶和悲惨的境况中。略解：亚当的第一个罪，一般称之为堕落。这里告诉我们，由于此堕落，所有世人就生在罪与抑郁不乐中。罗五12：这就如罪是从一人入了世界，死又是从罪来的；于是死就临到众人，因为众人都犯了罪。 问18：世人陷在罪恶境况中，那个罪恶在于什么？答：世人陷在罪恶境况中，那个罪恶在于：一、亚当初犯的罪孽，二、原来义性的丧失，三、全性的腐败，就是通常所说的原罪，四、各人从原罪所发生的本罪。 问19：世人在堕落境况中的悲惨是什么？答：全人类由于堕落丧失与神的交往，反落在神忿怒和咒诅之下，因此应受今生一切的愁苦和死亡，以及地狱永久的痛苦。 七、救恩问20：神任凭世人在罪恶和愁苦中沉沦吗？答：神既从无始的已往凭着自己的美意，拣选了许多人得永远的生命，就为他们设下恩典之约，要藉着一位救主，救他们脱离罪恶和愁苦，而进入拯救的地位。 问21：谁是选民的救主？答：神选民惟一的救主是主耶稣基督，他既从永远就是神的儿子，但到了时候，降世为人，此后神人两性分清，而成为一位，直到永远。 问22：基督既为神的儿子，怎样成为人？答：神的儿子基督成为人，乃是取人实在的身体和理性的灵魂，藉着圣灵的能力，在童贞女马利亚的腹中成胎而生，但是没有罪。 八、基督的拯救工作问23：基督作我们救主所执行的职分是什么？答：基督作我们的救主，在降卑与升高的境况中执行先知、祭司、君王的职分。 问24：基督怎样执行先知的职分？答：基督执行先知的职分，在于用他的道和圣灵，将神的旨意指示我们，为要叫我们得救。 问25：基督怎样执行祭司的职分？答：基督执行祭司的职分，在于将他自己一次献为祭，以满足人对神的公义所有的亏欠，而使我们与神和好，并且时常为我们祷告。 问26：基督执行君王的职分？答：基督怎样执行君王的职分，在于克服我们，使我们归向他；又管理保护我们，并且抑制或征服他的和我们的仇敌。 问27：基督的降卑在于什么？答：基督的降卑在于他降生为人，主在卑微的环境中，处在律法之下，忍受今生的苦难，神的震怒，和十字架被咒诅的死，又被埋葬，暂时服于死权之下。 问28：基督的升高在于什么？答：基督的升高，在于他第三日复活，升天，坐在父神的右边，并在来日来审判世界。 九、圣灵的拯救工作问29：我们怎能领受基督所赢得的赎罪之恩？答：我们领受基督所赢得的赎罪之恩，是靠着圣灵，使这恩在我们心里发生效力。 问30：圣灵怎样使基督赎罪之恩在我们心里发生效力？答：圣灵使基督赎罪之恩在我们心里发生效力，乃是藉着他的感动，使我们有信心，又藉着他有效的恩召，使我们和基督有连属。 问31：有效的恩召是什么？答：有效的恩召是神所成的工作，用以使我们觉悟自己的罪恶和苦难，又光照我们的心，使我们认识基督，并更新我们的心志，于是说服我们，叫我们能接纳在福音中所白白传授给我们的耶稣基督。 十、救恩在今世的益处问32：人蒙了有效的恩召，在今生得什么益处？答：人蒙了有效的恩召，在今生所得的益处就是称义，儿子的名分，成圣，并这些在今生所带来的一切福乐。 问33：称义是什么？答：称义是神白白恩典的作为，神藉此白白赦免我们一切的罪恶，悦纳我们在他面前为义人，这原因是他将基督的义算为我们的，而我们只凭信心接纳了。 问34：儿子的名分是什么？答：儿子的名分是神白白恩典的作为，神藉此就将我们收纳在他众子的数内，又使我们享有神众子一切利益的特权。 问35：成圣是什么？答：成圣是神鸿恩的工作，就是他按着自己的形象，更新我们的全人性，叫我们越久越能在罪上死，并向义而活。 问36：称义、儿子的名分与成圣，在今生所带来给我们的福乐是什么？答：称义、儿子名分与成圣，在今生所带来给我们的福乐，就是确知神的慈爱，得良心的平安，在圣灵中的喜乐，在恩惠上的长进，并在恩典中得蒙保守，一直到底。 十一、救恩在死后的益处问37：信徒临终的时候，从基督得什么益处？答：信徒临终的时候，灵魂就得以完全成圣，立刻进入荣耀里，他们的身体既与基督仍旧联合，就在坟墓里安然歇息，直等到复活的时候。 问38：在复活的时候，信徒从基督得什么益处？答：在复活的时候，信徒要在荣耀中复活，又将在审判的日子，当众人面前被主承认，又被断定无罪，于是满心得福，以神为乐，直到永远。 第二部分：我们该作什么一、道德律问39：神所要人尽的本份是什么？答：神所要人尽的本份，就是顺从他所启示的旨意。 问40：神起初赐给人什么法则叫人顺从？答：神起初启示人叫他顺从的法则，就是道德的律法。略解：罗二14～15：没有律法的外邦人，若顺着本性行律法上的事，他们虽然没有律法，自己就是自己的律法。这是显出律法的功用刻在他们心里。 问41：道德律法的大意，包括在什么里面？答：道德律法的大意包括在十诫里面。 问42：十条诫命的总纲是什么？答：十条诫命的总纲，就是要尽心，尽性，尽意，尽力爱我们的神，并且爱人如己。 问43：十条诫命的序言说什么？答：十条诫命的序言说：我是耶和华你的神，曾将你从埃及地为奴之家领出来。 问44：十条诫命的序言对我们有什么教训？答：十条诫命序言的教训就是：因为耶和华是神，也是我们的神，又是我们的救主，所以我们应当遵守他一切的诫命。 二、第一诫问45：第一条诫是什么？答：第一条诫是：除了我以外，你不可有别的神。 问46：第一条诫吩咐我们作什么？答：第一条诫吩咐我们认识神，并且承认他是独一的真神，又是我们的神，因此我们当敬拜荣耀他。 问47：第一条诫禁止我们作什么？答：第一条诫禁止我们弃绝真神，不敬拜他，不荣耀神，不以他为神，也不以他为我们的神，也禁止我们将那只当归给神的敬拜和荣耀给任何受造之物。 问48：第一条诫「除了我以外」，这几个字的意思是什么？答：第一条诫「除了我以外」（原文说在我面前）这几个字的意思是：那鉴察万物的神，留心观看，并且十分憎恶人敬拜别神的罪。 三、第二诫问49：第二条诫是什么？答：第二条诫是：不可为自己雕刻偶像，也不可作什么形象，仿佛上天，下地，和地底下，水中的百物；不可跪拜那些像，也不可事奉它，因为我耶和华你的神是忌邪的神。恨我的，我必追讨他的罪，自父及子，直到三四代；爱我，守我诫命的，我必必向他们发慈爱，直到千代。 问50：第二条诫吩咐我们作什么？答：第二条诫吩咐我们将神在圣经中所规定一切有关宗教的崇拜与规则，都领受遵从，并保守纯全。 问51：第二条诫禁止我们作什么？答：第二条诫禁止我们用形象拜神，或用圣经所未规定的任何方法拜他。 问52：我们为什么当守第二条诫？答：我们当守第二条诫，因为惟独神在我们身上是有主权的，我们是他的子民，并且神切切要我们专心敬拜他。 四、第三诫问53：第三条诫是什么？答：第三条诫是：你不可妄称耶和华你神的名，因为妄称耶和华名的，耶和华必不以他为无罪。 问54：第三条诫吩咐我们作什么？答：第三条诫吩咐我们当存圣洁恭敬的心来用神的一切名字，称呼，属性，规则，圣经的话，和工作。 问55：第三条诫禁止我们作什么？答：第三条诫禁止我们亵渎或妄用神所藉以彰显自己的任何事物。 问56：我们为什么当守第三条诫？答：我们当守第三条诫，因为犯这条诫，虽能逃避人的刑罚，却不能逃脱神公义的审判。 五、第四诫问57：第四条诫是什么？答：第四条诫是：当记念安息日，守为圣日。六日要劳碌作你一切的工，但第七日是向耶和华你神当守的安息日：这一日你和你的儿女，仆婢，牲畜，和你城里寄居的客旅，无论何工都不可作，因为六日之内，耶和华造天地海，和其中的万物，第七日便安息，所以耶和华赐福与安息日，定为圣日。 问58：第四条诫吩咐我们作什么？答：第四条诫吩咐我们将神在圣经中所规定每七日内的一整天，守为他的圣安息日。 问59：神规定第七日的那一日为安息日？答：从世界起始直到基督复活，神规定七日内的第七日为安息日，此后规定七日的头一日为基督徒的安息日，直到世界的末日。 问60：当如何守安息日为圣？答：守安息日为圣当整天有圣洁的休息，连平日合法的俗事和娱乐也不可作；除了作必需的和怜悯人的事外，一天的工作都当归与神，或同众人，或在家中敬拜神。 问61：第四条诫禁止我们作什么？答：第四条诫禁止我们忽略安息日所当尽的本分，也禁止以闲懒妄用此日，或作那本来为罪的事：又禁止我们思想、谈论和办理一切不必要的俗事和娱乐。 问62：我们为什么当守安息日？答：我们当守安息日，因为神吩咐我们六日内要劳碌作自己一切的工作，特留第七日作为他的日子，他也给我们作榜样，并赐福与安息日。 六、第五诫问63：第五条诫是什么？答：第五条诫是：当孝敬父母，使你的日子在耶和华你神所赐你的地上，得以长久。1．出廿12。 问64：第三条诫吩咐我们作什么？答：第五条诫吩咐我们当保守各人的名誉，无论在上，在下，或平等的，总要按着自己的等次和地位，向他尽本份。 问65：第五条诫禁止我们作什么？答：第五条诫禁止我们轻忽或损害各人按他的等次和地位所当得的尊贵，和所当受的事奉。1．罗十三7～8：凡人所当得的，就给他：当得粮的，给他纳粮；当得税的，给他上税；当惧怕的，惧怕他；当恭敬的，恭敬他。凡事都不可亏欠人，惟有彼此相爱。 问66：我们为什么当守第五条诫？答：我们当守第五条诫，因为神应许凡遵守这条诫的（只就能荣耀神而与自己有益处来说），在世得享长寿与繁荣。 七、第六诫问67：第六条诫是什么？答：第六条诫是：你不可杀人。1．出廿13：不可杀人。 问68：第六条诫吩咐我们作什么？答：第六条诫吩咐我们尽力依法保全自己的生命，和别人的生命。1．弗五29：从来没有人恨恶自己的身子，总是保养顾惜。2．诗八二3～4：当为困苦和穷乏的人施行公义。当保护贫寒和穷乏的人，救他们脱离恶人的手。伯廿九13：将要灭亡的，为我祝福；我也使寡归心中欢乐。 问69：第六条诫禁止我们作什么？答：第六条诫禁止我们自杀，非法杀人，和一切关于害人的事。1．徒十六28：保罗大声呼叫说，不要伤害自己！2．创九6：凡流人血的，他的血也必被人所流。3．箴廿四11～12：人被拉到死地，你要解救：人将被杀，你须拦阻。你若说：「这事我未曾知道。」那衡量人心的，岂不明白么？ 八、第七诫问70：第七条诫是什么？答：第七条诫是：你不可奸淫。出廿14：不可奸淫。 问71：第七条诫吩咐我们作什么？答：第七条诫吩咐我们无论存心，说话，行事，都要保守自己，和别人的纯洁。1．提后22：你要逃避少年的私欲，同那清心祷告主的人追求公义，信德，仁爱，和平。2．西四6：你们的言语要常常带着和气，好像用盐调和。3．彼前三2：这正是因看见你们有贞洁的品行和敬爱的心。4．帖前四4：要你们各人晓得怎样用圣洁尊贵，守着自己的身体。5．弗五11～12：那暗昧无益的事，不要与人同行，倒要责备行这事的人：因为他们暗中所行的，就是提起来，也是可耻的。 问72：第七条诫禁止我们作什么？答：第七条诫禁止我们一切不纯洁的意念，言语和行为。略解：这条诫是关于纯洁，吩咐我们在思想、言语、行为上要纯洁，严禁一切不纯洁与不正经。它承认，神是身体与灵魂的所有人，并且有权吩咐人为了他而将身体灵魂保守纯洁与神圣。1．太五28：凡看见妇女就动淫念的，这人心里已经与她犯奸淫了。2．弗五4：淫词，妄语，和戏笑的话，都不相宜。3．弗五3：淫乱并一切污秽，在你们中间连提都不可。 九、第八诫问73：第八条诫是什么？答：第八条诫是：你不可偷盗。出廿15：不可偷盗。 问74：第八条诫吩咐我们作什么？答：第八条诫吩咐我们合法的获得并增进自己的财富和别人的财富。1．罗十二17：众人以为美的事，要留心去作。2．箴廿七23：你要详细知道你羊群的景况，留心料理你的牛群。3．利廿五35：你的弟兄在你那里若渐渐贫穷，手中缺乏，你就要帮补他。 问75：第八条诚禁止我们作什么？答：第八条诫禁止我们非法的妨碍自己和别人财富的增进。 十、第九诫问76：第九条诫是什么？答：第九条诫是：你不可作假见证陷害人。出廿16：不可作假见证陷害人。 问77：第九条诫吩咐我们作什么？答：第九条诫吩咐我们与人交往，总要诚实，又要保守自己和别人的名誉，若作见证，更当如此。1．亚八16：各人与邻舍说话诚实。2．彼前三16：存着无亏的良心，叫你们在何事上被毁谤，就在何事上可以叫那诬赖你们在基督里有好品行的人，自觉羞愧。徒廿五10：保罗说，我站在该撒的堂前，我向犹太人并没有行过什么不义的事。3．约叁12：低米丢行善，有众人给他作见证，又有真理给他作见证；就是我们也给他作见证。4．箴十四5：诚实见证人，不说谎话。十四25：作真见证的，救人性命。 问78：第九条诫禁止我们作什么？答：第九条诫禁止我们作一切不合乎真理的事，并一切损害自己和别人名誉的事。 十一、第十诫问79：第十条诫是什么？答：第十条诫是：你不可贪恋人的房屋，你不可贪恋人的妻子，仆婢，牛驴，并他一切所有的。出廿17。 问80：第十条诫吩咐我们作什么？答：第十条诫吩咐我们无论处什么境遇，总要知足，并要对别人和他一切所有的，存正当的爱心。1．来十三5：你们存心不可贪爱钱财，要以自己所有的为足。2．罗十二15：与喜乐的人要同乐，与哀哭的人要同哭。林前十三4～6：爱是恒久忍耐，又有恩慈；爱是不嫉妒：爱是不自夸，不张狂，不作害羞的事，不求自己的益处，不轻易发怒，不计算人的恶，不喜欢不义，只喜欢真理。 问81：第十条诫禁止我们作什么？答：第十条诫禁止我们不满意自己的境遇或嫉妒别人的福分，而对他所有的起贪恋的私心。 十二、律法的刑罚问82：神的诫命有人能守得完全吗？答：从始祖犯罪以来，除了耶稣以外，没有人能在令生将神的诫命守得完全，反倒在意念、言语和行为上，天天违背神的诫命。 问83：违背诫命的罪都同样可恶吗？答：违背诫命的罪不都同样可恶，因为罪本身的轻重或人犯罪的情形有所不同，所以有的罪在神眼中就比别的罪更可恶。 十三、得救之法问85：为要逃脱因罪当受神的义怒和咒诅，神吩咐我们作什么？答：为要逃脱罪所当受的义怒和咒诅，神吩咐我们信服耶稣基督，悔改以致得永生，以及勤用基督所设立一切外部的蒙恩之法，好叫救赎的益处归于我们。 问86：信服耶稣基督是什么？答：信服耶稣基督是神所赐的救恩，使我们照着福音的信息与劝勉接纳基督，唯独靠他得救。 问87：悔改以致得永生是什么？答：悔改以致得永主是神所赐的救恩，使罪人因真觉悟自己的罪，又确知神在基督里的恩慈，就痛心懊悔，恨恶并离开自己的罪，归向神，立志竭力重新顺从。 问88：基督设立什么外部的蒙恩之法，好叫救赎的益处归于我们？答：基督为叫救赎的益处归于我们，所设立那明显而常用蒙恩之法是：圣经、圣礼和祷告；这些都有效力叫蒙选的人得救。 十四、圣经是蒙恩的凭藉问89：圣经怎样有救人的效力？答：神的灵时常藉着人诵读，和听讲圣经使罪人醒悟，认罪回转，并藉着信心在成圣与安慰上被建立，以致得救。 问90：圣经必须怎样读，怎样听，才可有救人的效力？答：要叫圣经有效人的效力，我们必须留心，殷勤，以预备、祷告的态度来学习圣经的话，用信心和爱心领受而存在心里，又在日常生活中实行出来。 十五、圣礼是蒙恩的凭藉问91：圣礼怎样有救人的效力？答：圣礼有救人的效力，不是因为圣礼本身有能力，也不是因为行礼的人有能力，乃唯独藉基督所赐的恩典，和圣灵在那些以信领受的人心中所作的工作。 问92：圣礼是什么？答：圣礼是基督所设立的仪式，用具体之物将基督和新约的益处向信徒表明、印证，而运用在他们心里。 问93：新约的圣礼有几个？答：新约的圣礼有两个，就是洗礼和主的晚餐。 十六、洗礼问94：洗礼是什么？答：洗礼是奉父子圣灵的名，用水一洗，表明且印证我们与耶稣有连属，可以承受恩约的益处，并且自己应许作属主的人。 问95：谁当受洗礼？答：有形教会以外的人，必须等他们信了基督，又应许顺从基督，才可受洗；只是有形教会内信徒的婴孩都当受洗礼。 十七、主餐问96：主的晚餐是什么？答：主的晚餐是照着基督所规定的，授受饼和酒，以表明主的死，按理领受的人：不凭肉体，乃凭信心，分领主的身体和血，并他一切的益处，以致灵性得养育，在恩典上有长进。 问97：要为按理领受主的晚餐，必须怎样？答：为要按理领受主的晚餐，必须自己省察：有没有属灵的知识，可以分辨是主的身体，能不能凭信心以主为食物，有没有悔改的心、爱心，并重新顺从的心，免得因不按理吃喝，就自取审判。 十八、祷告是蒙恩的凭藉问98：祷告是什么？答：祷告是奉耶稣的名，又认自己的罪，并诚实感谢神诸般的恩慈，向神祈求心中所愿，而又合乎神旨意的事。 问99：神赐什么准则指教我们怎样祷告？答：全部圣经都指教我们怎样祷告，但有基督教导门徒的主祷文，特为我们祷告的准则。 十九、主祷文问100：主祷文的首句教导我们什么？答：主祷文的首句：「我们在天上的父」，教导我们存圣洁恭敬的心，坦然无惧的恭敬神，如同儿女亲近父亲一样，笃信他肯听且能帮助我们，并且教导我们要和人一同祷告，又要为人祷告。 问101：我们在主祷文第一条求什么？答：主祷文第一条说：「愿人都尊你的名为圣。」我们在此求神赐力量，叫我们和众人在他自己所显明的一切事上能荣耀他的名，并求他为自己的荣耀处理万事。 问102：我们在主祷文第二条求什么？答：主祷文第二条说：「愿你的国降临。」我们在此求神叫撒但的国衰败，叫他恩典的国兴旺，使自己和众人得以进入而常久在内，并求他荣耀的国早日降临。 问103：我们在主祷文第三条求什么？答：主祷文第三条说：「愿你的旨意行在地上，如同行在天上。」我们在此求神赐恩，叫我们能凡事甘心乐意的学习，遵从，顺服他的旨意，如同在天上的天使一样。 问104：我们在主祷文第四条求什么？答：主祷文第四条说：「我们日用的饮食，今日赐给我们。」我们在此求神开恩赐我们今生所需要的够用而美善的东西，并使我们同时得享他的福乐。 问105：我们在主祷文第三条求什么？答：主祷文第五条说：「免我们的债，如同我们免了人的债。」我们在此求神开恩，因基督的缘故白白饶恕我们一切的罪，我们所以敢这样求，因为我们蒙了神的恩典，才能从心里饶恕人。 问106：我们在主祷文第六条求什么？答：主祷文第六条说：「不叫我们遇见试探，救我们脱离那恶者。」我们在此求神保守我们不受试探而犯罪，或在受试探时扶助我们并拯救我们脱离凶恶。 问107：主祷文的结语教导我们什么？答：主祷文的结语说：「因为国度、权柄、荣耀，全是你的，直到永远，阿们。」这是教导我们惟独神能应允我们的祷告，并且祷告的时候当称赞他，将国度、权柄、荣耀都归于他，末了为要证明所求的是诚心所愿，又深信这是必蒙应允，就说：「阿们。」]]></content>
      <categories>
        <category>信仰文章</category>
      </categories>
      <tags>
        <tag>信条</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[liberty安装adminCenter && jython监控liberty]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fliberty%E5%AE%89%E8%A3%85adminCenter%2F</url>
    <content type="text"><![CDATA[描述如果 Liberty 安装没有服务器，请创建 Liberty 服务器。例如，在命令窗口中的 wlp/bin 目录，创建名为 myServer 的服务器。1server create adminSrv 说明：该示例命令将服务器文件添加到 wlp/usr/servers/adminSrv 目录。 配置配置server.xml文件如下：1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;server description="new server"&gt; &lt;!-- Enable features --&gt; &lt;featureManager&gt; &lt;feature&gt;jsp-2.2&lt;/feature&gt; &lt;!--安装管理中心--&gt; &lt;feature&gt;adminCenter-1.0&lt;/feature&gt; &lt;!--增加监控功能--&gt; &lt;feature&gt;monitor-1.0&lt;/feature&gt; &lt;/featureManager&gt; &lt;!-- To access this server from a remote client add a host attribute to the following element, e.g. host="*" --&gt; &lt;httpEndpoint id="defaultHttpEndpoint" httpPort="9089" httpsPort="9449" host="*"/&gt; &lt;!-- Automatically expand WAR files and EAR files --&gt; &lt;applicationManager autoExpand="true"/&gt; &lt;!--adminCenter的用户名和密码--&gt; &lt;quickStartSecurity userName="admin" userPassword="admin"/&gt; &lt;!--key.jks证书的密码该证书自动生成--&gt; &lt;keyStore id="defaultKeyStore" password="123456"/&gt;&lt;/server&gt; 启动server启动SERVER如下12345678910111213[was@kube-mini bin]$ sh server run adminSrvLaunching adminSrv (WebSphere Application Server 16.0.0.2/wlp-1.0.13.cl160220160526-2258) on IBM J9 VM, version pxa6480sr3fp12-20160919_01 (SR3 FP12) (en_US)[AUDIT ] CWWKE0001I: The server adminSrv has been launched.[AUDIT ] CWWKZ0058I: Monitoring dropins for applications.[AUDIT ] CWWKF0012I: The server installed the following features: [servlet-3.0, jsp-2.2, ssl-1.0, jndi-1.0, json-1.0, adminCenter-1.0, distributedMap-1.0, jaxrs-1.1, restConnector-1.0].[AUDIT ] CWWKF0011I: The server adminSrv is ready to run a smarter planet.[AUDIT ] CWWKT0016I: Web application available (default_host): http://10.244.3.0:9089/ibm/api/[AUDIT ] CWWKT0016I: Web application available (default_host): http://10.244.3.0:9089/IBMJMXConnectorREST/[AUDIT ] CWWKT0016I: Web application available (default_host): http://10.244.3.0:9089/ibm/adminCenter/serverConfig-1.0/[AUDIT ] CWWKT0016I: Web application available (default_host): http://10.244.3.0:9089/ibm/adminCenter/explore-1.0/[AUDIT ] CWWKT0016I: Web application available (default_host): http://10.244.3.0:9089/adminCenter/[AUDIT ] CWWKT0016I: Web application available (default_host): http://10.244.3.0:9089/snoop/[AUDIT ] CWWKZ0001I: Application snoop started in 0.319 seconds. 访问控制台：1https://192.168.10.32:9449/adminCenter/login.jsp REST Connector API 监控将 REST 连接器文件复制到 Jython 目录：1234$ cd $WLP_DIR/wlp/jython $ cp $WLP_DIR/wlp/clients/jython/restConnector.py . $ cp $WLP_DIR/wlp/clients/restConnector.jar . $ ls -l 收集 Liberty 服务器的性能数据 启动 Jython 会话123456java -cp jython-standalone-2.5.3.jar:restConnector.jar org.python.util.jython[was@kube-mini jython]$ java -cp jython-standalone-2.5.3.jar:restConnector.jar org.python.util.jythonJython 2.5.3 (2.5:c56500f08d34+, Aug 13 2012, 14:54:35)[IBM J9 VM (IBM Corporation)] on java1.8.0Type "help", "copyright", "credits" or "license" for more information. 连接到控制器服务器要连接到控制器服务器，可使用 restConnector.py 文件中的 JMXRESTConnector 对象。我们使用了以下元素： 控制器信任密钥文件 控制器信任密码 控制器主机名或 IP 地址 控制器端口 控制器用户 ID 和密码12345678&gt;&gt;&gt; from restConnector import JMXRESTConnector &gt;&gt;&gt; JMXRESTConnector.trustStore = '/home/was/nd/wlp/usr/servers/adminSrv/resources/security/key.jks'&gt;&gt;&gt; JMXRESTConnector.trustStorePassword = '123456'&gt;&gt;&gt; connector = JMXRESTConnector() &gt;&gt;&gt; connection = connector.connect( '&lt;controller_hostname&gt;', 9449, 'admin', 'admin') Connecting to the server... Successfully connected to the server "&lt;controller_hostname&gt;:9449" 连接到控制器 MBean 服务器1234567891011121314151617181920212223242526272829mconnection = connection.getMBeanServerConnection()&gt;&gt;&gt; mconnection = connector.getMBeanServerConnection() &gt;&gt;&gt; mconnection com.ibm.ws.jmx.connector.client.rest.internal.RESTMBeanServerConnection@aba685fb &gt;&gt;&gt; dir( mconnection) ['MBeanCount', 'PollingMode', 'ServerPollingThread', '__class__', '__copy__', '__deepcopy__', '__delattr__', '__doc__', '__ensure_finalizer__', '__eq__', '__format__', '__getattribute__', '__hash__', '__init__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__str__', '__subclasshook__', '__unicode__', 'addNotificationListener', 'class', 'createMBean', 'defaultDomain', 'domains', 'equals', 'getAttribute', 'getAttributes', 'getClass', 'getDefaultDomain', 'getDomains', 'getMBeanCount', 'getMBeanInfo', 'getObjectInstance', 'hashCode', 'invoke', 'isInstanceOf', 'isRegistered', 'notify', 'notifyAll', 'queryMBeans', 'queryNames', 'removeNotificationListener', 'setAttribute', 'setAttributes', 'toString', 'unregisterMBean', 'wait'] &gt;&gt;&gt; type( mconnection) &lt;type 'com.ibm.ws.jmx.connector.client.rest.internal.RESTMBeanServerConnection'&gt; &gt;&gt;&gt; mconnection.getClass() &lt;type 'com.ibm.ws.jmx.connector.client.rest.internal.RESTMBeanServerConnection'&gt; &gt;&gt;&gt; for i in mconnection.getClass().getMethods(): print i ... public boolean java.lang.Object.equals(java.lang.Object) public int java.lang.Object.hashCode() public java.lang.String java.lang.Object.toString() 列出可用的 MBean123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&gt;&gt;&gt; from javax.management import ObjectName &gt;&gt;&gt; mbeans = mconnection.queryNames( ObjectName( "WebSphere:*"), None).toArray() &gt;&gt;&gt; type( mbeans) &lt;type 'array.array'&gt; &gt;&gt;&gt; mbeans[0] WebSphere:name=com.ibm.websphere.config.mbeans.FeatureListMBean &gt;&gt;&gt; type( mbeans[0]) &lt;type 'javax.management.ObjectName'&gt; &gt;&gt;&gt; for i in mbeans: print i ... WebSphere:name=com.ibm.websphere.config.mbeans.FeatureListMBean WebSphere:feature=collectiveController,type=ControllerConfig,name=ControllerConfig WebSphere:name=com.ibm.websphere.config.mbeans.ServerXMLConfigurationMBean WebSphere:type=ServletStats,name=com.ibm.ws.jmx.connector.server.rest.MBeanServerConnector WebSphere:feature=collectiveController,type=CollectiveRepository,name=CollectiveRepository WebSphere:feature=collectiveController,type=MaintenanceMode,name=MaintenanceMode WebSphere:feature=collectiveMember,type=EndpointRoutingInfo,name=EndpointRoutingInfo WebSphere:feature=collectiveController,type=RepositoryPathUtility, name=RepositoryPathUtility WebSphere:name=com.ibm.ws.jmx.mbeans.sessionManagerMBean WebSphere:name=com.ibm.ws.jmx.mbeans.generatePluginConfig WebSphere:feature=restConnector,type=FileService,name=FileService WebSphere:feature=collectiveController,type=ServerCommands,name=ServerCommands WebSphere:name=com.ibm.ws.config.serverSchemaGenerator WebSphere:feature=collectiveController,type=CollectiveRegistration, name=CollectiveRegistration WebSphere:feature=CacheAdmin,type=DynaCache,name=DistributedMap WebSphere:feature=collectiveController,type=RoutingContext,name=RoutingContext WebSphere:feature=collectiveController,type=ClusterManager,name=ClusterManager WebSphere:feature=collectiveController,type=RoutingInfoManager,name=RoutingInfoManager WebSphere:feature=collectiveController,type=RepositoryConfiguration, name=RepositoryConfiguration WebSphere:service=com.ibm.ws.kernel.filemonitor.FileNotificationMBean WebSphere:feature=channelfw,type=endpoint,name=defaultHttpEndpoint WebSphere:type=JvmStats WebSphere:feature=channelfw,type=endpoint,name=defaultHttpEndpoint-ssl WebSphere:name=com.ibm.websphere.runtime.update.RuntimeUpdateNotificationMBean WebSphere:feature=collectiveController,type=AdminMetadataManager,name=AdminMetadataManager WebSphere:feature=collectiveMember,type=SingletonServiceMessenger, name=SingletonServiceMessenger WebSphere:feature=kernel,name=ServerInfo WebSphere:type=ThreadPoolStats,name=Default Executor WebSphere:feature=restConnector,type=FileTransfer,name=FileTransfer 获得 JvmStats MBean123456&gt;&gt;&gt; mbeans = mconnection.queryNames( ObjectName( "WebSphere:type=JvmStats,*"), None).toArray() &gt;&gt;&gt; for i in mbeans: print i ... WebSphere:type=JvmStats 访问 JvmStats MBean 详细信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546&gt;&gt;&gt; mbean_jvm = mbeans[ 0] &gt;&gt;&gt; mbean_info = mconnection.getMBeanInfo( mbean_jvm) &gt;&gt;&gt; type( mbean_info) &lt;type 'javax.management.MBeanInfo'&gt; &gt;&gt;&gt; dir( mbean_info) ['__class__', '__copy__', '__deepcopy__', '__delattr__', '__doc__', '__ensure_finalizer__', '__eq__', '__format__', '__getattribute__', '__hash__', '__init__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__str__', '__subclasshook__', '__unicode__', 'attributes', 'class', 'className', 'clone', 'constructors', 'description', 'descriptor', 'equals', 'getAttributes', 'getClass', 'getClassName', 'getConstructors', 'getDescription', 'getDescriptor', 'getNotifications', 'getOperations', 'hashCode', 'notifications', 'notify', 'notifyAll', 'operations', 'toString', 'wait'] &gt;&gt;&gt; mbean_info javax.management.MBeanInfo[description=Information on the management interface of the MBean, attributes=[javax.management.MBeanAttributeInfo[description=UsedMemory, name=UsedMemory, type=long, read-only, descriptor=&#123;openType=javax.management.openmbean.SimpleType(name=java.lang.Long), originalType=long&#125;], javax.management.MBeanAttributeInfo[description=FreeMemory, name=FreeMemory, type=long, read-only, descriptor=&#123;openType=javax.management.openmbean.SimpleType(name=java.lang.Long), originalType=long&#125;], javax.management.MBeanAttributeInfo[description=Heap, name=Heap, type=long, read-only, descriptor=&#123;openType=javax.management.openmbean.SimpleType(name=java.lang.Long), originalType=long&#125;], javax.management.MBeanAttributeInfo[description=UpTime, name=UpTime, type=long, read-only, descriptor=&#123;openType=javax.management.openmbean.SimpleType(name=java.lang.Long), originalType=long&#125;], javax.management.MBeanAttributeInfo[description=ProcessCPU, name=ProcessCPU, type=double, read-only, descriptor=&#123;openType=javax.management.openmbean.SimpleType(name=java.lang.Double), originalType=double&#125;], javax.management.MBeanAttributeInfo[description=GcCount, name=GcCount, type=long, read-only, descriptor=&#123;openType=javax.management.openmbean.SimpleType(name=java.lang.Long), originalType=long&#125;], javax.management.MBeanAttributeInfo[description=GcTime, name=GcTime, type=long, read-only, descriptor=&#123;openType=javax.management.openmbean.SimpleType(name=java.lang.Long), originalType=long&#125;]], constructors=[javax.management.MBeanConstructorInfo[description=Public constructor of the MBean, name=com.ibm.ws.monitors.helper.JvmStats, signature=[javax.management.MBeanParameterInfo[description=, name=p1, type=com.ibm.ws.monitors.helper.JvmMonitorHelper, descriptor=&#123;&#125;]], descriptor=&#123;&#125;]], operations=[], notifications=[], descriptor=&#123;immutableInfo=true, interfaceClassName=com.ibm.websphere.monitor.meters.JvmMXBean, mxbean=true&#125;] 获得 JvmStats MBean 属性1234567891011121314151617181920212223242526272829303132&gt;&gt;&gt; mbean_attributes = mbean_info.getAttributes() &gt;&gt;&gt; type( mbean_attributes) &lt;type 'array.array'&gt; &gt;&gt;&gt; type( mbean_attributes[ 0]) &lt;type 'javax.management.MBeanAttributeInfo'&gt; &gt;&gt;&gt; dir( mbean_attributes[0]) ['__class__', '__copy__', '__deepcopy__', '__delattr__', '__doc__', '__ensure_finalizer__', '__eq__', '__format__', '__getattribute__', '__hash__', '__init__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__str__', '__subclasshook__', '__unicode__', 'class', 'clone', 'description', 'descriptor', 'equals', 'getClass', 'getDescription', 'getDescriptor', 'getName', 'getType', 'hashCode', 'is', 'isIs', 'isReadable', 'isWritable', 'name', 'notify', 'notifyAll', 'readable', 'toString', 'type', 'wait', 'writable'] &gt;&gt;&gt; for attribute in mbean_attributes: name = attribute.getName() value = mconnection.getAttribute( mbean_jvm, name) type = attribute.getType() print " %s [%s] = %s" % ( name, type, str( value)) ... UsedMemory [long] = 52011592 FreeMemory [long] = 3481008 Heap [long] = 55771136 UpTime [long] = 2435005 ProcessCPU [double] = 0.0729284201396 GcCount [long] = 144 GcTime [long] = 365 &gt;&gt;&gt; exit() 添加 Jython 实用工具函数为了简化 Jython 会话，您可以创建一个连接参数文件和一些实用工具函数。 要创建连接参数文件，请输入：1vi wlp_collect_conf.py 123456789101112Config = &#123; 'host': '192.168.10.32', 'port': 9449, 'user': 'admin', 'password': 'admin', 'truststore': '/home/was/nd/wlp/usr/servers/adminSrv/resources/security/key.jks', 'truststore_password': '123456', 'objectName': 'WebSphere:*', 'collectiveName': 'WebSphere:type=CollectiveRepository,*', 'routingName': 'WebSphere:type=RoutingContext,*', 'attributeName': '*'&#125; 现在，创建包含用于 connect、disconnect 和 collect 实用工具的函数的文件：1vi wlp_collect.py collect 函数使用了 MBean getAttributes 和 getOperations 方法。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import sysfrom restConnector import JMXRESTConnectorfrom javax.management import ObjectNamefrom wlp_collect_conf import Configdef connect(): """ param : none BUT uses the Config object define in wlp_collect_conf.py result: return a connection object note : use simple connect method """ print Config['port'] print Config['truststore'] JMXRESTConnector.trustStore = Config['truststore'] JMXRESTConnector.trustStorePassword = Config['truststore_password'] connector = JMXRESTConnector() connector.connect(Config['host'], Config['port'], Config['user'], Config['password']) return connectordef disconnect(connector): """ param : a connection object (return by connect()) result: none """ connector.disconnect()def collect(connector, details=False, objectName=Config['objectName'], attributeName=Config['attributeName']): """ param1: connection object (return by connect() function) param2: output with or without details (True|False) param3: mbean object like "WebSphere:type=JvmStats,*" param4: attribute to retrieve in the mbean object result: return an array of mbeans objects found """ mconnection = connector.getMBeanServerConnection() # print dir( mconnection) # "WebSphere:type=endpoint,*" mbeans = mconnection.queryNames(ObjectName(objectName), None).toArray() for mbean in mbeans: print "\n MBean details for %s" % str(mbean) # --- get MBeanInfo mbean_info = mconnection.getMBeanInfo(mbean) mbean_class = mbean_info.className # --- printing attributes mbean_attributes = mbean_info.getAttributes() print "\n %s attributes" % str(len(mbean_info.attributes)) for attribute in mbean_attributes: name = attribute.name value = mconnection.getAttribute(mbean, name) type = attribute.type if details and (attributeName == "*" or attributeName == name): print " %s [%s] = %s" % (name, type, str(value)) # --- printing operations mbean_operations = mbean_info.getOperations() print "\n %s operations" % str(len(mbean_info.operations)) for operation in mbean_operations: name = operation.getName() # value = mconnection.getOperation( mbean, name) # type = operation.type if details and (attributeName == "*" or attributeName == name): # print " %s" % name print("\n " + str(operation.getName()) + " : " + str(operation.getDescription())) for param in operation.getSignature(): print(" " + str(param.getName()) + " [" + str(param.getType()) + "] : " + str(param.getDescription())) return mbeans collect 方法可以包含 1-4 个参数： 参数 1：连接对象 参数 2：显示详细信息 [False, True]（默认值为 False。） 参数 3：ObjectName（默认值为 WebSphere:*。） 参数 4：要收集的属性（默认值为 *。） 要使用新实用工具函数，可启动一个 Jython 会话：1java -cp jython-standalone-2.5.3.jar:restConnector.jar org.python.util.jython 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&gt;&gt; from wlp_collect import * &gt;&gt;&gt; dir() ['ClientProvider', 'Config', 'ConnectorSettings', 'JMXConnector', 'JMXRESTConnector', 'ObjectName', '__builtins__', '__doc__', '__name__', '__package__', 'array', 'collect', 'collect_controller', 'connect', 'connect_adv', 'disconnect', 'getServersFromRepository', 'java', 'print_usage', 'script_name', 'sys', 'urllib2'] &gt;&gt;&gt; connection = connect() 9449 /home/was/nd/wlp/usr/servers/adminSrv/resources/security/key.jks Connecting to the server... Successfully connected to the server "&lt;controller_hostname&gt;:9449" &gt;&gt;&gt; collect( connection, False, "WebSphere:type=JvmStats,*") MBean details for WebSphere:type=JvmStats 7 attributes 0 operations array(java.lang.Object, [WebSphere:type=JvmStats]) &gt;&gt;&gt; collect( connection, True, "WebSphere:type=JvmStats,*") MBean details for WebSphere:type=JvmStats 7 attributes UsedMemory [long] = 50492936 FreeMemory [long] = 11909624 Heap [long] = 62586880 UpTime [long] = 7060539 ProcessCPU [double] = 0.131003185929 GcCount [long] = 193 GcTime [long] = 460 0 operations array(java.lang.Object, [WebSphere:type=JvmStats]) &gt;&gt;&gt; collect( connection, True, "WebSphere:type=JvmStats,*", 'FreeMemory') MBean details for WebSphere:type=JvmStats 7 attributes FreeMemory [long] = 23083576 0 operations array(java.lang.Object, [WebSphere:type=JvmStats]) &gt;&gt;&gt; disconnect( connection)]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>liberty</tag>
        <tag>jython</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java处理对象排序和hadoop处理对象排序]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fjava%E5%A4%84%E7%90%86%E5%AF%B9%E8%B1%A1%E6%8E%92%E5%BA%8F%E5%92%8Chadoop%E5%A4%84%E7%90%86%E5%AF%B9%E8%B1%A1%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[描述使用JAVA程序按对象中的某一列进行排序。 使用到的是Comparable接口 学生对象类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.com.java;/** * Created by Administrator on 2017/6/2. */public class Student implements Comparable&lt;Student&gt;&#123; private String name; private int age; private int id; @Override public int compareTo(Student o) &#123; if(this.getAge()&gt;o.getAge())&#123; return 1; &#125;else&#123; return -1; &#125; &#125; @Override public String toString() &#123; return "Student&#123;" + "name='" + name + '\'' + ", age=" + age + ", id=" + id + '&#125;'; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 排序测试类123456789101112131415161718192021222324252627282930package com.com.java;import java.util.Arrays;/** * Created by Administrator on 2017/6/2. */public class Test &#123; public static void main(String args [])&#123; Student s1 = new Student(); s1.setId(1); s1.setAge(24); s1.setName("zhangsan"); Student s2 = new Student(); s2.setId(2); s2.setAge(21); s2.setName("lisi"); Student s3 = new Student(); s3.setId(3); s3.setAge(23); s3.setName("wangwu"); Student [] students = &#123;s1,s2,s3&#125;; Arrays.sort(students); for(Student s : students)&#123; System.out.println(s.toString()); &#125; &#125;&#125; 输出结果：123Student&#123;name='lisi', age=21, id=2&#125;Student&#123;name='wangwu', age=23, id=3&#125;Student&#123;name='zhangsan', age=24, id=1&#125; hadoop 处理数字排序1234567891011121314package com.com.number;import org.apache.hadoop.io.LongWritable;/** * Created by Administrator on 2017/6/2. */public class MyNumberComparator extends LongWritable.Comparator&#123; @Override public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) &#123; //默认升序 return -super.compare(b1, s1, l1, b2, s2, l2); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041package com.com.number;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;/** * Created by Administrator on 2017/6/2. */public class NumberMain &#123; public static void main(String args[])throws Exception&#123; //创建一个JOB Configuration configuration = new Configuration(); Job job =Job.getInstance(configuration); //指定任务的入口 job.setJarByClass(NumberMain.class); //指定任务的MAPPER job.setMapperClass(NumberMapper.class); job.setMapOutputKeyClass(LongWritable.class); job.setMapOutputValueClass(NullWritable.class); //指定任务的REDUCER job.setReducerClass(NumberReducer.class); job.setOutputKeyClass(LongWritable.class); job.setOutputValueClass(NullWritable.class); //指定排序规则 job.setSortComparatorClass(MyNumberComparator.class); //指定任务的输入输出 FileInputFormat.setInputPaths(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1])); //提交任务 job.waitForCompletion(true); &#125;&#125; 1234567891011121314151617181920212223package com.com.number;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import java.io.IOException;/** * Created by Administrator on 2017/6/2. */public class NumberMapper extends Mapper&lt;LongWritable,Text,LongWritable,NullWritable&gt; &#123; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; //得到数据 String str = value.toString().trim(); context.write(new LongWritable(Long.parseLong(str)), NullWritable.get()); &#125;&#125; 1234567891011121314151617package com.com.number;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.mapreduce.Reducer;import java.io.IOException;/** * Created by Administrator on 2017/6/2. */public class NumberReducer extends Reducer&lt;LongWritable,NullWritable,LongWritable,NullWritable&gt; &#123; @Override protected void reduce(LongWritable key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException &#123; context.write(key,NullWritable.get()); &#125;&#125; hadoop 处理字符串排序1234567891011121314package com.com.string;import org.apache.hadoop.io.Text;/** * Created by Administrator on 2017/6/2. */public class MyStringComparator extends Text.Comparator&#123; @Override public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) &#123; //默认升序 return -super.compare(b1, s1, l1, b2, s2, l2); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940package com.com.string;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;/** * Created by Administrator on 2017/6/2. */public class StringMain &#123; public static void main(String args[])throws Exception&#123; //创建一个JOB Configuration configuration = new Configuration(); Job job =Job.getInstance(configuration); //指定任务的入口 job.setJarByClass(StringMain.class); //指定任务的MAPPER job.setMapperClass(StringMapper.class); job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(NullWritable.class); //指定任务的REDUCER job.setReducerClass(StringReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(NullWritable.class); //指定排序规则 job.setSortComparatorClass(MyStringComparator.class); //指定任务的输入输出 FileInputFormat.setInputPaths(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1])); //提交任务 job.waitForCompletion(true); &#125;&#125; 123456789101112131415161718package com.com.string;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import java.io.IOException;/** * Created by Administrator on 2017/6/2. */public class StringMapper extends Mapper&lt;LongWritable,Text,Text,NullWritable&gt; &#123; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; context.write(value, NullWritable.get()); &#125;&#125; 123456789101112131415161718package com.com.string;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Reducer;import java.io.IOException;/** * Created by Administrator on 2017/6/2. */public class StringReducer extends Reducer&lt;Text,NullWritable,Text,NullWritable&gt; &#123; @Override protected void reduce(Text key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException &#123; context.write(key, NullWritable.get()); &#125;&#125; hadoop 处理对象排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146package com.com.employee;import org.apache.hadoop.io.Writable;import org.apache.hadoop.io.WritableComparable;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;/** * Created by Administrator on 2017/6/2. */public class Employee implements WritableComparable&lt;Employee&gt; &#123; private int empno; private String ename; private String job; private int mgr; private String hiredate; private int sal; private int comm; private int deptno; //单列排序 /**@Override public int compareTo(Employee o) &#123; if(this.getDeptno()&gt;o.getDeptno())&#123; return 1; &#125;else&#123; return -1; &#125; &#125;**/ //多列排序 public int compareTo(Employee o) &#123; //多个表排序，先按照部门号排序再按照薪水排序 if(this.getDeptno()&gt;o.getDeptno())&#123; return 1; &#125;else if (this.getDeptno()&lt;o.getDeptno())&#123; return -1; &#125; //部分号相同按照薪水排序 if(this.getSal()&gt;=o.getSal())&#123; return 1; &#125;else&#123; return -1; &#125; &#125; @Override public void write(DataOutput dataOutput) throws IOException &#123; dataOutput.writeInt(this.empno); dataOutput.writeUTF(ename); dataOutput.writeUTF(job); dataOutput.writeInt(mgr); dataOutput.writeUTF(hiredate); dataOutput.writeInt(sal); dataOutput.writeInt(comm); dataOutput.writeInt(deptno); &#125; @Override public void readFields(DataInput dataInput) throws IOException &#123; empno= dataInput.readInt(); ename=dataInput.readUTF(); job=dataInput.readUTF(); mgr=dataInput.readInt(); hiredate=dataInput.readUTF(); sal=dataInput.readInt(); comm=dataInput.readInt(); deptno=dataInput.readInt(); &#125; @Override public String toString() &#123; return "Employee&#123;" + "empno=" + empno + ", ename='" + ename + '\'' + ", deptno=" + deptno + ", sal=" + sal + '&#125;'; &#125; public int getEmpno() &#123; return empno; &#125; public void setEmpno(int empno) &#123; this.empno = empno; &#125; public String getEname() &#123; return ename; &#125; public void setEname(String ename) &#123; this.ename = ename; &#125; public String getJob() &#123; return job; &#125; public void setJob(String job) &#123; this.job = job; &#125; public int getMgr() &#123; return mgr; &#125; public void setMgr(int mgr) &#123; this.mgr = mgr; &#125; public String getHiredate() &#123; return hiredate; &#125; public void setHiredate(String hiredate) &#123; this.hiredate = hiredate; &#125; public int getSal() &#123; return sal; &#125; public void setSal(int sal) &#123; this.sal = sal; &#125; public int getComm() &#123; return comm; &#125; public void setComm(int comm) &#123; this.comm = comm; &#125; public int getDeptno() &#123; return deptno; &#125; public void setDeptno(int deptno) &#123; this.deptno = deptno; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839package com.com.employee;import com.com.emp.EmpMapper;import com.com.emp.EmpReducer;import com.com.emp.emp;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;/** * Created by Administrator on 2017/6/2. */public class EmployeeMain &#123; public static void main(String args[])throws Exception&#123; //创建一个JOB Configuration configuration = new Configuration(); Job job =Job.getInstance(configuration); //指定任务的入口 job.setJarByClass(EmployeeMain.class); //指定任务的MAPPER job.setMapperClass(EmployeeMapper.class); job.setMapOutputKeyClass(Employee.class); job.setMapOutputValueClass(NullWritable.class); //指定任务的REDUCER job.setReducerClass(EmployeeReducer.class); job.setOutputKeyClass(Employee.class); job.setOutputValueClass(NullWritable.class); //指定任务的输入输出 FileInputFormat.setInputPaths(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1])); //提交任务 job.waitForCompletion(true); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839package com.com.employee;import com.com.emp.emp;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import java.io.IOException;/** * Created by Administrator on 2017/6/2. */public class EmployeeMapper extends Mapper&lt;LongWritable,Text,Employee,NullWritable&gt; &#123; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String str = value.toString(); String words[] = str.split(","); Employee emp= new Employee(); emp.setEmpno(Integer.parseInt(words[0])); emp.setEname(words[1]); emp.setJob(words[2]); try&#123; emp.setMgr(Integer.parseInt(words[3])); &#125;catch (Exception ex)&#123; emp.setMgr(-1); &#125; emp.setHiredate(words[4]); emp.setSal(Integer.parseInt(words[5])); try &#123; emp.setComm(Integer.parseInt(words[6])); &#125;catch (Exception ex)&#123; emp.setComm(0); &#125; emp.setDeptno(Integer.parseInt(words[7])); context.write(emp, NullWritable.get()); &#125;&#125; 12345678910111213141516package com.com.employee;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.mapreduce.Reducer;import java.io.IOException;/** * Created by Administrator on 2017/6/2. */public class EmployeeReducer extends Reducer&lt;Employee,NullWritable,Employee,NullWritable&gt; &#123; @Override protected void reduce(Employee key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException &#123; context.write(key,NullWritable.get()); &#125;&#125;]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用MR程序处理数据]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E4%BD%BF%E7%94%A8MR%E7%A8%8B%E5%BA%8F%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[描述使用map/reducer程序来处理数据 使用到的JAR文件如下：1234/root/training/hadoop-2.4.1/share/hadoop/common/root/training/hadoop-2.4.1/share/hadoop/common/lib/root/training/hadoop-2.4.1/share/hadoop/mapreduce/root/training/hadoop-2.4.1/share/hadoop/mapreduce/lib 图文介绍MR的编程模型 使用JAVA程序来开发MR进行数据处理12345678910111213141516171819202122232425262728293031323334353637383940414243package com.com.wc;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;/** * Created by Administrator on 2017/6/1. */public class WordCountMain &#123; public static void main(String args[])throws Exception&#123; /** * 创建一个JOB JOB=mapper+reducer * 创建一个配置信息 * 创建一个任务 * Job job = new Job(conf); */ Configuration configuration = new Configuration(); Job job = Job.getInstance(configuration); //指定任务的入口 job.setJarByClass(WordCountMain.class); //设置任务的MAPPER job.setMapperClass(WordCountMapper.class); job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(LongWritable.class); //设置任务的REDUCER job.setReducerClass(WorkCountReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(LongWritable.class); //指定HDFS的输入和输出的路径 FileInputFormat.setInputPaths(job, new Path(args[0])); FileOutputFormat.setOutputPath(job,new Path(args[1])); //提交任务：true 在运行过程中输出日志 job.waitForCompletion(true); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536package com.com.wc;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Mapper;import java.io.IOException;/** * Created by Administrator on 2017/6/1. * WordCount的mapper程序 * 1、从HDFS读入数据 * 2、进行分词，得到MAPPER的输出 */// key1 value1 key2 value2public class WordCountMapper extends Mapper&lt;LongWritable,Text,Text,LongWritable&gt; &#123; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; //context 是MAPPER的上下文 // 1、上文是MAPPER // 2、下文是HDFS //得到数据 String str = value.toString(); //分词 String [] words = str.split(" "); //把分词后的结果得到了&lt;key2 value2&gt;输出到reducer中 for(String word:words)&#123; //输出 key2 value2 context.write(new Text(word),new LongWritable(1)); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233package com.com.wc;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Reducer;import java.io.IOException;/** * Created by Administrator on 2017/6/1. * reducer的输入是MAPPER * 相同的key2他的VALUE2会被同一个REDUCER处理（送到同一个VLAUE3中） * key3 value3 key4 value4 */public class WorkCountReducer extends Reducer&lt;Text,LongWritable,Text,LongWritable&gt;&#123; @Override protected void reduce(Text key3, Iterable&lt;LongWritable&gt; values3, Context context) throws IOException, InterruptedException &#123; //context 是MAPPER的上下文 // 1、上文是HDFS // 2、下文是REDUCER //求和 long sum = 0; for(LongWritable data : values3)&#123; sum = data.get()+sum; &#125; //输出key4 value4 context.write(key3,new LongWritable(sum)); &#125;&#125; 使用开发工具进行打包 运行：1hadoop jar Hdfs.jar /input /output/wc YARN平台运行机制]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>hadoop</tag>
        <tag>spark</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[websphere通过脚本来创建用户和组]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fwebsphere%E9%80%9A%E8%BF%87%E8%84%9A%E6%9C%AC%E6%9D%A5%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7%E5%92%8C%E7%BB%84%2F</url>
    <content type="text"><![CDATA[描述集团规范was账号安全要求：1、应按照用户分配账号，避免不同用户间共享账号；2、应删除或锁定与设备运行、维护等工作无关的账号；3、根据用户的业务需要，配置最小权限； 要求不得出现共用特权管理账号，管理账号必须按角色分配用户角色为monitor（监控员）、Configurator(配置员)、Operator（操作员）Administrator(管理员)之一 脚本12345678910111213141516171819202122232425262728293031323334353637AdminTask.createUser (['-uid', 'monitor', '-password', 'BossApp#2017', '-confirmPassword', 'BossApp#2017', '-cn', 'monitor', '-sn', 'monitor'])AdminTask.createGroup (['-cn', 'monitor', '-description', 'a group of admins'])AdminTask.mapGroupsToAdminRole('[-roleName monitor -accessids [group:defaultWIMFileBasedRealm/cn=monitor,o=defaultWIMFileBasedRealm ] -groupids [monitor@defaultWIMFileBasedRealm ]]')AdminTask.mapUsersToAdminRole('[-accessids [user:defaultWIMFileBasedRealm/uid=monitor,o=defaultWIMFileBasedRealm ] -userids [monitor ] -roleName monitor]')print 'monitor is create success ...'AdminTask.createUser (['-uid', 'operator', '-password', 'BossApp#2017', '-confirmPassword', 'BossApp#2017', '-cn', 'operator', '-sn', 'operator'])AdminTask.createGroup (['-cn', 'operator', '-description', 'a group of admins'])AdminTask.mapGroupsToAdminRole('[-roleName operator -accessids [group:defaultWIMFileBasedRealm/cn=operator,o=defaultWIMFileBasedRealm ] -groupids [operator@defaultWIMFileBasedRealm ]]')AdminTask.mapUsersToAdminRole('[-accessids [user:defaultWIMFileBasedRealm/uid=operator,o=defaultWIMFileBasedRealm ] -userids [operator ] -roleName operator]')print 'operator is create success ...'AdminTask.createUser (['-uid', 'configurator', '-password', 'BossApp#2017', '-confirmPassword', 'BossApp#2017', '-cn', 'configurator', '-sn', 'configurator'])AdminTask.createGroup (['-cn', 'configurator', '-description', 'a group of admins'])AdminTask.mapGroupsToAdminRole('[-roleName configurator -accessids [group:defaultWIMFileBasedRealm/cn=configurator,o=defaultWIMFileBasedRealm ] -groupids [configurator@defaultWIMFileBasedRealm ]]')AdminTask.mapUsersToAdminRole('[-accessids [user:defaultWIMFileBasedRealm/uid=configurator,o=defaultWIMFileBasedRealm ] -userids [configurator ] -roleName configurator]')print 'configurator is create success ...'AdminTask.createUser (['-uid', 'administrator', '-password', 'BossApp#2017', '-confirmPassword', 'BossApp#2017', '-cn', 'administrator', '-sn', 'administrator'])AdminTask.createGroup (['-cn', 'administrator', '-description', 'a group of admins'])AdminTask.mapGroupsToAdminRole('[-roleName administrator -accessids [group:defaultWIMFileBasedRealm/cn=administrator,o=defaultWIMFileBasedRealm ] -groupids [administrator@defaultWIMFileBasedRealm ]]')AdminTask.mapUsersToAdminRole('[-accessids [user:defaultWIMFileBasedRealm/uid=administrator,o=defaultWIMFileBasedRealm ] -userids [administrator ] -roleName administrator]')print 'administrator is create success ...'AdminConfig.save()#删除ALL_AUTHENTICATED 组中不必要的角色#ALL_AUTHENTICATED 组角色仅设为“控制台命名读”AdminTask.mapGroupsToNamingRole('[-roleName CosNamingRead -specialSubjects [ALLAUTHENTICATED ]]')AdminTask.listGroupsForNamingRoles()AdminConfig.save()#删除EVERYONE组AdminTask.removeGroupsFromNamingRole('[-specialSubjects [EVERYONE ] -roleName CosNamingRead]')AdminConfig.save()]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>was</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[websphere根据基线检查脚本]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fwebsphere%E6%A0%B9%E6%8D%AE%E5%9F%BA%E7%BA%BF%E6%A3%80%E6%9F%A5%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[描述集团安全检查中间件，根据检查表格模板，写python脚本进行自查安全检查项包括：账号安全要求、检查启动帐户权限、自动登出、管理后台登录登陆限制、ALL_AUTHENTICATED 组角色仅设为“控制台命名读”、密码安全要求、检查用户口令策略是否符合安全要求、明文口令、补丁管理、漏洞管理、权限设置、错误页面重定向、banner 安全配置、用例/文件管理、禁止Websphere列表显示文件、启用日志等 检查脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326import osimport os.pathimport timeimport reimport globimport traceback(False, True) = (0, 1)svr = AdminControl.queryNames('type=Server,*')svr_num = svr.split(',')[5][8]print '********:',svrprint '********:',svr_numdef Init(): try: AdminConfig = sys._getframe(1).f_locals["AdminConfig"] AdminApp = sys._getframe(1).f_locals["AdminApp"] AdminControl = sys._getframe(1).f_locals["AdminControl"] AdminTask = sys._getframe(1).f_locals["AdminTask"] except: print "Warning: Caught exception accessing Admin objects. Continuing."# 检查soap.client.props配置文件中com.ibm.SOAP.securityEnabled的值def checkPassword(profile_name): soap_client_props = ("%s/properties/soap.client.props") % (profile_name) result = "" if os.path.isfile(soap_client_props): file = open(soap_client_props, 'r') contents = file.readlines() file.close() for i in contents: if -1 != i.find('com.ibm.SOAP.securityEnabled'): result = i if i: print "checkPassword:", result else: print "checkPassword:false"# 检查是否删除EVERYONE组# 如果was版本为8或者7启动了就用wsadmin脚本来检查# 否则直接读取naming-authz.xml配置文件来检查是否包含EveryoneExt关键字def checkCosNaming_Everyone(profile_name): f_everyone = True if svr_num == '8' or svr_num == '7': groups_NamingRoles = AdminTask.listGroupsForNamingRoles() if groups_NamingRoles.count("EVERYONE"): f_everyone = False if f_everyone: print "everyone is removed,CheckCosNaming_Everyone result:true" else: print "everyone not removed,CheckCosNaming_Everyone result:false" elif svr_num == '6': cell_name = AdminControl.getCell() file_path = ("%s/config/cells/%s/naming-authz.xml") % ( profile_name, cell_name) if os.path.isfile(file_path): file = open(file_path, 'r') contents = file.read() if -1 != contents.find("EveryoneExt"): print "everyone not removed,CheckCosNaming_Everyone result:false" else: print "everyone is removed,CheckCosNaming_Everyone result:true" file.close() else: passdef checkCosNaming(profile_name): checkCosNaming_Everyone(profile_name) checkCosNaming_AllAuthenticated(profile_name)# 检查ALLAUTHENTICATED组是否存在并且是否是控制台命名读权限# 如果was版本为8或者7就用wsadmin脚本来检查# 否则直接读取naming-authz.xml配置文件来检查是否包含AllAuthenticatedUsersExt关键字def checkCosNaming_AllAuthenticated(profile_name): if svr_num == '8' or svr_num == '7': groups_NamingRoles = AdminTask.listGroupsForNamingRoles() index = groups_NamingRoles.find("CosNamingRead=") if groups_NamingRoles[index:-1].count("ALLAUTHENTICATED"): if 1 != groups_NamingRoles.count("ALLAUTHENTICATED"): print "allAuthenticated more,CheckCosNaming_AllAuthenticated result:false" else: print "allAuthenticated readonly once,CheckCosNaming_AllAuthenticated result:true" else: print "allAuthenticated not readonly,CheckCosNaming_AllAuthenticated result:false" elif svr_num == '6': cell_name = AdminControl.getCell() print cell_name file_path = ("%s/config/cells/%s/naming-authz.xml") % (profile_name, cell_name) if os.path.isfile(file_path): file = open(file_path, 'r') contents = file.readlines() file.close() Flag = False for i in contents: if -1 != i.find("SecurityRoleExt_1"): Flag = True continue if -1 != i.find("authorizations"): Flag = False break if True == Flag: if -1 != i.find("AllAuthenticatedUsersExt"): print "allAuthenticated readonly once,CheckCosNaming_AllAuthenticated result:true" break if False == Flag: print "allAuthenticated not readonly,CheckCosNaming_AllAuthenticated result:false" else: pass# 根据制定备份目录查找是否有根据概要文件命名的备份文件# 如果有返回true 否则返回falsedef backupFiles(backup_path, profile_name): file_list = os.listdir(backup_path) result = "false" for i in file_list: if os.path.splitext(i)[1] == ".zip" and -1 != i.find(profile_name): result = "true" break if os.path.splitext(i)[1] == ".gz" and -1 != i.find(profile_name): result = "true" break if result == "true": print "checkbackupfiles:true" elif result == "false": print "checkbackupfiles:false"# 检查config和properties两个目录的权限是否为700def checkFolderAttributes(profile_name): config_path = ("%s/config") % ( profile_name) properties_path = ("%s/properties") % ( profile_name) print "config_attribute:", command = "ls -ld %s" % config_path os.system(command) print "properties_attribute:", command = "ls -ld %s" % properties_path os.system(command)# 检查WAS的版本信息以及更新记录def checkInfo(profile_name): history_path = ("%s/bin/historyInfo.sh") % ( profile_name) version_path = ("%s/bin/versionInfo.sh") % ( profile_name) genVersionReport_path = ("%s/bin/genVersionReport.sh") % ( profile_name) genHistoryReport_path = ("%s/bin/genHistoryReport.sh") % ( profile_name) hisroty_command = "sh %s" % history_path version_command = "sh %s" % version_path genHistory_command = "sh %s" % genHistoryReport_path genVersion_command = "sh %s" % genVersionReport_path print "History" os.system(hisroty_command) print "History-End" print "Version" os.system(version_command) print "Version-End" print "genHistory" os.system(genHistory_command) print "genHistory-End" print "genVersion" os.system(genVersion_command) print "genVersion-End"# 检查配置的所有用户信息def checkUser(): print "checkUser" if svr_num == '8' or svr_num == '7': print AdminTask.listUserIDsOfAuthorizationGroup() print AdminTask.listAuditUserIDsOfAuthorizationGroup() elif svr_num == '6': print AdminTask.listUserIDsOfAuthorizationGroup() else: pass print "checkUserEnd"# 检查二项配置是否达标# 检查文件ibm-web-ext.xmi 是在installedApps不是在config目录下切记# 1、是否配置错误页面 defaultErrorPage# 2、是否允许目录遍历 directoryBrowsingEnabled=false fileServingEnabled=falsedef checkBrowser( profile_name): Apps = AdminApp.list().split('\n') cell_name = AdminControl.getCell() config_file = [] wrong_directoryBrowsing = [] wrong_fileServing = [] error_file = [] for i in Apps: tmp_path = ("%s/installedApps/%s/%s.ear") % ( profile_name, cell_name, i) if os.path.exists(tmp_path): for j in os.listdir(tmp_path): if j[-4:] == ".war": tmp_file = tmp_path + "/" + j + "/WEB-INF/ibm-web-ext.xmi" if os.path.isfile(tmp_file): config_file.append(tmp_file) for x in config_file: file = open(x, 'r') contents = file.read() file.close() text = contents.find('directoryBrowsingEnabled="false"') if -1 == text: wrong_directoryBrowsing.append(x) text = contents.find('fileServingEnabled="false"') text1 = contents.find('fileServingEnabled="true"') if -1 == text or -1 != text1: wrong_fileServing.append(x) text = contents.find("defaultErrorPage") if -1 == text: error_file.append(x) if AdminApp.list() == "": print "errorPage:true" print "CheckFileServing:valid" print "CheckContentsBrowser:valid" if 0 != len(error_file): print "errorPage:false,file is ", error_file else: print "errorPage:true" if 0 == len(wrong_directoryBrowsing): print "CheckContentsBrowser:valid" else: print "CheckContentsBrowser:invalid.file is", wrong_directoryBrowsing if 0 == len(wrong_fileServing): print "CheckFileServing:valid" else: print "CheckFileServing:invalid.file is", wrong_fileServing print "checkFile:", config_filedef checkRolesMap( profile_name): Apps = AdminApp.list().split('\n') cell_name = AdminControl.getCell() result_Map = [] print "rolesMap" for x in Apps: rolesMap = ("%s/config/cells/%s/applications/%s.ear/deployments/%s/META-INF/ibm-application-bnd.xmi") % ( profile_name, cell_name, x, x) print rolesMap if os.path.isfile(rolesMap): file = open(rolesMap, 'r') contents = file.readlines() file.close() Flag = False count = 0 for i in contents: if -1 != i.find("/authorizations"): Flag = False if count &lt; 3: result_Map.append(x) break count = 0 continue if -1 != i.find("authorizations"): Flag = True continue if True == Flag: if -1 != i.find("users"): count = count + 1 continue if -1 != i.find("specialSubjects"): count = count + 1 continue if -1 != i.find("group"): count = count + 1 continue if 0 != len(result_Map): print "RolesMap:", ",".join(result_Map) print result_Map else: print "RolesMap:true" print "rolesMapEnd"def checkLTPA(profile_name): print "LTPA" if svr_num == '8' or svr_num == '7': print AdminTask.getActiveSecuritySettings() elif svr_num == '6': cell_name = AdminControl.getCell() file_path = ("%s/config/cells/%s/security.xml") % ( profile_name, cell_name) if os.path.isfile(file_path): file = open(file_path, 'r') contents = file.read() file.close() if -1 != contents.find('activeAuthMechanism="LTPA_1"'): print "[activeAuthMechanism LTPA]" else: print "LTPA is false" else: pass print "LTPAEND"try: appServer_path ='/home/was/was85/AppServer' profile_path = '/home/was/boss_app/' profile_name = 'boss-app-bd01-pf1' backup_path = '/home/was/backup' Init() checkPassword(profile_path+profile_name) checkCosNaming(profile_path+profile_name) backupFiles(backup_path, profile_name) checkFolderAttributes(profile_path+profile_name) checkInfo(profile_path+profile_name) checkUser() print "java2security:", AdminConfig.showAttribute(AdminConfig.list("Security"), "enforceJava2Security") print "appSecurityEnabled:", AdminTask.isAppSecurityEnabled() print "logTrace:", AdminConfig.showAttribute(AdminConfig.list("TraceService"), "enable") print "loglevel:", AdminConfig.showAttribute(AdminConfig.list("TraceService"), "startupTraceSpecification") #print "timeout:", AdminConfig.showAttribute(AdminConfig.showAttribute(AdminConfig.showAttribute(AdminConfig.list("DeployedObjectConfig"), "sessionManagement"), "tuningParams"),"invalidationTimeout") emps = ",".join(AdminApp.list().split("\n")) emp_ret = [] if -1 != emps.find("DefaultApplication"): emp_ret.append("DefaultApplication") if -1 != emps.find("PlantsByWebSphere"): emp_ret.append("PlantsByWebSphere") if -1 != emps.find("SamplesGallery"): emp_ret.append("SamplesGallery") if -1 != emps.find("ivtApp"): emp_ret.append("ivtApp") if -1 != emps.find("query"): emp_ret.append("query") if 0 == len(emp_ret): print "examples:valid" else: print "examples:", ",".join(emp_ret) checkBrowser(profile_path+profile_name) checkRolesMap(profile_path+profile_name) checkLTPA(profile_path+profile_name)except AttributeError: pass 检查结果123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510********: WebSphere:name=boss-app-bd01-node1-srv,process=boss-app-bd01-node1-srv,platform=proxy,node=boss-app-bd01-node1,j2eeType=J2EEServer,version=8.5.5.11,type=Server,mbeanIdentifier=cells/boss-app-bd01-node1-cell/nodes/boss-app-bd01-node1/servers/boss-app-bd01-node1-srv/server.xml#Server_1183122130078,cell=boss-app-bd01-node1-cell,spec=1.0,processType=UnManagedProcess********: 8checkPassword: com.ibm.SOAP.securityEnabled=trueeveryone not removed,CheckCosNaming_Everyone result:falseallAuthenticated readonly once,CheckCosNaming_AllAuthenticated result:truecheckbackupfiles:trueconfig_attribute:drwxr-xr-x 9 was was 4096 12月 9 11:51 /home/was/boss_app/boss-app-bd01-pf1/configproperties_attribute:drwxr-xr-x 7 was was 4096 5月 23 14:32 /home/was/boss_app/boss-app-bd01-pf1/propertiesHistoryWVER0210I: Copyright (c) IBM Corporation 2002, 2012; All rights reserved.WVER0212I: HistoryInfo Reporter V1.7.1.28，日期：10/18/11--------------------------------------------------------------------------------IBM WebSphere 产品历史记录报告--------------------------------------------------------------------------------日期和时间 2017年5月25日 上午10时54分16秒 时的报告安装--------------------------------------------------------------------------------产品目录 /home/was/was85/AppServer版本目录 /home/was/was85/AppServer/properties/versionDTD 目录 /home/was/was85/AppServer/properties/version/dtd日志目录 /home/was/var/ibm/InstallationManager/logs安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140317_1520.xml时间戳记 2014-03-17 15:20:42+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 64 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 更新版本 8.5.5.1软件包 com.ibm.websphere.ND.v85_8.5.5001.20131018_2242日志文件名 /home/was/var/ibm/InstallationManager/logs/20140317_1523.xml时间戳记 2014-03-17 15:23:31+0800结果 成功已安装功能部件 针对 Java 的 IBM 64 位 WebSphere SDK 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 可嵌入式 EJB 容器 独立瘦客户机和资源适配器安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.1软件包 com.ibm.websphere.ND.v85_8.5.5001.20131018_2242日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1228.xml时间戳记 2014-05-13 12:28:44+0800结果 成功已安装功能部件 针对 Java 的 IBM 64 位 WebSphere SDK 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 可嵌入式 EJB 容器 独立瘦客户机和资源适配器安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 回滚版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1231.xml时间戳记 2014-05-13 12:31:23+0800结果 成功安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 卸载版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1233.xml时间戳记 2014-05-13 12:33:48+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 64 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1237a.xml时间戳记 2014-05-13 12:38:01+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 卸载版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1244.xml时间戳记 2014-05-13 12:44:25+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1247.xml时间戳记 2014-05-13 12:47:18+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 卸载版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1251.xml时间戳记 2014-05-13 12:51:30+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1255.xml时间戳记 2014-05-13 12:56:02+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 64 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 卸载版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1258a.xml时间戳记 2014-05-13 12:58:38+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 64 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1302.xml时间戳记 2014-05-13 13:02:43+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 卸载版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1304.xml时间戳记 2014-05-13 13:04:38+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1306.xml时间戳记 2014-05-13 13:06:38+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 卸载版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1327.xml时间戳记 2014-05-13 13:27:19+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1330.xml时间戳记 2014-05-13 13:30:46+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 64 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 卸载版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1339.xml时间戳记 2014-05-13 13:39:26+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 64 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1343.xml时间戳记 2014-05-13 13:44:11+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 卸载版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1357.xml时间戳记 2014-05-13 13:57:23+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1436.xml时间戳记 2014-05-13 14:36:38+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 更新版本 8.5.5.1软件包 com.ibm.websphere.ND.v85_8.5.5001.20131018_2242日志文件名 /home/was/var/ibm/InstallationManager/logs/20140513_1441.xml时间戳记 2014-05-13 14:41:30+0800结果 成功已安装功能部件 针对 Java 的 IBM 32 位 WebSphere SDK 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 可嵌入式 EJB 容器 独立瘦客户机和资源适配器安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 更新版本 8.5.5.10软件包 com.ibm.websphere.ND.v85_8.5.5010.20160721_0036日志文件名 /home/was/var/ibm/InstallationManager/logs/20161130_1508.xml时间戳记 2016-11-30 15:08:35+0800结果 成功已安装功能部件 针对 Java 的 IBM 32 位 WebSphere SDK 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 可嵌入式 EJB 容器 独立瘦客户机和资源适配器安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 卸载版本 8.5.5.10软件包 com.ibm.websphere.ND.v85_8.5.5010.20160721_0036日志文件名 /home/was/var/ibm/InstallationManager/logs/20161209_1022.xml时间戳记 2016-12-09 10:22:59+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 32 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 安装版本 8.5.5.0软件包 com.ibm.websphere.ND.v85_8.5.5000.20130514_1044日志文件名 /home/was/var/ibm/InstallationManager/logs/20161209_1026.xml时间戳记 2016-12-09 10:26:54+0800结果 成功已安装功能部件 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 独立瘦客户机和资源适配器 可嵌入式 EJB 容器 针对 Java 的 IBM 64 位 WebSphere SDK安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 更新版本 8.5.5.10软件包 com.ibm.websphere.ND.v85_8.5.5010.20160721_0036日志文件名 /home/was/var/ibm/InstallationManager/logs/20161209_1113.xml时间戳记 2016-12-09 11:13:42+0800结果 成功已安装功能部件 针对 Java 的 IBM 64 位 WebSphere SDK 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 可嵌入式 EJB 容器 独立瘦客户机和资源适配器安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.ND.v85操作 更新版本 8.5.5.11软件包 com.ibm.websphere.ND.v85_8.5.5011.20161206_1434日志文件名 /home/was/var/ibm/InstallationManager/logs/20170124_1009.xml时间戳记 2017-01-24 10:09:38+0800结果 成功已安装功能部件 针对 Java 的 IBM 64 位 WebSphere SDK 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 可嵌入式 EJB 容器 独立瘦客户机和资源适配器安装事件--------------------------------------------------------------------------------Installation Manager 产品标识 com.ibm.websphere.IBMJAVA.v71操作 安装版本 7.1.3.60软件包 com.ibm.websphere.IBMJAVA.v71_7.1.3060.20161124_1256日志文件名 /home/was/var/ibm/InstallationManager/logs/20170419_1435.xml时间戳记 2017-04-19 14:35:55+0800结果 成功--------------------------------------------------------------------------------结束历史记录报告--------------------------------------------------------------------------------History-EndVersionWVER0010I: Copyright (c) IBM Corporation 2002, 2012; All rights reserved.WVER0012I: VersionInfo reporter V1.15.1.48，日期：2/8/12--------------------------------------------------------------------------------IBM WebSphere 产品安装状态报告--------------------------------------------------------------------------------日期和时间 2017年5月25日 上午10时54分19秒 时的报告安装--------------------------------------------------------------------------------产品目录 /home/was/was85/AppServer版本目录 /home/was/was85/AppServer/properties/versionDTD 目录 /home/was/was85/AppServer/properties/version/dtd日志目录 /home/was/var/ibm/InstallationManager/logs产品列表--------------------------------------------------------------------------------ND 已安装IBMJAVA71 已安装已安装产品--------------------------------------------------------------------------------名称 IBM WebSphere Application Server Network Deployment版本 8.5.5.11标识 ND构建级别 cf111649.01构建日期 12/6/16软件包 com.ibm.websphere.ND.v85_8.5.5011.20161206_1434体系结构 x86-64 (64 bit)已安装功能部件 针对 Java 的 IBM 64 位 WebSphere SDK WebSphere Application Server Full Profile 用于 EJB 3.0 之前的模块的 EJBDeploy 工具 可嵌入式 EJB 容器 独立瘦客户机和资源适配器可选语言 简体中文已安装产品--------------------------------------------------------------------------------名称 IBM WebSphere SDK Java Technology Edition (Optional)版本 7.1.3.60标识 IBMJAVA71构建级别 cf111647.02构建日期 11/24/16软件包 com.ibm.websphere.IBMJAVA.v71_7.1.3060.20161124_1256体系结构 x86-64 (64 bit)已安装功能部件 IBM WebSphere SDK for Java Technology Edition V7.1可选语言 简体中文--------------------------------------------------------------------------------结束安装状态报告--------------------------------------------------------------------------------Version-EndgenHistoryWVER0210I: Copyright (c) IBM Corporation 2002, 2012; All rights reserved.WVER0212I: HistoryInfo Reporter V1.7.1.28，日期：10/18/11genHistory-EndgenVersionWVER0010I: Copyright (c) IBM Corporation 2002, 2012; All rights reserved.WVER0012I: VersionInfo reporter V1.15.1.48，日期：2/8/12genVersion-EndcheckUser&#123;nobody=[], monitor=[], configurator=[], administrator=[], deployer=[], iscadmins=[], operator=[], adminsecuritymanager=[]&#125;&#123;auditor=[]&#125;checkUserEndjava2security: falseappSecurityEnabled: falselogTrace: trueloglevel: *=info:SecurityManager=all:SystemOut=allexamples:validerrorPage:trueCheckContentsBrowser:validCheckFileServing:validcheckFile: ['/home/was/boss_app/boss-app-bd01-pf1/installedApps/boss-app-bd01-node1-cell/BOSS_APP.ear/boss_app_web.war/WEB-INF/ibm-web-ext.xmi']rolesMap/home/was/boss_app/boss-app-bd01-pf1/config/cells/boss-app-bd01-node1-cell/applications/BOSS_APP.ear/deployments/BOSS_APP/META-INF/ibm-application-bnd.xmiRolesMap:truerolesMapEndLTPA[[enableGlobalSecurity true] [dynUpdateSSLConfig true] [activeAuthMechanism LTPA] [adminPreferredAuthMech RSAToken] [useDomainQualifiedUserNames false] [cacheTimeout 600] [issuePermissionWarning true] [enforceJava2Security false] [appSecurityEnabled false] [enforceFineGrainedJCASecurity false] [activeUserRegistry WIMUserRegistry] [properties [[[name security.enablePluggableAuthentication] [value true] ][[name com.ibm.CSI.rmiOutboundPropagationEnabled] [value true] ][[name com.ibm.CSI.rmiInboundPropagationEnabled] [value true] ][[name com.ibm.CSI.rmiOutboundLoginEnabled] [value false] ][[name com.ibm.ws.security.webInboundPropagationEnabled] [value true] ][[name com.ibm.ws.security.ssoInteropModeEnabled] [value false] ][[name com.ibm.CSI.supportedTargetRealms] [value ] ][[name com.ibm.CSI.rmiInboundLoginConfig] [value system.RMI_INBOUND] ][[name com.ibm.CSI.rmiOutboundLoginConfig] [value system.RMI_OUTBOUND] ][[name com.ibm.ws.security.webInboundLoginConfig] [value system.WEB_INBOUND] ][[name com.ibm.ws.security.defaultLoginConfig] [value system.DEFAULT] ][[name com.ibm.wsspi.security.ltpa.tokenFactory] [value com.ibm.ws.security.ltpa.LTPATokenFactory|com.ibm.ws.security.ltpa.LTPAToken2Factory|com.ibm.ws.security.ltpa.AuthzPropTokenFactory] ][[name com.ibm.wsspi.security.token.authenticationTokenFactory] [value com.ibm.ws.security.ltpa.LTPATokenFactory] ][[name com.ibm.wsspi.security.token.authorizationTokenFactory] [value com.ibm.ws.security.ltpa.AuthzPropTokenFactory] ][[name com.ibm.wsspi.security.token.propagationTokenFactory] [value com.ibm.ws.security.ltpa.AuthzPropTokenFactory] ][[name com.ibm.wsspi.security.token.singleSignonTokenFactory] [value com.ibm.ws.security.ltpa.LTPAToken2Factory] ][[name com.ibm.ws.security.webChallengeIfCustomSubjectNotFound] [value true] ][[name com.ibm.security.useFIPS] [value false] ][[name com.ibm.websphere.security.DeferTAItoSSO] [value com.ibm.ws.security.spnego.TrustAssociationInterceptorImpl] ][[name com.ibm.ws.security.propagationExcludeList] [value com.ibm.security.jgss.*:javax.security.auth.kerberos.KerberosKey:javax.security.auth.kerberos.KerberosTicket] ][[name com.ibm.websphere.security.krb.allowLTPAAuth] [value true] ][[name com.ibm.websphere.security.krb.canonical_host] [value true] ][[name com.ibm.ws.security.addHttpOnlyAttributeToCookies] [value true] ][[name com.ibm.ssl.defaultCertReqSubjectDN] [value cn=10.96.18.227,ou=boss-app-bd01-node1-cell,ou=boss-app-bd01-node1,o=IBM,c=US] ][[name com.ibm.ssl.rootCertSubjectDN] [value [cn=10.96.18.227,ou=Root Certificate,ou=boss-app-bd01-node1-cell,ou=boss-app-bd01-node1,o=IBM,c=US]] ][[name com.ibm.ssl.rootCertValidDays] [value 5475] ][[name com.ibm.ssl.defaultCertReqDays] [value 365] ]]] ]LTPAEND]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>was</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[was收集类加载失败的trace日志方法]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fwas%E6%94%B6%E9%9B%86%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%A4%B1%E8%B4%A5%E7%9A%84trace%E6%97%A5%E5%BF%97%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[描述对于java.lang.ClassNotFoundException报错，需要收集classloader的trace，需要重启才能收集完整的数据。MustGather: Classloader problems for WebSphere Application Serverhttp://www-01.ibm.com/support/docview.wss?rs=180&amp;context=SSCVRZU&amp;q1=MustGatherDocument&amp;uid=swg21196187&amp;loc=en_US&amp;cs=utf-8&amp;lang=en 解决方法中文即：(1),管理控制台 -&gt; 服务器 -&gt; 应用程序服务器 -&gt; 您的服务器 -&gt; 服务器基础结构 -&gt; Java 和进程管理 -&gt; 进程定义 -&gt; Java 虚拟机选中 详细类装入 管理控制台 -&gt; 服务器 -&gt; 应用程序服务器 -&gt; 您的服务器 -&gt; 服务器基础结构 -&gt; Java 和进程管理 -&gt; 进程定义 -&gt; Java 虚拟机 通用JVM参数的最后使用空格与前面的配置隔开，然后直接添加下面的内容：1-Dws.ext.debug=true -Dws.osgi.debug 保存配置后重新启动后生效。 (2),您的服务器 -&gt; 故障诊断 -&gt; 诊断跟踪服务 最大大小 修改为 20历史日志文件的最大数 修改为 20 管理控制台 -》 服务器 》应用程序服务器 》 您的服务器 》故障诊断 》 更改日志详细信息级别将123*=info修改为：*=info:com.ibm.ws.classloader.*=all 确定后重新启动后生效。确认问题出现后执行 (3)收集日志12#cd /tmp#WASHOME/profiles/yourprofile/bin/collector.sh 将生成的 jar 发给我，将前面的配置恢复为原来的配置]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>was</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDFS的高级功能]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2FHDFS%E7%9A%84%E9%AB%98%E7%BA%A7%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[回收站HDFS的回收站：默认：禁用1、没有开启回收站时删除数据的提示：1217/04/12 20:50:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.Deleted /data 2、启用回收站：通过设置一个时间 —&gt; 本质：把删除的文件放到一个隐藏目录下12345678修改core-site.xml文件&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt; 日志：Moved: 'hdfs://192.168.10.44:9000/tools' to trash at: hdfs://192.168.19.44:9000/user/root/.Trash/Current 3、恢复1hdfs dfs -mv /user/root/.Trash/Current/tools/aaa.bbb /testfolder ORACLE的回收站补充：Oracle的回收站—-&gt; Oracle的闪回技术123456789101112131415161718192021222324252627SQL&gt; drop table emp;Table dropped.SQL&gt; select * from tab;TNAME TABTYPE CLUSTERID------------------------------ ------- ----------BIN$NR61HPlPEmTgUAB/AQAnFg==$0 TABLEBONUS TABLEDEPT TABLESALGRADE TABLETEST1 TABLESQL&gt; show recyclebin;ORIGINAL NAME RECYCLEBIN NAME OBJECT TYPE DROP TIME---------------- ------------------------------ ------------ -------------------EMP BIN$NR61HPlPEmTgUAB/AQAnFg==$0 TABLE 2016-06-13:09:21:28SQL&gt;SQL&gt; select * from "BIN$NR61HPlPEmTgUAB/AQAnFg==$0";通过Oracle的闪回(flashback)技术进行恢复SQL&gt; flashback table emp to before drop;通过回收站中的名字进行闪回:flashback table "BIN$NR61HPlUEmTgUAB/AQAnFg==$0" to before drop;闪回重名的表：flashback table emp to before drop rename to emp_old; 配额 quota(使用管理员命令)(1) 名称配额：限制目录下的文件个数(实际: 是个数-1)12345[-setQuota &lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;][-clrQuota &lt;dirname&gt;...&lt;dirname&gt;]hdfs dfs -mkdir /test1hdfs dfsadmin -setQuota 3 /test1 (2) 空间配额：限制目录下的文件大小—-&gt; 一定大于128M123456789101112[-setSpaceQuota &lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;][-clrSpaceQuota &lt;dirname&gt;...&lt;dirname&gt;]hdfs dfs -mkdir /test2hdfs dfsadmin -setSpaceQuota 1M /test2日志：The DiskSpace quota of /test2 is exceeded: quota = 1048576 B = 1 MB but diskspace consumed = 134217728 B = 128 MB重新设置hdfs dfsadmin -clrSpaceQuota /test2hdfs dfsadmin -setSpaceQuota 130M /test2 安全模式: safe mode(1) HDFS只读12345678910111213hdfs dfsadmin -safemodeUsage: java DFSAdmin [-safemode enter | leave | get | wait][root@hadoop111 tools]# hdfs dfsadmin -safemodeUsage: java DFSAdmin [-safemode enter | leave | get | wait][root@hadoop111 tools]# hdfs dfsadmin -safemode getSafe mode is OFF[root@hadoop111 tools]# hdfs dfsadmin -safemode enterSafe mode is ON[root@hadoop111 tools]# hdfs dfs -mkdir /test3mkdir: Cannot create directory /test3. Name node is in safe mode.[root@hadoop111 tools]# hdfs dfsadmin -safemode leaveSafe mode is OFF (2) 作用：HDFS在启动的过程中，首先会进入安全模式，来检查数据块的副本率如果数据块的副本率 &lt; HDFS默认的副本率(默认：0.9999) —–&gt; 数据块的水平复制 快照作用123(*) 是一种备份，保护重要的数据(*) 默认：禁用(*) 本质：把数据拷贝一份到一个隐藏目录下 开启快照（管理员）12345[-allowSnapshot &lt;snapshotDir&gt;][-disallowSnapshot &lt;snapshotDir&gt;]开启/students的快照：hdfs dfsadmin -allowSnapshot /students 生成快照（创建一个备份）:普通命令1234567-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]][-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;] hdfs dfs -createSnapshot /students snapshot_students_01 日志：Created snapshot /students/.snapshot/snapshot_students_01 对比快照123456hdfs dfs -put student02.txt /studentshdfs dfs -createSnapshot /students snapshot_students_02hdfs snapshotDiff /students snapshot_students_01 snapshot_students_02输出结果 M . + ./student02.txt 查看快照1hdfs lsSnapshottableDir 对比快照1hdfs snapshotDiff /input backup_input_01 backup_input_02 恢复快照1hdfs dfs -cp /input/.snapshot/backup_input_01/data.xtx /input]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创世记一到十一章]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E5%88%9B%E4%B8%96%E8%AE%B0%E4%B8%80%E5%88%B0%E5%8D%81%E4%B8%80%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[描述]]></content>
      <categories>
        <category>信仰文章</category>
      </categories>
      <tags>
        <tag>创世纪</tag>
        <tag>神学教材</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[命令行操作HDFS]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9CHDFS%2F</url>
    <content type="text"><![CDATA[描述1、普通操作命令: hdfs dfs （写法：hadoop fs ）（*）创建目录 -mkdir 在HDFS上创建目录123(*) Linux: mkdir -p /parent/child (*) hdfs dfs -mkdir /parent hdfs dfs -mkdir /parent/child （*）显示文件1234-ls 列出hdfs文件系统根目录下的目录和文件 递归显示目录下的子目录和文件-ls -R 列出hdfs文件系统所有的目录和文件-lsr （*）上传数据12345-put 上传文件或者从键盘输入字符到HDFS-moveFromLocal 与put相类似，命令执行后源文件 local src 被删除，也可以从从键盘读取输入到hdfs file中-copyFromLocal 与put相类似，也可以从从键盘读取输入到hdfs file中 Linux对应目录：/root/training/hadoop-2.4.1/tmp/dfs （*）下载数据12345678910-copyToLocal -get 将HDFS中的文件被复制到本地系统中-getmerge 将hdfs指定目录下所有文件排序后合并到local指定的文件中，文件不存在时会自动创建，文件存在时会覆盖里面的内容hdfs dfs -getmerge /students students.txt [root@hadoop111 temp]# more students.txt1,Tom,232,Mary,243,Jerry,20 -------&gt; Hive的外部表4,Jone,18 （*）删除数据123456-rm 每次可以删除多个文件或目录-rmr 删除目录和子目录日志：17/04/12 20:50:53 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.Deleted /data （*）复制和移动1234-cp 拷贝HDFS上的文件hdfs dfs -cp /students/student01.txt /students/student04.txt -mv 移动HDFS上的文件 （*）显示某个目录的统计信息1234-count 统计hdfs对应路径下的目录个数，文件个数，文件总计大小显示为目录个数，文件个数，文件总计大小，输入路径 hdfs dfs -count /students （*）每个文件或者目录的统计信息12-du 显示hdfs对应路径下每个文件夹和文件的大小 hdfs dfs -du /students （*）查看文件内容1-text、-cat 将文本文件或某些格式的非文本文件通过文本格式输出 （*）balancer 如果管理员发现某些DataNode保存数据过多，某些DataNode保存数据相对较少，可以使用上述命令手动启动内部的均衡过程1hdfs balancer （*）快照：默认禁用123[-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]][-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;][-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;] 2、管理员命令: hdfs dfsadmin **（*）安全模式: safemode 只读 —&gt; 检查数据块的副本率12[-safemode enter | leave | get | wait]hdfs dfsadmin -safemode get （*）快照的管理命令12[-allowSnapshot &lt;snapshotDir&gt;][-disallowSnapshot &lt;snapshotDir&gt;] （*）配额1234567名称配置----&gt; 目录下的文件个数[-setQuota &lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;][-clrQuota &lt;dirname&gt;...&lt;dirname&gt;] 空间配额 ---&gt; 文件的大小[-setSpaceQuota &lt;quota&gt; &lt;dirname&gt;...&lt;dirname&gt;][-clrSpaceQuota &lt;dirname&gt;...&lt;dirname&gt;]]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop搭建伪分布模式]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fhadoop%E6%90%AD%E5%BB%BA%E4%BC%AA%E5%88%86%E5%B8%83%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[描述特点： 具备Hadoop的所有的功能，在单机上，模拟一个分布式的环境 eg: 后台Java进程： NameNodeDataNodeSecondaryNameNode 第二名称节点ResourceManagerNodeManager 安装1、修改：/opt/hadoop-2.4.1/etc/hadoop/hadoop-env.sh 27行 export JAVA_HOME=/usr/java/jdk1.7.0_45 2、hdfs-site.xml: 配置HDFS的属性123456&lt;!--配置数据块的冗余度，默认3--&gt;&lt;!--一般跟数据节点个数一样，最大不要超过3--&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt; 3、core-site.xml:123456789101112131415161. HDFS的NameNode的地址2. 数据对应的Linux保存路径&lt;!--NameNode地址--&gt;&lt;!--端口：9000是RPC的端口--&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://192.168.10.44:9000&lt;/value&gt;&lt;/property&gt;&lt;!--DataNode对应的Linux保存的目录--&gt;&lt;!--默认：linux的tmp目录--&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop-2.4.1/tmp&lt;/value&gt;&lt;/property&gt; 4、map-site.xml：MapReduce运行的框架123456cp mapred-site.xml.template mapred-site.xml &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt; 5、yarn-site.xml:1234567891011121、Resourcemanager的地址2、MR运行的方式&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;192.168.10.44&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt; 6、对NameNode进行格式化12345成功：生成目录 ----&gt; 1. 元信息 2.数据块&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop-2.4.1/tmp&lt;/value&gt;&lt;/property&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172命令：hdfs namenode -format17/05/12 18:29:28 INFO namenode.NameNode: STARTUP_MSG:/************************************************************STARTUP_MSG: Starting NameNodeSTARTUP_MSG: host = redhat-master/192.168.10.44STARTUP_MSG: args = [-format]STARTUP_MSG: version = 2.4.1STARTUP_MSG: classpath = /opt/hadoop-2.4.1/etc/hadoop:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/had oop-2.4.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.4 .1/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop-2.4.1/share/ hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/comm ons-lang-2.6.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jer sey-json-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/protob uf-java-2.5.0.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jackson-core -asl-1.8.8.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/asm-3.2.jar:/ opt/hadoop-2.4.1/share/hadoop/common/lib/hadoop-annotations-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/java-xmlbuilder-0.4.ja r:/opt/hadoop-2.4.1/share/hadoop/common/lib/hadoop-auth-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar :/opt/hadoop-2.4.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoo p-2.4.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.4.1/sha re/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.4.1/share/hadoop/com mon/lib/httpcore-4.2.5.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jerse y-core-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/slf4j-api-1.7.5. jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/h adoop-2.4.1/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/h adoop-2.4.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.4. 1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/opt/hadoop- 2.4.1/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2. 4.1/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.4.1/share/h adoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop-2.4.1/sh are/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.4.1/share/hadoop/ common/lib/log4j-1.2.17.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/ jasper-runtime-5.5.23.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/junit-4.8.2.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/zookeepe r-3.4.5.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/ hadoop-2.4.1/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.4.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hado op-2.4.1/share/hadoop/common/hadoop-common-2.4.1-tests.jar:/opt/hadoop-2.4.1/share/hadoop/common/hadoop-common-2.4.1.jar:/opt/hadoop-2 .4.1/share/hadoop/common/hadoop-nfs-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/jetty-util-6 .1.26.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoo p-2.4.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.4.1 /share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.4.1/share/had oop/hdfs/lib/jackson-core-asl-1.8.8.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/co mmons-cli-1.2.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/jersey-core-1. 9.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop-2 .4.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.4.1/share/h adoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.4.1/share/hadoop/ hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/log4j- 1.2.17.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23 .jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/hadoop-hdfs-2.4.1-tests.jar:/opt/hadoop-2.4.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.4.1.jar:/op t/hadoop-2.4.1/share/hadoop/hdfs/hadoop-hdfs-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.4.1 /share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/ xz-1.0.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/ hadoop-2.4.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop- 2.4.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.4.1/s hare/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/opt/hadoop-2.4.1/share/ha doop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/javax. inject-1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/o pt/hadoop-2.4.1/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.4.1/s hare/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/jackson-jaxrs-1.8.8.jar:/opt/hadoop-2.4.1/share/had oop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/jackson-xc-1.8.8.jar:/opt/hadoop-2.4.1/share/hadoop/yar n/lib/jackson-mapper-asl-1.8.8.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/ guava-11.0.2.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/jersey-guice-1. 9.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar :/opt/hadoop-2.4.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.4. 1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/zookeeper-3.4.5.jar:/opt/hadoop-2.4.1/share/hado op/yarn/lib/jline-0.9.94.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/jersey -client-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/hadoop-yarn-ser ver-applicationhistoryservice-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.4.1.jar:/opt/hadoop-2.4.1/share /hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/hadoop-yarn-server-resourcem anager-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoo p/yarn/hadoop-yarn-server-web-proxy-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.4.1.jar:/opt/hadoop -2.4.1/share/hadoop/yarn/hadoop-yarn-api-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/hadoop-yarn-client-2.4.1.jar:/opt/hadoop-2.4.1/ share/hadoop/yarn/hadoop-yarn-common-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/yarn/hadoop-yarn-server-common-2.4.1.jar:/opt/hadoop-2.4 .1/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.4.1/share/hadoop/map reduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.4.1/share/had oop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.4.1/share/hadoop/m apreduce/lib/hadoop-annotations-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.4.1/share/hado op/mapreduce/lib/hamcrest-core-1.1.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.4.1/share/hado op/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduc e/lib/jersey-core-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduc e/lib/guice-servlet-3.0.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/opt/hadoop-2.4.1/share/hadoop/m apreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/mapre duce/lib/aopalliance-1.0.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/li b/jersey-server-1.9.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/lib/junit-4.10.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/hadoop-ma preduce-client-hs-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.4.1.jar:/opt/hadoop-2.4.1/share/ha doop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.1-te sts.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce /hadoop-mapreduce-client-shuffle-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.1.jar:/opt/h adoop-2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.4.1.jar:/opt/hadoop-2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-cli ent-common-2.4.1.jar:/opt/hadoop-2.4.1/contrib/capacity-scheduler/*.jarSTARTUP_MSG: build = http://svn.apache.org/repos/asf/hadoop/common -r 1604318; compiled by 'jenkins' on 2014-06-21T05:43ZSTARTUP_MSG: java = 1.7.0_45************************************************************/17/05/12 18:29:28 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]17/05/12 18:29:28 INFO namenode.NameNode: createNameNode [-format]Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /opt/hadoop-2.4.1/lib/native/libhadoop.so.1.0.0 which might have di sabled stack guard. The VM will try to fix the stack guard now.It's highly recommended that you fix the library with 'execstack -c &lt;libfile&gt;', or link it with '-z noexecstack'.17/05/12 18:29:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes whe re applicableFormatting using clusterid: CID-2a403c4d-f234-4261-9604-bb27d134b8e317/05/12 18:29:32 INFO namenode.FSNamesystem: fsLock is fair:true17/05/12 18:29:32 INFO namenode.HostFileManager: read includes:HostSet()17/05/12 18:29:32 INFO namenode.HostFileManager: read excludes:HostSet()17/05/12 18:29:32 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=100017/05/12 18:29:32 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true17/05/12 18:29:32 INFO util.GSet: Computing capacity for map BlocksMap17/05/12 18:29:32 INFO util.GSet: VM type = 64-bit17/05/12 18:29:32 INFO util.GSet: 2.0% max memory 966.7 MB = 19.3 MB17/05/12 18:29:32 INFO util.GSet: capacity = 2^21 = 2097152 entries17/05/12 18:29:32 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false17/05/12 18:29:32 INFO blockmanagement.BlockManager: defaultReplication = 117/05/12 18:29:32 INFO blockmanagement.BlockManager: maxReplication = 51217/05/12 18:29:32 INFO blockmanagement.BlockManager: minReplication = 117/05/12 18:29:32 INFO blockmanagement.BlockManager: maxReplicationStreams = 217/05/12 18:29:32 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks = false17/05/12 18:29:32 INFO blockmanagement.BlockManager: replicationRecheckInterval = 300017/05/12 18:29:32 INFO blockmanagement.BlockManager: encryptDataTransfer = false17/05/12 18:29:32 INFO blockmanagement.BlockManager: maxNumBlocksToLog = 100017/05/12 18:29:32 INFO namenode.FSNamesystem: fsOwner = root (auth:SIMPLE)17/05/12 18:29:32 INFO namenode.FSNamesystem: supergroup = supergroup17/05/12 18:29:32 INFO namenode.FSNamesystem: isPermissionEnabled = true17/05/12 18:29:32 INFO namenode.FSNamesystem: HA Enabled: false17/05/12 18:29:32 INFO namenode.FSNamesystem: Append Enabled: true17/05/12 18:29:33 INFO util.GSet: Computing capacity for map INodeMap17/05/12 18:29:33 INFO util.GSet: VM type = 64-bit17/05/12 18:29:33 INFO util.GSet: 1.0% max memory 966.7 MB = 9.7 MB17/05/12 18:29:33 INFO util.GSet: capacity = 2^20 = 1048576 entries17/05/12 18:29:33 INFO namenode.NameNode: Caching file names occuring more than 10 times17/05/12 18:29:33 INFO util.GSet: Computing capacity for map cachedBlocks17/05/12 18:29:33 INFO util.GSet: VM type = 64-bit17/05/12 18:29:33 INFO util.GSet: 0.25% max memory 966.7 MB = 2.4 MB17/05/12 18:29:33 INFO util.GSet: capacity = 2^18 = 262144 entries17/05/12 18:29:33 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.999000012874603317/05/12 18:29:33 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 017/05/12 18:29:33 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension = 3000017/05/12 18:29:33 INFO namenode.FSNamesystem: Retry cache on namenode is enabled17/05/12 18:29:33 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis17/05/12 18:29:33 INFO util.GSet: Computing capacity for map NameNodeRetryCache17/05/12 18:29:33 INFO util.GSet: VM type = 64-bit17/05/12 18:29:33 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB17/05/12 18:29:33 INFO util.GSet: capacity = 2^15 = 32768 entries17/05/12 18:29:33 INFO namenode.AclConfigFlag: ACLs enabled? false17/05/12 18:29:33 INFO namenode.FSImage: Allocated new BlockPoolId: BP-768855361-192.168.10.44-149458497362717/05/12 18:29:34 INFO common.Storage: Storage directory /opt/hadoop-2.4.1/tmp/dfs/name has been successfully formatted.17/05/12 18:29:35 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 017/05/12 18:29:35 INFO util.ExitUtil: Exiting with status 017/05/12 18:29:35 INFO namenode.NameNode: SHUTDOWN_MSG:/************************************************************SHUTDOWN_MSG: Shutting down NameNode at redhat-master/192.168.10.44************************************************************/ 7、启动: start-all.sh —&gt; 四次密码 停止：stop-all.sh —&gt; 四次密码 8、测试1234567891011121314151617hdfs dfs -put data.txt /datahadoop jar hadoop-mapreduce-examples-2.4.1.jar wordcount /data /output/wc hdfs dfs -ls /output/wc-rw-r--r-- 1 root supergroup 0 2017-05-12 18:54 /output/wc/_SUCCESS-rw-r--r-- 1 root supergroup 55 2017-05-12 18:53 /output/wc/part-r-00000hdfs dfs -cat /output/wc/part-r-00000 Beijing 2China 2I 2capital 1is 1love 2of 1the 1]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>hadoop</tag>
        <tag>spark</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop搭建本地模式]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fhadoop%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[描述安装配置Hadoop，本次安装为本地模式安装，在一台LINUX上完成 准备工作安装Linux、JDK、主机名、关闭防火墙 安装JDK12jdk-7u45-linux-x64.rpmrpm -ivh jdk-7u45-linux-x64.rpm 配置环境变量12export JAVA_HOEM=/usr/java/jdk1.7.0_45PATH=/usr/java/jdk1.7.0_45/bin:$PATH 测试安装是否成功1234[root@redhat-master tools]# java -versionjava version "1.7.0_45"Java(TM) SE Runtime Environment (build 1.7.0_45-b18)Java HotSpot(TM) 64-Bit Server VM (build 24.45-b08, mixed mode) 安装hadoop12hadoop-2.4.1.tar.gztar -zxvf hadoop-2.4.1.tar.gz -C /opt 安装到/opt目录下配置环境变量12345HADOOP_HOME=/opt/hadoop-2.4.1export HADOOP_HOMEexport JAVA_HOEM=/usr/java/jdk1.7.0_45PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:/usr/java/jdk1.7.0_45/bin:$PATH 配置hadoop修改1vi /opt/hadoop-2.4.1/etc/hadoop/hadoop-env.sh 测试例子在根目录创建temp/input 和/temp/output在input目录 创建测试文件data.txt如下:123I love BeijingI love ChinaBeijing is the capital of China 进入mapreduce目录执行如下命令：12cd /opt/hadoop-2.4.1/share/hadoop/mapreducehadoop jar hadoop-mapreduce-examples-2.4.1.jar wordcount ~/temp/input/ ~/temp/output/wc 执行过程中的日志如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /opt/hadoop-2.4.1/lib/native/libhado op.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.It's highly recommended that you fix the library with 'execstack -c &lt;libfile&gt;', or link it with '-z noe xecstack'.17/05/12 17:35:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable17/05/12 17:35:10 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.se ssion-id17/05/12 17:35:10 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=17/05/12 17:35:10 INFO input.FileInputFormat: Total input paths to process : 117/05/12 17:35:11 INFO mapreduce.JobSubmitter: number of splits:117/05/12 17:35:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1357466763_000117/05/12 17:35:11 WARN conf.Configuration: file:/tmp/hadoop-root/mapred/staging/root1357466763/.staging /job_local1357466763_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notificatio n.max.retry.interval; Ignoring.17/05/12 17:35:11 WARN conf.Configuration: file:/tmp/hadoop-root/mapred/staging/root1357466763/.staging /job_local1357466763_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notificatio n.max.attempts; Ignoring.17/05/12 17:35:12 WARN conf.Configuration: file:/tmp/hadoop-root/mapred/local/localRunner/root/job_loca l1357466763_0001/job_local1357466763_0001.xml:an attempt to override final parameter: mapreduce.job.end -notification.max.retry.interval; Ignoring.17/05/12 17:35:12 WARN conf.Configuration: file:/tmp/hadoop-root/mapred/local/localRunner/root/job_loca l1357466763_0001/job_local1357466763_0001.xml:an attempt to override final parameter: mapreduce.job.end -notification.max.attempts; Ignoring.17/05/12 17:35:12 INFO mapreduce.Job: The url to track the job: http://localhost:8080/17/05/12 17:35:12 INFO mapreduce.Job: Running job: job_local1357466763_000117/05/12 17:35:12 INFO mapred.LocalJobRunner: OutputCommitter set in config null17/05/12 17:35:12 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output .FileOutputCommitter17/05/12 17:35:12 INFO mapred.LocalJobRunner: Waiting for map tasks17/05/12 17:35:12 INFO mapred.LocalJobRunner: Starting task: attempt_local1357466763_0001_m_000000_017/05/12 17:35:13 INFO mapred.Task: Using ResourceCalculatorProcessTree : [ ]17/05/12 17:35:13 INFO mapred.MapTask: Processing split: file:/root/temp/input/data.txt:0+6017/05/12 17:35:13 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$Ma pOutputBuffer17/05/12 17:35:13 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)17/05/12 17:35:13 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 10017/05/12 17:35:13 INFO mapred.MapTask: soft limit at 8388608017/05/12 17:35:13 INFO mapred.MapTask: bufstart = 0; bufvoid = 10485760017/05/12 17:35:13 INFO mapred.MapTask: kvstart = 26214396; length = 655360017/05/12 17:35:13 INFO mapred.LocalJobRunner:17/05/12 17:35:13 INFO mapred.MapTask: Starting flush of map output17/05/12 17:35:13 INFO mapred.MapTask: Spilling map output17/05/12 17:35:13 INFO mapred.MapTask: bufstart = 0; bufend = 108; bufvoid = 10485760017/05/12 17:35:13 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); leng th = 45/655360017/05/12 17:35:13 INFO mapred.MapTask: Finished spill 017/05/12 17:35:13 INFO mapred.Task: Task:attempt_local1357466763_0001_m_000000_0 is done. And is in the process of committing17/05/12 17:35:13 INFO mapred.LocalJobRunner: map17/05/12 17:35:13 INFO mapred.Task: Task 'attempt_local1357466763_0001_m_000000_0' done.17/05/12 17:35:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local1357466763_0001_m_000000_017/05/12 17:35:13 INFO mapred.LocalJobRunner: map task executor complete.17/05/12 17:35:13 INFO mapred.LocalJobRunner: Waiting for reduce tasks17/05/12 17:35:13 INFO mapred.LocalJobRunner: Starting task: attempt_local1357466763_0001_r_000000_017/05/12 17:35:13 INFO mapreduce.Job: Job job_local1357466763_0001 running in uber mode : false17/05/12 17:35:13 INFO mapred.Task: Using ResourceCalculatorProcessTree : [ ]17/05/12 17:35:13 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task .reduce.Shuffle@5d7106d17/05/12 17:35:13 INFO mapreduce.Job: map 100% reduce 0%17/05/12 17:35:13 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleL imit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=1017/05/12 17:35:13 INFO reduce.EventFetcher: attempt_local1357466763_0001_r_000000_0 Thread started: Eve ntFetcher for fetching Map Completion Events17/05/12 17:35:13 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local 1357466763_0001_m_000000_0 decomp: 89 len: 93 to MEMORY17/05/12 17:35:13 INFO reduce.InMemoryMapOutput: Read 89 bytes from map-output for attempt_local1357466 763_0001_m_000000_017/05/12 17:35:13 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 89, inMemoryMa pOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;8917/05/12 17:35:13 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning17/05/12 17:35:13 INFO mapred.LocalJobRunner: 1 / 1 copied.17/05/12 17:35:13 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on -disk map-outputs17/05/12 17:35:13 INFO mapred.Merger: Merging 1 sorted segments17/05/12 17:35:13 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 79 bytes17/05/12 17:35:13 INFO reduce.MergeManagerImpl: Merged 1 segments, 89 bytes to disk to satisfy reduce m emory limit17/05/12 17:35:13 INFO reduce.MergeManagerImpl: Merging 1 files, 93 bytes from disk17/05/12 17:35:13 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce17/05/12 17:35:13 INFO mapred.Merger: Merging 1 sorted segments17/05/12 17:35:13 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 79 bytes17/05/12 17:35:13 INFO mapred.LocalJobRunner: 1 / 1 copied.17/05/12 17:35:13 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce. job.skiprecords17/05/12 17:35:13 INFO mapred.Task: Task:attempt_local1357466763_0001_r_000000_0 is done. And is in the process of committing17/05/12 17:35:13 INFO mapred.LocalJobRunner: 1 / 1 copied.17/05/12 17:35:13 INFO mapred.Task: Task attempt_local1357466763_0001_r_000000_0 is allowed to commit n ow17/05/12 17:35:13 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1357466763_0001_r _000000_0' to file:/root/temp/output/wc/_temporary/0/task_local1357466763_0001_r_00000017/05/12 17:35:13 INFO mapred.LocalJobRunner: reduce &gt; reduce17/05/12 17:35:13 INFO mapred.Task: Task 'attempt_local1357466763_0001_r_000000_0' done.17/05/12 17:35:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local1357466763_0001_r_000000_017/05/12 17:35:13 INFO mapred.LocalJobRunner: reduce task executor complete.17/05/12 17:35:14 INFO mapreduce.Job: map 100% reduce 100%17/05/12 17:35:14 INFO mapreduce.Job: Job job_local1357466763_0001 completed successfully17/05/12 17:35:14 INFO mapreduce.Job: Counters: 33 File System Counters FILE: Number of bytes read=541166 FILE: Number of bytes written=984442 FILE: Number of read operations=0 FILE: Number of large read operations=0 FILE: Number of write operations=0 Map-Reduce Framework Map input records=3 Map output records=12 Map output bytes=108 Map output materialized bytes=93 Input split bytes=95 Combine input records=12 Combine output records=8 Reduce input groups=8 Reduce shuffle bytes=93 Reduce input records=8 Reduce output records=8 Spilled Records=16 Shuffled Maps =1 Failed Shuffles=0 Merged Map outputs=1 GC time elapsed (ms)=99 CPU time spent (ms)=0 Physical memory (bytes) snapshot=0 Virtual memory (bytes) snapshot=0 Total committed heap usage (bytes)=252190720 Shuffle Errors BAD_ID=0 CONNECTION=0 IO_ERROR=0 WRONG_LENGTH=0 WRONG_MAP=0 WRONG_REDUCE=0 File Input Format Counters Bytes Read=60 File Output Format Counters Bytes Written=67 查看生成的目录文件 hadoop目录结构]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>hadoop</tag>
        <tag>spark</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop学习笔记第一天]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fhadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E7%AC%AC%E4%B8%80%E5%A4%A9%2F</url>
    <content type="text"><![CDATA[一、学什么？Hadoop、Spark(Scala编程语言)1、重要：原理—-&gt; 画图 2、安装和配置 3、操作：命令行、Java API、Web Console（控制台） 二、搭建Linux环境:一定要关闭防火墙 service iptables status service iptables stop 1、vi编辑器::set number 显示行号 :set wrap 换行 :set nowrap 不换行 搜索：/ ### 2、配置文件：/etc/hosts 配置IP地址和主机名的关系 增加：192.168.137.111 hadoop111 ### 3、安装JDK (*)tar -zxvf jdk-7u75-linux-i586.tar.gz -C ~/training/ (*)设置环境变量：~/.bash_profile JAVA_HOME=/root/training/jdk1.7.0_75 export JAVA_HOME PATH=$JAVA_HOME/bin:$PATH export PATH (*) 使环境变量生效 source ~/.bash_profile ### 4、安装Tomcat tail -f localhost_access_log.2017-04-12.txt 三、各章概述(一)、Hadoop的起源与背景知识#### 1、什么是大数据？举例： （1）商品推荐 问题1：大量的订单如何存储？如何找到订单？---&gt; 大数据的存储 问题2：如何计算订单？ -----&gt; 大数据的计算 （2）天气预报 问题1：大量的天气数据存储？如何找到？ ---&gt; 大数据的存储 问题2：如何计算？ -----&gt; 大数据的计算 核心：（1） 数据的存储 （2） 数据的计算 #### 2、传统的解决大数据问题的方式：数据仓库(Oracle、MySQL) Hadoop是数据仓库的一种实现方式 #### 3、概念：OLTP和OLAP Hadoop是数据仓库的一种实现方式,数据仓库是一个OLAP的应用 (*) OLTP: online transaction process 联机事务处理 (*) OLAP: online analytic process 联机分析处理: 一般只做select #### 4、（重点）Google的基本思想: Hadoop看成是一个山寨版的Google Google Hadoop （1）GFS（Google File System） ---&gt; HDFS(Hadoop Distributed File System) (*) 文件的元信息： 命令：hdfs dfs -put a.avi /movie 文件的元信息(大概150B)：---&gt; HDFS适合存单个的大文件 { 文件名：a.avi 路径：/movie 大小：200M 数据块：2个 数据块1：{DN1:5} 冗余信息： {DN2:10} {DN1:10} 数据块2：{DN3:2} 冗余信息： {DN2:8} {DN1:11} } (*) 数据如何找到？ ----&gt; 倒排索引 Reverted Index (*) 复习：Oracle的索引 index，可以提高查询的效率 概念：rowid 行地址，伪列 rownum 行号，伪列 ---&gt; 分页查询 执行计划： Oracle: explain plan for select * from emp where deptno=10; select * from table(dbms_xplan.display); Hive:执行SQL explain select * from emp where deptno=10; （1）没有索引 -------------------------------------------------------------------------- | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | -------------------------------------------------------------------------- | 0 | SELECT STATEMENT | | 3 | 261 | 3 (0)| 00:00:01 | |* 1 | TABLE ACCESS FULL| EMP | 3 | 261 | 3 (0)| 00:00:01 | -------------------------------------------------------------------------- （2）有索引 create index myindex on emp(deptno); --------------------------------------------------------------------------------------- | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | --------------------------------------------------------------------------------------- | 0 | SELECT STATEMENT | | 3 | 261 | 2 (0)| 00:00:01 | | 1 | TABLE ACCESS BY INDEX ROWID| EMP | 3 | 261 | 2 (0)| 00:00:01 | |* 2 | INDEX RANGE SCAN | MYINDEX | 3 | | 1 (0)| 00:00:01 | --------------------------------------------------------------------------------------- （*）倒排索引 Reverted Index （2）PageRank（搜索排名） ---&gt; MapReduce(Java程序) （3）BigTable(大表) ---&gt; HBase (二)、实验环境(三)、Apache Hadoop的体系结构(重要)1、HDFS的体系结构 2、Yarn的体系结构：运行MapReduce程序 3、HBase的体系结构 (四)、Hadoop 2.X的安装与配置1、本地模式 （一台Linux） 2、伪分布模式 （一台Linux） 3、全分布模式 （三台Linux） (五)、Hadoop应用案例分析1、基于大数据的应用架构 2、日志分析（用户行为分析） 3、Hadoop在淘宝的应用 (六)、HDFS：存数据的#### 1、操作：命令行、Java API、Web Console（控制台） #### 2、HDFS的提供功能： （*）回收站recyclebin：补充：Oracle回收站 （*）快照snapshot：备份 （*）配额quota： （1）名称配额 : 限制目录下的文件的个数 （2）空间配额 ：限制目录下的文件的大小 （*）安全模式（safemode）：重要，如果是安全模式，HDFS只读 （*）权限：chmod，类似Linux的权限 #### 3、HDFS底层原理 （*）RPC：remote procedure call 远程过程调用 （*）Java的动态代理 (七)、MapReduce: Java程序 —&gt; 提交Yarn(容器)上运行 —&gt; 处理的是HDFS的数据#### 1、第一个程序：WordCount单词计数 数据: I love Beijing I love China Beijing is the capital of China #### 2、（重要:画图）MapReduce程序的编程模型：数据流动的过程 #### 3、开发自己的WordCount程序 #### 4、MapReduce提供功能：排序、序列化、合并（Combiner，可以提高效率） 分区（Partition：可以提高效率） #### 5、重要：MapReduce的核心：Shuffle(洗牌) #### 6、MapReduce案例程序：去掉重复记录、多表查询、自连接、 倒排索引(Reverted Index) #### 7、使用MRUnit对MR进行单元测试 数据分析的引擎：Hive Pig Impala(基于C语言)补充：MySQL数据库 (八)、Hive: 支持SQL（子集）: select insert(九)、Pig: 支持Pig Latin(十)、HBase: Hadoop Database,NoSQL数据库1、体系结构（重要），和Hadoop的关系 2、安装和配置 1、本地模式 （一台Linux） 2、伪分布模式 （一台Linux） 3、全分布模式 （三台Linux） 3、操作：命令行：hbase shell Java API Web Console 4、HBase的原理 5、HBase的过滤器（类似where）：就是一个Java程序 6、使用MR处理HBase的数据 数据采集的工具 (十一)、Sqoop: RDBMS(Oracle,MySQL关系型数据库) &lt;—&gt; Hadoop(HDFS)(十二)、Flume: 采集日志 —&gt; Hadoop(HDFS)(十三)、HUE: 基于Web的管理工具实现Hadoop的集群（HA：high avaibility 高可用性）: 四台 (十四)、ZooKeeper：相当于是一个数据库(十五)、Hadoop的集群和HA:（*）联盟：Federation （*）HA ============================================================== (十六)、Storm: 实时处理系统1、区别：离线计算(Hadoop MR)和流式计算（实时计算:Storm） 2、搭建Storm：（三台机器） 3、编程模型 4、开发Storm程序：WordCount 5、Storm和其他系统集成: Redis、HDFS、HBase、Hive JMS（Java Messaging Service）、Kafka（消息系统） 四、图形描述分布式文件系统 机架感知 数据仓库]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>hadoop</tag>
        <tag>spark</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017-05-04祷告会]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F2017-05-04%E7%A5%B7%E5%91%8A%E4%BC%9A%2F</url>
    <content type="text"><![CDATA[为自己的服侍祷告我们应当想一个问题，我们应当服侍谁，以及如何服侍他们，加6：1-2服侍这个词听起来挺吓人的，别人的麻烦我们不想掺和，我们自己的麻烦已经够多了，何必没事找事呢，但是，我们必须与其他弟兄姐妹产生关系，服侍人也被人服侍，提出意见也接受意见，有人说过，如果你在JH不积极参与服饰就是在伤害弟兄姐妹。我们必须伸手，因为上帝护照我们是为了帮助别人和被人帮助的。我们的问题不仅仅是自己的问题，归根揭底，上帝把我们放在JH中，我们的问题就是JH整体的问题，上帝护照你去勉励挑战和帮助你生命中其他的弟兄姐妹，并且他们也蒙召来关心你，我们必须在服侍别人的过程中，自己才能逐渐成圣。下面我们来思考自己目前的环境，寻找服侍的机会，上帝把那些有需要的人放在你周围，你能为他们做什么，你做了些什么？ 为自己敬虔的生活祷告保罗也告诉提摩太：有敬虔的外貌却被了敬虔的实意，这等人你要躲开何为真正的敬虔？表现在行为上？还是存在于人的内心？祷告的时间或次数越多就越敬虔？读的圣经越多或参加的宗教活动越多就越敬虔吗？神的仆人说，“敬虔意味着摆上整个生命，全然献给上帝。所谓敬虔者，就是不再随从自己的意思或今世的风俗，而是单单顺从上帝的旨意，凡事都尊崇上帝，凡事都服侍上帝，凡事都奉上帝的名，凡事都荣耀上帝，以上帝的事为念”这是敬虔的本质。保罗说：「操练身体，益处还少；惟独敬虔，凡事都有益处，因有今生和来生的应许。」人若操练敬虔，就要看到基督的生命时刻彰显在他的思想、言语、动作、以及态度里，保罗告诉提莫太，只是要弃绝那世俗的言语，和老妇荒渺的话，在敬虔上操练自己。敬虔的生活能给我们带来服侍的保障。敬虔的生活能够使我们更加认识到自己的不足。 为彼负扼祷告上帝呼召我们这一群人成为地上的JH，要我们彼此负扼，我们知道彼此负额并不容易，我们都有自己的棱角，都有自己的原生家庭、都有自己的生活习惯，我们都受罪的辖制，以自我为中心，做事独来独往，遇到挫折灰心丧气，没有喜乐和顺服，这并不是上帝对JH的计划，上帝希望JH全休信徒联为一体，而不是一群孤立的个体，人被造并不是为了孤军奋战。所以求神给我们彼此连接的心、彼此配合的心、彼此负额的生命。让我们学会付代价， 为教会大使命祷告现今的很多JH，都变得相当封闭，世人看不见我们如何彼此相爱，而我们的JH生活只是主日聚集在一起，周间的小组查经，世人并不知道我们怎么去荣耀神，我们活不出群体的美好，经上说城造在山上是不能隐藏的（太5：14-16），我们的JH应当成为灯塔而不是防空洞，耶稣在被卖的那一夜他为门徒祷告：要使我们合一。耶稣说我们彼此相爱彼此合一世人就因此认出我们，现在为JH祷告使JH对内有栽培对外有开拖，求上帝的灵充满JH，使JH苏醒，让每一个肢体都可以回应上帝的护照，在他的救赎计划中有份。能够兼起神给我们的使命。]]></content>
      <categories>
        <category>团契生活</category>
      </categories>
      <tags>
        <tag>祷告会</tag>
        <tag>团契</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎样读圣经]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E6%80%8E%E6%A0%B7%E8%AF%BB%E5%9C%A3%E7%BB%8F%2F</url>
    <content type="text"><![CDATA[描述我要给不同的人一些不同的读经建议： 致“能读，但却从不读经”的人 致“打算开始读，想寻求如何开始建议的人” 致“爱圣经，相信圣经，但只读了一点点的人” 致“熟读圣经，却觉得并没有从中获益的人” 致“真爱圣经，依靠圣经，规律读经的人” 1. 致“能读，但却从不读经”的人你是这样的人吗？如果是，我有话要对你说。以你现在的状态，我无法安慰你，安慰你也毫无意义。你这样对待圣经，我也不能对你讲平安或者天堂，你很可能会失丧灵魂！ 你很危险，因为“你所忽视的圣经就是你不爱上帝的明证”！身体的健康大体上可以从胃口来判断，灵魂的健康能从如何对待圣经来判断，你显然活在重病之中，你还不悔改吗！？ 我看不到你的心，不能让你明白，也不能让你体会到这件事。我能做的只是对你现在的状态严肃抗议，并把这抗议放在你的良心面前。为此，我恨不能把我的心掏给你！不要悔改得太迟了！不要忽视圣经，直到你病重到最后的时刻，发现圣经根本读不懂，对你不安的灵魂来说，这就像以色列人和埃及人之间的云一样乌黑！不要在你一生之中，一直说“没有圣经人也能过得很好”，但到了时候，却发现，没有圣经，人很可怜，结局就是地狱！不要到了那天，你才明白：“怎么对我来说报纸都比圣经有价值呢？不应该这样，我不应该最后的时刻不得安慰！”忽视圣经的读者，我要直接警告你，审判就在你的门口，随时准备进来毁灭你！求上帝怜悯你！ 2. 致“打算开始读，想寻求如何开始建议的人”你是这类人吗？听听我的建议吧！ ① 今天就开始读经要做一件事的方法就是去“做”，读经的方法就是马上去“读”。不是概念、愿望、分析、计划、思考，这些不能使你前进哪怕一步！你必须切实去“读”。读经和祷告一样，没有捷径。如果你自己不能读，就要找别人来读给你听。不论是通过眼睛还是耳朵，圣经的话必须进入你的心里！ ② 以渴望明白圣经的心来读认为只需翻阅一定数量的纸张，里面的意思理解与否完全不重要，这样的想法，要扼杀在摇篮里！一些无知的人认为，只要每天读很多章圣经，即便不明白所读的内容，只知道书签应该放在哪里就万事大吉了。这是把读经变为形式！这和罗马天主教买赎罪券的习惯一样败坏，不理解圣经就不能从圣经得益处。你读经时，要经常自问：“这些内容到底是什么意思？”像挖金子一样挖掘圣经的含义，要努力，不要太快放弃。 ③ 以孩子般的信心和谦卑来读经打开圣经的同时，也打开你的心，对上帝说：“主啊，请对我说话，你的仆人静听。”即便与你有限的理性背道而驰，也要下定决心相信圣经的内容，即便你不喜欢，也要下定决心接受圣经的真理！ 警惕，一些读者有“削减”圣经的习惯。他们只接受喜欢的教义，那些谴责自己或爱人、亲戚、朋友的内容，他们便抵制。这样的话，圣经就毫无用处。我们能判断什么应该在圣经中吗？我们比上帝更有智慧吗？记住，你要接受和相信圣经中的一切，即便你不能理解，也要凭着信心接受。记住，你祷告时，是你在对上帝说，上帝在听；但是，你读经时，是上帝在对你说，你要做的不是顶嘴，而是“听”！ ④ 以顺服和应用的心来读经每天读经时，要下定决心：按照圣经的原则生活，要依靠圣经，行事为人要遵从圣经的命令。读经时，要思考：这如何影响“我的”想法和行为？这教导“我”什么？因为好奇或者为了增加学识而读经，却不接受圣经对你的心灵和行为的影响，是错误的。阅读圣经最好的方法就是在每日的生活中行所读的内容！ ⑤ 每天都要读经把阅读和默想上帝的话语作为每日必须要做的事。每日的灵粮像身体的食物和衣服一样必须。昨天的饭菜不能供应今天的需要，今天的饭菜不能供应明天的需要。像旷野的以色列人一样，每天早晨领取新鲜的吗哪。选择适合你的时间，不要匆匆读经，把最好的时间而不是最差的时间留给圣经。不论你的计划是什么，每天都来到恩典的宝座前读经，这要成为习惯。 ⑥ 按顺序读经恐怕圣经中的很多章节，有些人根本没读过。这是一个非常骄傲的习惯，“圣经都是神所默示的，于教训，督责，使人归正，教导人学义，都是有益的”（提后3:16）。这种习惯现在很普遍，但是却缺乏对真理的全面把握。有些人读经的习惯是挑挑拣拣，他们似乎从来没有打算规律地通读整本圣经，这也同样是巨大的错误。当然，在疾病和痛苦中时，寻找一些对应的经文是可以的，但这是例外。我相信，到目前为止，最好的读经计划就是同时开始通读旧约和新约，读完之后，再从头开始。这是每个人都应该记住的。这种方法我已经坚持了将近40年，从未改变过。 ⑦ 不带偏见、诚实地读经对圣经的文本，要采取最朴素和明显的解释，对于强解要十分警惕。按照一般的规则，圣经里所讲的就是它要讲的。西塞尔的方法非常有价值：“解经的正确方法就是，我们读到的就是圣经要讲的，不要试图去以特殊的方式强解。”胡克说：“绝对可靠的解经原则就是，文本本身的意思。离文本的意思越远就越危险。” ⑧ 最后，以基督为中心来读经整本圣经都是为了证明耶稣： 旧约的仪式是基督的影子； 旧约的士师和拯救者是基督的预表； 旧约的历史表明这个世界需要基督； 旧约的预言成就在基督的受难上； 旧约的预言成就在基督的荣耀再来时； 第一次的到来和第二次的到来； 基督的羞耻； 基督的国； 基督的十字架和冠冕。 这些内容充满圣经，记住这些能让你正确地读经。 如果篇幅允许，我还能列出很多。但即使这几点，也能引起你的注意了。遵照这个，我坚信你绝不会迷失去天堂的路。遵照这个，你心里的光就会不断增长。没有其他书的证据能和人从持续不断地读经中所获得的内在证据相比。这样的人不需要博学之士的著作，他自己已经掌握了证据。这本书喂养并满足他的灵魂。一个穷苦的基督徒妇女曾对一个不信的人说：“我没有知识，不能跟你辩论，但是因为尝了之后留在我嘴里的香甜味道，所以我知道蜂蜜是蜂蜜，同样，因为尝了之后我心里留下的味道，所以我知道圣经是上帝的书。” 3. 致“爱圣经，相信圣经，但只读了一点点的人”这样的人恐怕有很多。这个时代是忙碌的速食时代，是充斥着各种会议的时代，所以，私人读经的时间会缩短或者减少。你的良心是在说你就是这样的人吗？认真听，我要说的绝对值得你全神贯注。 ◆ 你可能是“需要的时候从圣经得少许安慰的人”。试探随时存在，苦难像疾风，吹掉树叶，使鸟窝失去保护。我怕你那点可怜的圣经储备会越来越少，我怕到了最后，你会发现，可用的圣经“额度”太小，避难的逃城弱不禁风！ ◆ 你可能是“从不立足于圣经真理的人”。如果听到你在得救、恩典、信心、坚韧等这些问题上有很多困惑，那我绝不惊讶。魔鬼老奸巨猾，像便雅悯人一样，它“能用机弦甩石打人，毫发不差。”（士师记20:16）。只要他高兴，就能随时引用圣经。你却没有准备好武器与他大战一场。你的盔甲还没穿上，你的刀剑也没握紧。 ◆ 你可能是“在生活中总是出错的人”。你的婚姻、对孩子的教养、家庭琐事、公司事务，这些都不顺，你的世界到处触礁，因为你对“灯塔”和“处方”并不熟悉。 ◆ 你可能是“让假师傅带着走了一段时间的人”。那些聪明雄辩的人，可以给谎言穿上真理外衣的人，把你带入错谬之中，我一点也不惊讶。你已经完全失衡，所以不能怪别人把你甩来甩去，像风浪中的一块破木板。 说这些多么令人不安！希望读者要逃避！要听我的建议！对于圣经，不要只读“一点点”，要读“很多”。“把基督的道理，丰丰富富地存在心里”（歌罗西书3:16）。在属灵的知识上，不要总是做一个婴孩，要努力在神国知识上装备，不断地学习新知识。宗教的情感是非常不确定的，就像潮水，时涨时落，就像月亮，时亮时暗。但深深扎根于圣经的信仰，是牢固持久的财产，使人不仅能说：“在基督里，我感觉有盼望。”更能说：“我知道我所信的是谁！”（提后1:12） 4. 致“熟读圣经，却觉得并没有从中获益的人”这是魔鬼狡猾的试探。有时他会说：“根本别读经”，有时他会说：“读经给你带来什么好处了吗？别读了！”是这样吗？我深切地同情你。希望我说的话对你有帮助。 不要因为你一直没有看到圣经带来的益处，就认为你不能从圣经中获益。最伟大的产品制造出来之前，都是沉默安静不易被察觉的。想想月亮对地球的影响，空气对肺的影响吧，想想露珠无声地掉落，想想青草悄悄地长高。读经对灵魂的影响，远比你认为的大的多！ 神的话也许正逐渐地进深地改变你的心，只是你并未发觉。通常的规律是，记不得什么了，但是性格却受到了永久地影响。每年，你是不是都对罪更加厌恶？基督是不是越发珍贵？圣洁在你眼中是不是变得可爱，更令你渴慕？如果答案是肯定的，那么鼓起勇气继续坚持吧！圣经的确对你产生了益处，虽然你并没有察觉。 圣经也许正在阻止你朝着罪恶和迷惑前进的脚步，圣经也许正在把你从深陷愚蠢的沼泽中拯救出来。如果停止读经，你很快就会发现四面受敌，被罪捆绑。有时，我们会因为恩典白白得来而忘记它的价值。 努力抵制魔鬼！读经带来的属灵呼吸，正在使你的灵魂一天比一天强壮，不论是感觉如何，都要把这点牢记于心！ 5. 致“真爱圣经，依靠圣经，规律读经的人”你是这样的人吗？我想对你说一些话，使你能更好地预备主再来的日子。 ◆ 要下定决定每年都“越来越多地读经”，这要印在心上。要带着丰富的圣经知识来应对死亡的航行。也许我们的道路充满风雪，视力和听力的衰退会打败我们，也许我们会掉入深水之中。哦！在那样的时刻，要将他的话“存在心里”！（诗篇119:11） ◆ 要下定决心每年都要“在读经上警醒”。要警醒读经的时间和方式，没有足够的理由，绝不能省略每日的读经。读经时，不要发呆、打瞌睡、哈欠连天，要像伦敦的商人读泰晤士报的城市版一样，或者像妻子读远方丈夫的来信一样。要警醒，不要让任何牧师、讲道、书籍、小册子、朋友的话，高于圣经的话。那些横亘在你与圣经之间，使你看不到圣经的书籍、小册子或者辅导，都是应当受咒诅的！我再说一遍，要非常小心！我们打开圣经的那一刻，魔鬼就坐在身边。要以渴慕的心来读经，要以单纯受教的心来读经！ ◆ 要下定决心“在家里更尊崇圣经”。早晚都读给孩子和配偶听，不要羞于让别人知道，不要因为没有看到效果就气馁。家庭的读经已经使很多人免受牢狱之灾，保守很多人脱离地狱不灭的火。 ◆ 要下定决心“更多地默想圣经”。随身携带两三段经文，一有空就在脑子里反复思想，对我们十分有益。默想经文保守我们不胡思乱想，给日常的阅读带来标准，使灵魂免遭萧条或滋生腐败，使思想圣洁活泼，不成为只剩蛤蟆没有鱼的池塘。 ◆ 要下定决心和弟兄姊妹“更多地谈论圣经”。恕我直言，基督徒之间的谈话，通常毫无意义！多少都是无聊、轻佻、冷漠的内容！要更多地谈论圣经，这能帮助我们赶走魔鬼，保守我们的心意合一。在这邪恶的世界，我们需要努力一起往前走，耶稣常伴我们左右，与我们同行，就像他在以马忤斯与两个门徒同行一样！ ◆ 最后，要下定决心每年都“越来越按照圣经活着”。不论是世界上还是家里，要经常反思我们的想法和行为、习惯和脾气，在公众场合和私下的表现。让我们以圣经为尺子来衡量每件事，在上帝的帮助下来解决每件事，我们就会越来越明白“用什么洁净我们的行为呢？是要遵行你的话。”（诗篇119:9） 希望每位读者都严肃认真地阅读这本书。希望我深爱的牧师都是读经的牧师；我深爱的会众都是读经的会众；而我深爱的这个国家，是一个读经的国家！最后，我把这愿望放在上帝手中，祈求上帝成就！]]></content>
      <categories>
        <category>团契生活</category>
      </categories>
      <tags>
        <tag>团契</tag>
        <tag>读经</tag>
        <tag>灵修</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redhat中安装virtualbox虚拟机]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fredhat%E4%B8%AD%E5%AE%89%E8%A3%85virtualbox%2F</url>
    <content type="text"><![CDATA[描述虽然rhel中有自带的虚拟机软件virtual machine manager。但是它只能设置一个网卡。如果想虚拟机中设置多块网卡，可以使用简单的virtualbox。 安装步骤：1：下载软件并上传virtualbox下载网址1https://www.virtualbox.org/wiki/Download_Old_Builds_5_0 2：yum安装virtualbox说明：安装之前需要安装SDL-1.2.14-6.e16.x86_64.rpm安装virtualbox 3：打开virtualbox]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>redhat</tag>
        <tag>virtualbox</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Mesos管理Docker集群]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E4%BD%BF%E7%94%A8Mesos%E7%AE%A1%E7%90%86Docker%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[描述说明：本次测试刚开始的时候使用的是传统的was8.5.5，发现使用marathon来管理的时候一直有问题，该问题后期解决。 Liberty就是为微服务产生的，小巧灵活部署方便。关于mesos 还有很多知识点要学，比如Mesos DRF算法、Master/Slave资源调度等。 熟知 mesos总体架构Apache Mesos 是一个分布式系统的管理软件，对集群的资源进行分配和管理。总体架构如下： Mesos组成部分Mesos-master：主要负责管理各个framework和slave，并将slave上的资源分配给各个framework Mesos-slave：负责管理本节点上的各个mesos-task，比如：为各个executor分配资源 Framework：计算框架，如：Hadoop，Spark等，通过MesosSchedulerDiver接入Mesos Executor：执行器，安装到mesos-slave上，用于启动计算框架中的task。 资源提供的例子 让我们一起来熟悉下这个图上的流程步骤： 1)slave 1 报告给master他拥有4核cpu和4G剩余内存，matser调用allocation政策模块，告诉salve 1 计算框架1应该被提供可用的资源。 2）master给计算框架1发送一个在slave1上可用的资源描述。 3）计算框架的调度器回复给master运行在slave上两个任务的相关信息，任务1需使用2个cpu，内存1G，任务2需使用1个cpu，2G内存。 4）最后，master发送任务给slave，分配适当的给计算框架执行器，继续发起两个任务（图上虚线处），因为仍有1个cpu和1G内存未分配，allocation模块现在或许提供剩下的资源给计算框架2。 除此之外，当任务完成，新的资源成为空闲时，这个资源提供程序将会重复。 熟知zookeeper概念解释ZooKeeper是用来给集群服务维护配置信息，域名服务，提供分布式同步和提供组服务。所有这些类型的服务都使用某种形式的分布式应用程序。是一个分布式的，开放源码的协调服务，是的Chubby一个的实现，是Hadoop和Hbase的重要组件。 角色介绍 领导者（leader）：领导者负责投票发起和决议，更新系统状态 跟随者（follwoer）：follower用于接收客户请求并向客户端返回结果，在选主过程中参与投票 观察者：ObServer可以接受客户端连接，将写请求转发给leader节点，但ObServer不参加投票过程，只同步leader的状态，ObServer的目的是为了拓展系统，提高读取速度。 客户端：请求发起方 熟知marathon架构介绍marathon是一个mesos框架，能够支持运行长服务，比如web应用等。是集群的分布式Init.d，能够原样运行任何Linux二进制发布版本，如Tomcat Play等等，可以集群的多进程管理。也是一种私有的Pass，实现服务的发现，为部署提供提供REST API服务，有授权和SSL、配置约束，通过HAProxy实现服务发现和负载平衡。 我们可以如同一台Linux主机一样管理数千台服务器，它们的对应原理如下图，使用Marathon类似Linux主机内的init Systemd等外壳管理，而Mesos则不只包含一个Linux核，可以调度数千台服务器的Linux核，实际是一个数据中心的内核 熟知chronosChronos本质上是cron-on-mesos,这是一个用来运行基于容器定时任务的Mesos框架。 准备开始系统环境修改hosts文件 软件安装说明：因该虚拟机能连接外部网络，所有软件的安装均采用yum安装方式 在两台机器上安装mesos源 在192.168.10.33【master】上安装Mesos，Marathon，Chronos，ZooKeeper 配置 zookeeper 启动服务 在192.168.10.22【slave】上安装Mesos，Marathon，Chronos，ZooKeeper DOCKER相关设定 配置 zookeeper 启动服务 说明：如果服务器上之前装过jdk，升级到最新版本（经测试必须要&gt;=1.8） 软件验证  登录Mesos http://192.168.10.33:5050  登录Marathon http://192.168.10.33:8080  登录Chronos http://192.168.10.33:4400 说明：chronos是一个任务调度管理器，本次测试中并没有使用 使用mesos管理docker 登录mesos的管理平台，在agent选项卡中发现已经有两台主机进行关联 但是在首页面，发现并没有任务在执行 下面通过marathon 进行任务的创建 说明：marathon可以通过管理控制台和REST API两种方式创建APP目前使用的是管理控制台的方式。 登录管理控制台，点击创建application，如下图 启动之后可以观察到如下的情况 在两台主机上分别能够看到两个进程在运行 marathon有自己的REST API，我们通过API的方式来创建一个任务。 首先创建如下的配置文件hello.json 使用curl的方式调用测试: Docker容器liberty镜像 直接在容器中安装配置liberty，最后commit成镜像  通过dockerfile生成镜像 说明：本次为测试，直接使用在容器中安装配置liberty的方式，生产上需要使用dockerfile生成景象。通过docker images命令查看liberty的镜像大小，该镜像大小为634M 该镜像中生成了一个该要文件，liberty自带的应用 192.168.10.33和192.168.10.22都需要有liberty的镜像文件 Marathon管理docker容器在marathon的管理控制台上创建application应用 内容如下： 启动了两个实例： 访问URL如下： 注意：目前宿主机上映射的端口都是随即来管理了，那么怎么能让负载均衡来发现这么多的服务呢？ 服务发现实现服务发现的方法是在集群的每个主机上运行一个TCP/HTTP的代理，透明地连接本地主机上的静态服务端口转发到个人的动态分配主机/端口组合马拉松应用程序实例(运行便任务)。客户端很容易连接到服务端口，并且不需要知道服务发现实现的具体细节。如果所有的应用通过marathon加装，那这个方式就足够了。实现服务发现的插件有好多，比如：mesos-dns/bamboo/marathon-lb等，本文用到的是marathon-lb，下面来介绍安装配置使用方法： Marathon-lb是一个Docker化的应用，包含HAProxy，使用marathon rest api重新生成HAProxy配置。它支持高级功能像SSL卸载,粘性的连接,和基于VHost负载平衡,允许为你的marathon应用指定虚拟host。 当使用marathon-lb，注意requirePosts=true不是不须设置，其他的说明在ports documentation中查阅。参考：https://github.com/mesosphere/marathon-lb 安装marathon-lb#下载marathon-lb镜像1docker pull mesosphere/marathon-lb 可以通过docker run运行，也可以通过marathon部署到mesos集群里 通过marathon来运行marathon-lb marathon-lb使用方法发布Application， 先创建app的json配置信息 说明：一定要加上HAPROXY_GROUP标签，对于web服务，可以加上VHOST标签，让marathon-lb设置WEB虚拟主机；对于web服务，servicePort设置为0即可，marathon-lb会自动把web服务集群发布到80、443上； Liberty对应的json文件如下： Marathon管理控制台显示为： 生成的三个DOCKER容器都可以访问 访问： http://192.168.10.22:31229 http://192.168.10.22:31838 http://192.168.10.33:31113 在装有marathon-lb（192.168.10.33）的主机上设置DNS 在192.168.10.33主机上访问：http://test-mesos.liberty.com 说明：用浏览器通过http和https访问虚拟主机，发现服务已经启动，实际上是marathon-lb内置的haproxy对liberty的三个实例配置的web服务集群： 对于marathon-lb，可以同时部署多台，然后用DNS轮询或者keepalived虚拟IP实现高可用。 注意：经测试，如果把192.168.10.33主机上的liberty容器停止，访问机http://test-mesos.liberty.com依然可以成功，因为marath-lb会发现192.168.10.22主机上有可用服务。通过marath控制台，可以动态增加多个liberty服务 查看mesos 的控制台可以看到当前任务列表如下： 说明：本次测试刚开始的时候使用的是传统的was8.5.5，发现使用marathon来管理的时候一直有问题，该问题后期解决。 Liberty就是为微服务产生的，小巧灵活部署方便。 关于mesos 还有很多知识点要学，比如Mesos DRF算法、Master/Slave资源调度等。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>mesos</tag>
        <tag>docker</tag>
        <tag>matathon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[was85下JDK版本之间的切换]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2Fwas85%E4%B8%8BJDK%E7%89%88%E6%9C%AC%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%87%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[注意：WAS85默认是不支持JDK1.8版本的，需要手动升级WAS85到WAS8.5.5.11之后，才可以支持JDK1.8 升级过之后，安装JDK1.8 JDK版本下载连接如下：1http://www-01.ibm.com/support/docview.wss?uid=swg24043149 描述本文以JDK1.8为例子下载过的软件包名称为：8.0.3.20-WS-IBMWASJAVA-Linux.zip 注意：JDK是分平台的，请根据自己的需求下载 安装说明：在执行该命令之前，确保InstallationManager已经安装！ 切换到/InstallationManager/eclipse/tools目录下，执行如下命令： windows: 123456imcl.exe install com.ibm.websphere.ND.v85_offering_version,optional_feature_ID -repositories source_repository -installationDirectory installation_directory -sharedResourcesDirectory shared_directory -acceptLicense linux:12345./imcl install com.ibm.websphere.ND.v85_offering_version -repositories source_repository -installationDirectory installation_directory -sharedResourcesDirectory shared_directory -acceptLicense 说明：offering_version：可以有选择地附加下划线的版本ID，是一个提供特定安装的版本号（例如8.5.0.20110503_0200）获取该版本号的方法为：./imcl listAvailablePackages -repositories /home/was/software/JDK/repository.config！如果没有指定offering_version，默认为本次发行的最新版本。 source_repository：该文件为安装WAS的配置文件，详细请查看repository.config！ installation_directory：WAS的安装目录（例如/home/was/IBM/WebSphere/Appserver） shared_directory:WAS的共享目录（例如/home/was/IBM/ IMShared） acceptLicense:接受License 安装JDK：12345./imcl install com.ibm.websphere.IBMJAVA.v80 -repositories /home/was/software/JDK/repository.config -installationDirectory /home/was/IBM/WebSphere/AppServer -sharedResourcesDirectory /home/was/IBM/IMShared -acceptLicense 配置管理JDK* 说明：可以在JDK各个版本之间进行切换 切换home/was/IBM/WebSphere/AppServer/bin 例子：1234./managesdk.sh -enableProfileAll -sdkname 1.8_64|1.8_32|1.7_64|1.7_32|1.6_64|1.6_32 -enableServer]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>was</tag>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[处理HTTP头暴露WAS版本信息]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E5%A4%84%E7%90%86HTTP%E5%A4%B4%E6%9A%B4%E9%9C%B2WAS%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF%20%2F</url>
    <content type="text"><![CDATA[描述&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在访问Web服务器时，返回的HTTP响应消息头(Response Header)中通常包含Server版本以及其他一些信息。这些头信息可用于网站统计分析，比如某些爬虫类搜索引擎，当然也包括攻击者进行社会工程信息收集。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事实上，有些头信息完全可以去掉或隐藏，而不影响系统正常访问，同时也节省了少许传输字节。隐藏服务器在HTTP响应消息头中的不必要信息，是为了防止服务器的版本信息泄露，可做为提高站点安全的一项初步防护措施。 脚本修改 说明：修改之前请先备份server.xml文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#HTTP_1(cells/cellName/nodes/nodeName/servers/serverName|server.xml#HTTPInboundChannel_1330505241923) #HTTP_2(cells/cellName/nodes/nodeName/servers/serverName|server.xml#HTTPInboundChannel_1330505241924) #HTTP_3(cells/cellName/nodes/nodeName/servers/serverName|server.xml#HTTPInboundChannel_1330505241925) #HTTP_4(cells/cellName/nodes/nodeName/servers/serverName|server.xml#HTTPInboundChannel_1330505241926) #HTTP_1 -&gt; WCInboundAdmin WAS管理控制台 #HTTP_2 -&gt; WCInboundDefault HTTP传输 #HTTP_3 -&gt; WCInboundAdminSecure WAS安全管理控制台 #HTTP_4 -&gt; WCInboundDefaultSecure HTTPS传输 #参数说明：RemoveServerHeader #参数使用：使用此属性来指定在发送响应消息前是否除去现有的服务器头。 # 如果此属性设置为true ，那么将忽略对ServerHeaderValue 属性指定的值，缺省值 false #参数说明：ServerHeaderValue #参数使用：使用此属性来指定服务器头，当未提供服务器头时，会将此属性指定的服务器头添加到外发响应消息中。 #如果 RemoveServerHeader 属性设置为 true，那么将忽略此属性。缺省值 WAS/x.x #说明：RemoveServerHeader 和 ServerHeaderValue二选其一，本例中用到的是RemoveServerHeader HttpList = AdminConfig.getid('/HTTPInboundChannel:/').split('\n') #根据实际情况来修改 HttpName = ("HTTP_1","HTTP_2","HTTP_3","HTTP_4") for http in HttpList: HttpNameArray = http.split('(') Name = HttpNameArray[0] if Name in HttpName: Value = HttpNameArray[1].replace(')','') AdminConfig.create('Property','('+Value+')','[[name "RemoveServerHeader"][value "true"][required "false"]]') print Name + ' is success!' AdminConfig.save()]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>was</tag>
        <tag>jdk</tag>
        <tag>python</tag>
        <tag>安全漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何修改WAS控制台密码]]></title>
    <url>%2F2018%2F12%2F30%2Fblog%2F%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9WAS%E6%8E%A7%E5%88%B6%E5%8F%B0%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[描述好多同学在安装完WAS之后，经常会发现控制台密码（wsadmin密码）忘记的情况。导致工作难以进展下去，下面这篇文章详细讲明了怎么找回控制台密码如果WAS启用了安全性，并且密码忘记了，想要找回密码的步骤如下： 禁用安全性进入server的bin目录，如下图： 执行命令：./wsadmin.sh -conntype NONE 重启该server，进入控制台，发现不用输入用户名和密码可以直接登录进去 说明：勾选中“启用管理安全性”点击应用，然后点击“配置”如下图：输入主要管理用户名点击“确定”按钮，如下图：点击“确定”之后，重启该SERVER,登录控制台如下图：输入刚才修改的密码即可！说明：如果你有疑问请给我联系]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>was</tag>
        <tag>jdk</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s常用命令总结]]></title>
    <url>%2F2018%2F12%2F17%2Fblog%2Fk8s%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[描述k8s常用命令： 123kube-apiserver.yaml - --insecure-bind-address=0.0.0.0 - --insecure-port=8080 安装 bash 自动提示12345678kubeadm completion bash &gt;/etc/profile.d/kubeadm.shkubectl completion bash &gt;/etc/profile.d/kubectl.shsource /etc/profile或者source &lt;(kubectl completion bash)echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc 显示该命名空间下所有的资源1kubectl get all --namespace=kube-system 查看集群状态信息1kubectl cluster-info 查看命令行和服务端版本1kubectl version 显示支持的API版本集合1kubectl api-versions 显示kubectl的配置1kubectl config view 显示集群节点1kubectl get node 创建资源1kubectl create -f *.yaml 使用run创建deployment1kubectl run tomcat --image=tomcat:6 --replicas=6 --port=8080 创建映射1234#为deployment的tomcat创建service，并通过Service的9999端口转发至容器的8080端口上。kubectl expose deployment tomcat --port=9999 --target-port=8080 --external-ip=192.168.10.13kubectl expose deployment/tomcat --type="NodePort" --port 8090kubectl expose deployment prometheus --port=9090 --target-port=9090 --external-ip=192.168.10.11 通过set更改镜像里面的属性1kubectl set image deployment/tomcat tomcat=tomcat:7 进入YAML文件进行编辑1kubectl edit deployment/nginx-deployment 查看某种类型的 资源1kubectl get &lt;type&gt; &lt;name&gt; 检查资源出现的问题1kubectl describe &lt;type&gt; &lt;name&gt; 检查 POD的输出1kubectl logs 进入到POD1kubectl exec 实现水平扩展和收缩1kubectl scale rc php-controller --replicas=1 部署状态变更和检查1kubectl rollout status 查看deployment的状态1kubectl rollout status deployment/nginx-deployment 查看部署的历史1kubectl rollout history 回滚部署到最近的某个版本1kubectl rollout undo 显示暴露出来的端口号1kubectl get ep 显示命名空间1kubectl get namespace 创建命名空间1kubectl create namespace new-namespace 删除命名空间123#删除一个namespace会自动删除所有属于该namespace的资源。#default和kube-system命名空间不可删除。kubectl delete namespaces new-namespace 标记不可调度到该节点1kubectl cordon/uncordon $NODENAME 动态扩容1kubectl autoscale deployment tomcat --min=3 --max=5 --cpu-percent=20 Kubectl 上下文和配置12设置 kubectl 命令交互的 kubernetes 集群并修改配置信息。参阅 使用 kubeconfig 文件进行跨集群验证 获取关于配置文件的详细信息。$ kubectl config view # 显示合并后的 kubeconfig 配置 同时使用多个 kubeconfig 文件并查看合并后的配置1$ KUBECONFIG=~/.kube/config:~/.kube/kubconfig2 kubectl config view 获取 e2e 用户的密码123$ kubectl config view -o jsonpath='&#123;.users[?(@.name == "e2e")].user.password&#125;'$ kubectl config current-context # 显示当前的上下文$ kubectl config use-context my-cluster-name # 设置默认上下文为 my-cluster-name 向 kubeconf 中增加支持基本认证的新集群1$ kubectl config set-credentials kubeuser/foo.kubernetes.com --username=kubeuser --password=kubepassword 使用指定的用户名和 namespace 设置上下文123456789$ kubectl config set-context gce --user=cluster-admin --namespace=foo \ &amp;&amp; kubectl config use-context gce显示和查找资源#Get commands with basic output$ kubectl get services # 列出所有 namespace 中的所有 service$ kubectl get pods --all-namespaces # 列出所有 namespace 中的所有 pod$ kubectl get pods -o wide # 列出所有 pod 并显示详细信息$ kubectl get deployment my-dep # 列出指定 deployment$ kubectl get pods --include-uninitialized # 列出该 namespace 中的所有 pod 包括未初始化的 使用详细输出来描述命令123$ kubectl describe nodes my-node$ kubectl describe pods my-pod$ kubectl get services --sort-by=.metadata.name # List Services Sorted by Name 根据重启次数排序列出 pod1$ kubectl get pods --sort-by='.status.containerStatuses[0].restartCount' 获取所有具有 app=cassandra 的 pod 中的 version 标签12$ kubectl get pods --selector=app=cassandra rc -o \ jsonpath='&#123;.items[*].metadata.labels.version&#125;' 获取所有节点的 ExternalIP1$ kubectl get nodes -o jsonpath='&#123;.items[*].status.addresses[?(@.type=="ExternalIP")].address&#125;' 列出属于某个 PC 的 Pod 的名字123#“jq”命令用于转换复杂的 jsonpath，参考 https://stedolan.github.io/jq/$ sel=$&#123;$(kubectl get rc my-rc --output=json | jq -j '.spec.selector | to_entries | .[] | "\(.key)=\(.value),"')%?&#125;$ echo $(kubectl get pods --selector=$sel --output=jsonpath=&#123;.items..metadata.name&#125;) 查看哪些节点已就绪12$ JSONPATH='&#123;range .items[*]&#125;&#123;@.metadata.name&#125;:&#123;range @.status.conditions[*]&#125;&#123;@.type&#125;=&#123;@.status&#125;;&#123;end&#125;&#123;end&#125;' \ &amp;&amp; kubectl get nodes -o jsonpath="$JSONPATH" | grep "Ready=True" 列出当前 Pod 中使用的 Secret1$ kubectl get pods -o json | jq '.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name' | grep -v null | sort | uniq 更新资源12345$ kubectl rolling-update frontend-v1 -f frontend-v2.json # 滚动更新 pod frontend-v1$ kubectl rolling-update frontend-v1 frontend-v2 --image=image:v2 # 更新资源名称并更新镜像$ kubectl rolling-update frontend --image=image:v2 # 更新 frontend pod 中的镜像$ kubectl rolling-update frontend-v1 frontend-v2 --rollback # 退出已存在的进行中的滚动更新$ cat pod.json | kubectl replace -f - # 基于 stdin 输入的 JSON 替换 pod 强制替换，删除后重新创建资源。会导致服务中断。1$ kubectl replace --force -f ./pod.json 为 nginx RC 创建服务，启用本地 80 端口连接到容器上的 8000 端口1$ kubectl expose rc nginx --port=80 --target-port=8000 更新单容器 pod 的镜像版本（tag）到 v412345$ kubectl get pod mypod -o yaml | sed 's/\(image: myimage\):.*$/\1:v4/' | kubectl replace -f -$ kubectl label pods my-pod new-label=awesome # 添加标签$ kubectl annotate pods my-pod icon-url=http://goo.gl/XXBTWq # 添加注解$ kubectl autoscale deployment foo --min=2 --max=10 # 自动扩展 deployment “foo” 修补资源12使用策略合并补丁并修补资源。$ kubectl patch node k8s-node-1 -p '&#123;"spec":&#123;"unschedulable":true&#125;&#125;' # 部分更新节点 更新容器镜像； spec.containers[*].name 是必须的，因为这是合并的关键字1$ kubectl patch pod valid-pod -p '&#123;"spec":&#123;"containers":[&#123;"name":"kubernetes-serve-hostname","image":"new image"&#125;]&#125;&#125;' 使用具有位置数组的 json 补丁更新容器镜像1$ kubectl patch pod valid-pod --type='json' -p='[&#123;"op": "replace", "path": "/spec/containers/0/image", "value":"new image"&#125;]' 使用具有位置数组的 json 补丁禁用 deployment 的 livenessProbe1$ kubectl patch deployment valid-deployment --type json -p='[&#123;"op": "remove", "path": "/spec/template/spec/containers/0/livenessProbe"&#125;]' 编辑资源1234在编辑器中编辑任何 API 资源。$ kubectl edit svc/docker-registry # 编辑名为 docker-registry 的 service$ KUBE_EDITOR="nano" kubectl edit svc/docker-registry # 使用其它编辑器 Scale 资源1234$ kubectl scale --replicas=3 rs/foo # Scale a replicaset named 'foo' to 3$ kubectl scale --replicas=3 -f foo.yaml # Scale a resource specified in "foo.yaml" to 3$ kubectl scale --current-replicas=2 --replicas=3 deployment/mysql # If the deployment named mysql's current size is 2, scale mysql to 3$ kubectl scale --replicas=5 rc/foo rc/bar rc/baz # Scale multiple replication controllers 删除资源12345$ kubectl delete -f ./pod.json # 删除 pod.json 文件中定义的类型和名称的 pod$ kubectl delete pod,service baz foo # 删除名为“baz”的 pod 和名为“foo”的 service$ kubectl delete pods,services -l name=myLabel # 删除具有 name=myLabel 标签的 pod 和 serivce$ kubectl delete pods,services -l name=myLabel --include-uninitialized # 删除具有 name=myLabel 标签的 pod 和 service，包括尚未初始化的$ kubectl -n my-ns delete po,svc --all # 删除 my-ns namespace 下的所有 pod 和 serivce，包括尚未初始化的 与运行中的 Pod 交互12345678910$ kubectl logs my-pod # dump 输出 pod 的日志（stdout）$ kubectl logs my-pod -c my-container # dump 输出 pod 中容器的日志（stdout，pod 中有多个容器的情况下使用）$ kubectl logs -f my-pod # 流式输出 pod 的日志（stdout）$ kubectl logs -f my-pod -c my-container # 流式输出 pod 中容器的日志（stdout，pod 中有多个容器的情况下使用）$ kubectl run -i --tty busybox --image=busybox -- sh # 交互式 shell 的方式运行 pod$ kubectl attach my-pod -i # 连接到运行中的容器$ kubectl port-forward my-pod 5000:6000 # 转发 pod 中的 6000 端口到本地的 5000 端口$ kubectl exec my-pod -- ls / # 在已存在的容器中执行命令（只有一个容器的情况下）$ kubectl exec my-pod -c my-container -- ls / # 在已存在的容器中执行命令（pod 中有多个容器的情况下）$ kubectl top pod POD_NAME --containers # 显示指定 pod 和容器的指标度量 与节点和集群交互1234567$ kubectl cordon my-node # 标记 my-node 不可调度$ kubectl drain my-node # 清空 my-node 以待维护$ kubectl uncordon my-node # 标记 my-node 可调度$ kubectl top node my-node # 显示 my-node 的指标度量$ kubectl cluster-info # 显示 master 和服务的地址$ kubectl cluster-info dump # 将当前集群状态输出到 stdout $ kubectl cluster-info dump --output-directory=/path/to/cluster-state # 将当前集群状态输出到 /path/to/cluster-state 如果该键和影响的污点（taint）已存在，则使用指定的值替换1$ kubectl taint nodes foo dedicated=special-user:NoSchedule]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s中pv&pvc使用]]></title>
    <url>%2F2018%2F11%2F17%2Fblog%2Fk8s%E4%B8%ADpv%26pvc%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[描述PersistentVolume（pv）和PersistentVolumeClaim（pvc）是k8s提供的两种API资源，用于抽象存储细节。管理员关注于如何通过pv提供存储功能而无需关注用户如何使用，同样的用户只需要挂载pvc到容器中而不需要关注存储卷采用何种技术实现。 pvc和pv的关系与pod和node关系类似，前者消耗后者的资源。pvc可以向pv申请指定大小的存储资源并设置访问模式。 生命周期pv和pvc遵循以下生命周期： 供应准备。管理员在集群中创建多个pv供用户使用。 绑定。用户创建pvc并指定需要的资源和访问模式。在找到可用pv之前，pvc会保持未绑定状态。 使用。用户可在pod中像volume一样使用pvc。 释放。用户删除pvc来回收存储资源，pv将变成“released”状态。由于还保留着之前的数据，这些数据需要根据不同的策略来处理，否则这些存储资源无法被其他pvc使用。 回收。pv可以设置三种回收策略：保留（Retain），回收（Recycle）和删除（Delete）。 * 保留策略允许人工处理保留的数据。 删除策略将删除pv和外部关联的存储资源，需要插件支持。 回收策略将执行清除操作，之后可以被新的pvc使用，需要插件支持。 pv类型pv支持以下类型： GCEPersistentDisk AWSElasticBlockStore NFS iSCSI RBD (Ceph Block Device) Glusterfs HostPath (single node testing only – local storage is not supported in any way and WILL NOT WORK in a multi-node cluster) pv属性pv拥有以下属性： 容量。目前仅支持存储大小，未来可能支持IOPS和吞吐量等。 访问模式。ReadWriteOnce：单个节点读写。ReadOnlyMany：多节点只读。ReadWriteMany：多节点读写。挂载时只能使用一种模式。 回收策略。目前NFS和HostPath支持回收。 AWS、EBS、GCE、PD和Cinder支持删除。 阶段。分为Available（未绑定pvc）、Bound（已绑定）、Released（pvc已删除但资源未回收）、Failed（自动回收失败） pvc属性 访问模式。与pv的语义相同。在请求资源时使用特定模式。 资源。申请的存储资源数量 nfs示例nfs服务器搭建本文章不做赘述，请参考我的其他文章 pv和pvc创建与使用1、首先创建pv和pvccat task-pv-nfs.yaml123456789101112131415kind: PersistentVolumeapiVersion: v1metadata: name: task-pv-nfs-volume labels: type: localspec: storageClassName: manual capacity: storage: 10Gi accessModes: - ReadWriteOnce nfs: path: /nfs server: 192.168.21.194 cat task-pvc-nfs.yaml1234567891011kind: PersistentVolumeClaimapiVersion: v1metadata: name: task-pv-nfs-claimspec: storageClassName: manual accessModes: - ReadWriteOnce resources: requests: storage: 3Gi cat tomcat-nfs.yaml12345678910111213141516171819kind: PodapiVersion: v1metadata: name: task-pv-nfs-podspec: volumes: - name: task-pv-nfs-storage persistentVolumeClaim: claimName: task-pv-nfs-claim containers: - name: task-pv-nfs-container image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 80 name: "http-server" volumeMounts: - mountPath: "/usr/share/test" name: task-pv-nfs-storage 创建123456root@zyzx-master:[/root]kubectl create -f task-pv-nfs.yaml persistentvolume "task-pv-nfs-volume" createdroot@zyzx-master:[/root]kubectl create -f task-pvc-nfs.yaml persistentvolumeclaim "task-pv-nfs-claim" createdroot@zyzx-master:[/root]kubectl create -f tomcat-nfs.yaml pod "task-pv-nfs-pod" created 查看结果。进入到pod中查看挂载的目录，发现文件与nfs服务器中的文件一致12345678pod中查看root@task-pv-nfs-pod:/# cd /usr/share/test/root@task-pv-nfs-pod:/usr/share/test# ls1122 a.txt b.txtnfs服务器查看root@LY1F-R020510-VM08:[/nfs]ls1122 a.txt b.txt 参考：http://blog.csdn.net/xts_huangxin/article/details/51494472]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[离线安装docker]]></title>
    <url>%2F2018%2F11%2F17%2Fblog%2F%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85docker%2F</url>
    <content type="text"><![CDATA[描述在docker的使用过程中有时候会遇到一些私有化部署的问题，就是在一些无法上网的机器上面安装使用dokcer，这就引出了docker的离线安装的问题，docker要如何进行离线安装呢？让我们接下来一步步阐述! 环境：centos 7.2 内核版本3.10.0-229.el7.x86_64 docker 1.13.1版本 基本思路：在可以连接外网的机器（未安装过docker，同时跟局域网要安装docker的机器系统版本一致）通过yum命令将rpm以及相关的依赖下载完成将下载完成的rpm包，拷贝到局域网机器上面 构建本地yum源 使用yum install docker安装，安装完成 配置YUM源安装yum-utils，它提供了yum-config-manager实用程序：1yum install -y yum-utils 使用以下命令设置稳定的存储库1yum-config-manager --add-repo https://docs.docker.com/v1.13/engine/installation/linux/repo_files/centos/docker.repo 把下好的docker.repo文件放到/etc/yum.repos.d目录。因为安装docker需要依赖container-selinux，所以配置centos.repo的yum源1234567891011121314151617181920[centos7.2_base]name=CentOS7.2 - Basebaseurl=http://mirrors.ustc.edu.cn/centos/7/os/x86_64/gpgcheck=0gpgkey=http://mirrors.ustc.edu.cn/centos/7/os/x86_64/RPM-GPG-KEY-CentOS-7[centos7.2_extras]name=CentOS7.2 - Extrasbaseurl=http://mirrors.ustc.edu.cn/centos/7/extras/x86_64/gpgcheck=0gpgkey=http://mirrors.ustc.edu.cn/centos/7/os/x86_64/RPM-GPG-KEY-CentOS-7[centos7.2_updates]name=CentOS7.2 - Updatesbaseurl=http://mirrors.ustc.edu.cn/centos/7/updates/x86_64/gpgcheck=0gpgkey=http://mirrors.ustc.edu.cn/centos/7/os/x86_64/RPM-GPG-KEY-CentOS-7[epel]name=CentOS7.2 - epelbaseurl=http://mirrors.ustc.edu.cn/epel/7/x86_64/gpgcheck=0gpgkey=http://mirrors.ustc.edu.cn/centos/7/os/x86_64/RPM-GPG-KEY-CentOS-7 通过yum makecache使其生效。 配置好yum源之后，可以通过yum的list命令，获取可以安装的docker版本：1yum list docker --showduplicates |sort -r docker离线安装包的下载要下载docker离线安装包，需要通过yum的离线下载命令进行，一般我们使用yum install下载安装包会进行安装，安装完成后删除下载的安装包，yum提供了一种只下载安装包，但是不进行安装的方法：1yum install docker-engine-1.13.1-1.e17.centos --downloadonly --downloaddir=/opt/docker-test 通过这个命令，我们可以将docker相关的rpm包下载到/opt/docker目录，如图： copy rpm包到需要安装docker的机器上面将docker的rpm包拷贝到需要安装docker的局域网集群上面，例如：/opt/docker-test 构建本地yum源1、构建本地源之前，需要在本地安装createrepo，用于构建本地源，方法，同docker包下载，通过yum install –downloadonly下载好，copy到该机器上面，通过rpm -ivh进行安装，createrepo关联包很少，不详细描述。 2、删除/etc/yum.repo.d目录下文件，创建新的*.repo文件，如：docker.repo，进行配置，如图： 3、createrepo -d /opt/docker设置本地源，执行成功后本地源就设置完成后会生成repodata目录 4、输入yum repolist看是否能看到自己构建的本地源 5、清除缓存，yum clean all 6、创建缓存，yum makecache 7、看本地源是否配置成功，通过yum list看是否输出了新的rpm包，如果能查询到，证明配置成功 安装docker121.13 yum install docker-engine-1.13.1-1.e17.centos17.06 yum install docker-ce-17.06.0.ce-1.el7.centos]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes iptables 路由表之间规则]]></title>
    <url>%2F2018%2F11%2F17%2Fblog%2Fkubernetes%20iptables%20%E8%B7%AF%E7%94%B1%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[描述通过iptables表和路由表确定SVC到POD之间的转发 获取主机IPTABLES列表1iptables -L 路由链路表如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197Chain PREROUTING (policy ACCEPT)target prot opt source destination cali-PREROUTING all -- 0.0.0.0/0 0.0.0.0/0 /* cali:6gwbT8clXdHdC1b1 */KUBE-SERVICES all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes service portals */Chain INPUT (policy ACCEPT)target prot opt source destination Chain OUTPUT (policy ACCEPT)target prot opt source destination cali-OUTPUT all -- 0.0.0.0/0 0.0.0.0/0 /* cali:tVnHkvAo15HuiPy0 */KUBE-SERVICES all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes service portals */Chain POSTROUTING (policy ACCEPT)target prot opt source destination cali-POSTROUTING all -- 0.0.0.0/0 0.0.0.0/0 /* cali:O3lYWMrLQYEMJtB5 */KUBE-POSTROUTING all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes postrouting rules */Chain KUBE-MARK-DROP (0 references)target prot opt source destination MARK all -- 0.0.0.0/0 0.0.0.0/0 MARK or 0x8000Chain KUBE-MARK-MASQ (55 references)target prot opt source destination MARK all -- 0.0.0.0/0 0.0.0.0/0 MARK or 0x4000Chain KUBE-NODEPORTS (1 references)target prot opt source destination KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:stream */ tcp dpt:30020KUBE-SVC-3SREC2SJYLTSKQEK tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:stream */ tcp dpt:30020KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/api-redis-service: */ tcp dpt:30379KUBE-SVC-BJKULRBFEUDA5TH7 tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/api-redis-service: */ tcp dpt:30379KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:http */ tcp dpt:30017KUBE-SVC-WEHLQ23XZWSA5ZX3 tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:http */ tcp dpt:30017KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:api */ tcp dpt:30018KUBE-SVC-CK6HVV5A27TDFNIA tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:api */ tcp dpt:30018KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/webpage-service: */ tcp dpt:30088KUBE-SVC-DXQJSVAVMM4JBM5D tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/webpage-service: */ tcp dpt:30088KUBE-MARK-MASQ udp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:subscription */ udp dpt:30095KUBE-SVC-SUW36EE5KMI6EKBX udp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:subscription */ udp dpt:30095KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/api-mysql-service: */ tcp dpt:30306KUBE-SVC-6PDJRRG5T6RW7KTG tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/api-mysql-service: */ tcp dpt:30306KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/elasticsearch-logging:transport */ tcp dpt:30093KUBE-SVC-JX2STUD6DQ2DDKET tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/elasticsearch-logging:transport */ tcp dpt:30093KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/elasticsearch-logging:es */ tcp dpt:30092KUBE-SVC-FZXLVFFHDTMBYMVK tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/elasticsearch-logging:es */ tcp dpt:30092KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/oam-api-service: */ tcp dpt:30097KUBE-SVC-TZVMHZPBZR2QOQ5K tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/oam-api-service: */ tcp dpt:30097KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/webhook-service: */ tcp dpt:30081KUBE-SVC-PVHWH3ECAYGNZZVB tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/webhook-service: */ tcp dpt:30081KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/webapi-service: */ tcp dpt:30099KUBE-SVC-3VHIICAEU5HT52G5 tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/webapi-service: */ tcp dpt:30099KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/jenkins:jnlp */ tcp dpt:30079KUBE-SVC-QQKVHNOHOB2VHDA6 tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/jenkins:jnlp */ tcp dpt:30079KUBE-MARK-MASQ tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/jenkins:jenkins */ tcp dpt:30080KUBE-SVC-HTF37THYO2K4HCUV tcp -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/jenkins:jenkins */ tcp dpt:30080**Chain KUBE-SEP-SFHYVH4YEL7C4TIN (1 references)target prot opt source destination KUBE-MARK-MASQ all -- 10.168.191.72 0.0.0.0/0 /* cmos-im/tomcat-im:tomcat-im-tomcat-port0 */DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 /* cmos-im/tomcat-im:tomcat-im-tomcat-port0 */ tcp to:10.168.191.72:8080**Chain KUBE-SERVICES (2 references)target prot opt source destination **KUBE-SVC-HLA3OUSNXIHY3R4E tcp -- 0.0.0.0/0 172.25.35.178 /* cmos-im/tomcat-im:tomcat-im-tomcat-port0 cluster IP */ tcp dpt:8080**KUBE-SVC-NB5N7BCNHXFQTDNT tcp -- 0.0.0.0/0 172.25.54.78 /* ptz-test/servicecenter:servicecenter-servicecomb-service-center-port0 cluster IP */ tcp dpt:30100KUBE-NODEPORTS all -- 0.0.0.0/0 0.0.0.0/0 /* kubernetes service nodeports; NOTE: this must be the last rule in this chain */ ADDRTYPE match dst-type LOCALChain KUBE-SVC-223V4VAX3AJD3QLL (1 references)target prot opt source destination **Chain KUBE-SVC-HLA3OUSNXIHY3R4E (1 references)target prot opt source destination KUBE-SEP-SFHYVH4YEL7C4TIN all -- 0.0.0.0/0 0.0.0.0/0 /* cmos-im/tomcat-im:tomcat-im-tomcat-port0 */**Chain KUBE-SVC-LDKPAIDTGCFIDQWF (1 references)target prot opt source destination Chain KUBE-SVC-MOZI7ROY4YNEACSA (1 references)target prot opt source destination Chain KUBE-SVC-MRGIW6HFKEVKQ5GE (1 references)target prot opt source destination Chain KUBE-SVC-NB5N7BCNHXFQTDNT (1 references)target prot opt source destination KUBE-SEP-PHDRHRTRKM5JGBZS all -- 0.0.0.0/0 0.0.0.0/0 /* ptz-test/servicecenter:servicecenter-servicecomb-service-center-port0 */Chain KUBE-SVC-NDXWUY3I4IMLUHOL (1 references)target prot opt source destination Chain KUBE-SVC-NPX46M4PTMTKRN6Y (1 references)target prot opt source destination KUBE-SEP-OBFXS2N4GR3RQJZW all -- 0.0.0.0/0 0.0.0.0/0 /* default/kubernetes:https */ recent: CHECK seconds: 10800 reap name: KUBE-SEP-OBFXS2N4GR3RQJZW side: source mask: 255.255.255.255KUBE-SEP-AZRR5TRDO7H34W7T all -- 0.0.0.0/0 0.0.0.0/0 /* default/kubernetes:https */ recent: CHECK seconds: 10800 reap name: KUBE-SEP-AZRR5TRDO7H34W7T side: source mask: 255.255.255.255KUBE-SEP-OGU4X45RPIQWTRSB all -- 0.0.0.0/0 0.0.0.0/0 /* default/kubernetes:https */ recent: CHECK seconds: 10800 reap name: KUBE-SEP-OGU4X45RPIQWTRSB side: source mask: 255.255.255.255KUBE-SEP-OBFXS2N4GR3RQJZW all -- 0.0.0.0/0 0.0.0.0/0 /* default/kubernetes:https */ statistic mode random probability 0.33332999982KUBE-SEP-AZRR5TRDO7H34W7T all -- 0.0.0.0/0 0.0.0.0/0 /* default/kubernetes:https */ statistic mode random probability 0.50000000000KUBE-SEP-OGU4X45RPIQWTRSB all -- 0.0.0.0/0 0.0.0.0/0 /* default/kubernetes:https */Chain KUBE-SVC-O6PRR6Z2TBJEUFGX (1 references)target prot opt source destination KUBE-SEP-TKM5BGFFFS6KRC33 all -- 0.0.0.0/0 0.0.0.0/0 /* ptz-test/ngtestcore:ngtestcore-ngtestcore-port1 */Chain KUBE-SVC-PCGVXA553IBI25SS (1 references)target prot opt source destination Chain KUBE-SVC-PO2LH3WLDWFHHU3U (1 references)target prot opt source destination Chain KUBE-SVC-PVHWH3ECAYGNZZVB (2 references)target prot opt source destination Chain KUBE-SVC-Q4UX7HBK3OZETM4L (1 references)target prot opt source destination KUBE-SEP-M5YTWAGLSPSLVI3H all -- 0.0.0.0/0 0.0.0.0/0 /* ptz-test/jmservice-01:jmservice-01-nginx-port0 */Chain KUBE-SVC-QQKVHNOHOB2VHDA6 (2 references)target prot opt source destination KUBE-SEP-IMZOAVYIJ64PONRG all -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/jenkins:jnlp */Chain KUBE-SVC-SA4Z3XO55ZALDP4E (1 references)target prot opt source destination Chain KUBE-SVC-SUW36EE5KMI6EKBX (2 references)target prot opt source destination KUBE-SEP-JLFHYQBJGH3INNYL all -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:subscription */Chain KUBE-SVC-TCOU7JCQXEZGVUNU (1 references)target prot opt source destination KUBE-SEP-DH4LAWFRLFMFANAO all -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/kube-dns:dns */Chain KUBE-SVC-TUNBVOKVMGWY6OUA (1 references)target prot opt source destination Chain KUBE-SVC-TZVMHZPBZR2QOQ5K (2 references)target prot opt source destination KUBE-SEP-U7Y37X5KI3HPJA6E all -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/oam-api-service: */Chain KUBE-SVC-UDKPAEECGV3R2CLN (1 references)target prot opt source destination Chain KUBE-SVC-USAPVVEI5E5B4IQ3 (1 references)target prot opt source destination Chain KUBE-SVC-UTED6VL47QGQTOC6 (1 references)target prot opt source destination Chain KUBE-SVC-V2S2NDPZP4IIUYQM (1 references)target prot opt source destination Chain KUBE-SVC-V5CFI4XLIUUM7FAA (1 references)target prot opt source destination KUBE-SEP-TMTS76ZUKSRSPPOV all -- 0.0.0.0/0 0.0.0.0/0 /* cmos-dubbotest/nginxsvc2:nginxsvc2-nginx-port0 */Chain KUBE-SVC-WEHLQ23XZWSA5ZX3 (2 references)target prot opt source destination KUBE-SEP-44LCWHLV4ON7DLOQ all -- 0.0.0.0/0 0.0.0.0/0 /* kube-system/monitoring-influxdb:http */Chain KUBE-SVC-WP2ULBYRMCPAGJ72 (1 references)target prot opt source destination Chain KUBE-SVC-Z4CBN6LZUFWXCG7I (1 references)target prot opt source destination Chain KUBE-SVC-ZG4ZXSQTWEOGUCG4 (1 references)target prot opt source destination Chain KUBE-SVC-ZNHMELMC4UUZ3OAE (1 references)target prot opt source destination Chain cali-OUTPUT (1 references)target prot opt source destination cali-fip-dnat all -- 0.0.0.0/0 0.0.0.0/0 /* cali:GBTAv2p5CwevEyJm */Chain cali-POSTROUTING (1 references)target prot opt source destination cali-fip-snat all -- 0.0.0.0/0 0.0.0.0/0 /* cali:Z-c7XtVd2Bq7s_hA */cali-nat-outgoing all -- 0.0.0.0/0 0.0.0.0/0 /* cali:nYKhEzDlr11Jccal */MASQUERADE all -- 0.0.0.0/0 0.0.0.0/0 /* cali:JHlpT-eSqR1TvyYm */ ADDRTYPE match src-type !LOCAL limit-out ADDRTYPE match src-type LOCALChain cali-PREROUTING (1 references)target prot opt source destination cali-fip-dnat all -- 0.0.0.0/0 0.0.0.0/0 /* cali:r6XmIziWUJsdOK6Z */Chain cali-fip-dnat (2 references)target prot opt source destination Chain cali-fip-snat (1 references)target prot opt source destination Chain cali-nat-outgoing (1 references)target prot opt source destination MASQUERADE all -- 0.0.0.0/0 0.0.0.0/0 /* cali:Wd76s91357Uv7N3v */ match-set cali4-masq-ipam-pools src ! match-set cali4-all-ipam-pools dst 查看k8s集群中的svc1234567kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEtomcat-im ClusterIP 172.25.35.178 &lt;none&gt; 8080/TCP 2dkubectl get ep NAME ENDPOINTS AGEtomcat-im 10.168.191.72:8080 2d 在路由表中搜索 SVC IP 地址如下： KUBE-SVC-HLA3OUSNXIHY3R4E tcp – 0.0.0.0/0 172.25.35.178 / cmos-im/tomcat-im:tomcat-im-tomcat-port0 cluster IP / tcp dpt:8080 根据KUBE-SVC-HLA3OUSNXIHY3R4E查找ENDPOINT，如下： KUBE-SEP-SFHYVH4YEL7C4TIN all – 0.0.0.0/0 0.0.0.0/0 / cmos-im/tomcat-im:tomcat-im-tomcat-port0 / target prot opt source destinationKUBE-MARK-MASQ all – 10.168.191.72 0.0.0.0/0 / cmos-im/tomcat-im:tomcat-im-tomcat-port0DNAT tcp – 0.0.0.0/0 0.0.0.0/0 / cmos-im/tomcat-im:tomcat-im-tomcat-port0 */ tcp to:10.168.191.72:8080 根据SVC可以找到对应的POD信息 查看主机路由表1234567891011121314151617181920ip routedefault via 192.168.26.1 dev eth0 10.168.2.128/26 via 192.168.26.37 dev tunl0 proto bird onlink 10.168.46.192/26 via 192.168.26.108 dev tunl0 proto bird onlink 10.168.48.0/26 via 192.168.26.22 dev tunl0 proto bird onlink 10.168.72.64/26 via 192.168.26.38 dev tunl0 proto bird onlink 10.168.78.0/26 via 192.168.26.34 dev tunl0 proto bird onlink 10.168.86.128/26 via 192.168.26.28 dev tunl0 proto bird onlink 10.168.107.0/26 via 192.168.26.21 dev tunl0 proto bird onlink 10.168.130.128/26 via 192.168.26.107 dev tunl0 proto bird onlink 10.168.191.64/26 via 192.168.26.116 dev tunl0 proto bird onlink blackhole 10.168.198.128/26 proto bird 10.168.208.192/26 via 192.168.26.112 dev tunl0 proto bird onlink 10.168.248.128/26 via 192.168.26.39 dev tunl0 proto bird onlink 10.168.248.192/26 via 192.168.26.39 dev tunl0 proto bird onlink 169.254.0.0/16 dev eth0 scope link metric 1002 169.254.169.254 via 192.168.26.6 dev eth0 proto static 172.25.64.0/22 dev docker0 proto kernel scope link src 172.25.65.0 192.168.26.0/24 dev eth0 proto kernel scope link src 192.168.26.19 说明： pod:10.168.191.72 地址可以在路由表中看到 10.168.191.64/26 via 192.168.26.116 dev tunl0 proto bird onlink 可以确定该POD部署在 192.168.26.116 ，通过路由可以把信息转发到指定主机的指定POD中]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>kubernates</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes部署nginx镜像]]></title>
    <url>%2F2018%2F10%2F17%2Fblog%2Fkubernetes%E9%83%A8%E7%BD%B2nginx%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[描述说明：本次测试是在kubernetes中部署nginx服务，前提是需要节点上已经存在了nginx镜像。 准备开始系统环境修改 hosts文件主备机都要关闭防火墙12345[root@redhat-master ~]# systemctl disable firewalld.service[root@redhat-master ~]# systemctl status firewalld.servicefirewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled) Active: inactive (dead) 软件安装请参考之前写的一篇文章《kubernetes通过yum安装配置》1http://mooon.top/2017/04/28/blog/kubernetes%E9%80%9A%E8%BF%87yum%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/ 测试集群是否工作在 master 节点上运行1kubectl get nodes 若正常工作，可获取工作节点信息及运行状态为Ready，如下图 发布nginx服务创建pod : nginx-pod.yaml123456789101112apiVersion: v1kind: Podmetadata: name: nginx-pod labels: name: nginx-podspec: containers: - name: nginx image: nginx ports: - containerPort: 80 运行：1kubectl create -f nging-pod.yaml 查看pod的状态在节点上查看运行的DOCKER镜像 创建replicationController : nginx-rc.yaml123456789101112131415161718apiVersion: v1kind: ReplicationControllermetadata: name: nginx-rcspec: replicas: 1 selector: name: nginx-pod template: metadata: labels: name: nginx-pod spec: containers: - name: nginx-pod image: nginx ports: - containerPort: 80 运行：1kubectl create -f nginx-rc.yaml 查看ReplicationController状况 创建service : nginx-service.yaml1234567891011apiVersion: v1kind: Servicemetadata: name: nginx-servicespec: type: NodePort ports: - port: 80 nodePort: 30001 selector: name: nginx-pod 运行：1kubectl create -f nginx-service.yaml 说明：其中Kubernetes服务为Kube系统自带服务，无需理会 测试发布的nginx服务使用curl工具使用其他机器的浏览器访问node1机器的30001端口 备注查看service的详细描述 kubernetes入门之kube-proxy实现原理service是一组pod的服务抽象，相当于一组pod的LB，负责将请求分发给对应的pod。service会为这个LB提供一个IP，一般称为cluster IP。kube-proxy的作用主要是负责service的实现，具体来说，就是实现了内部从pod到service和外部的从node port向service的访问。 举个例子，现在有podA，podB，podC和serviceAB。serviceAB是podA，podB的服务抽象(service)。那么kube-proxy的作用就是可以将pod(不管是podA，podB或者podC)向serviceAB的请求，进行转发到service所代表的一个具体pod(podA或者podB)上。请求的分配方法一般分配是采用轮询方法进行分配。 另外，kubernetes还提供了一种在node节点上暴露一个端口，从而提供从外部访问service的方式。 比如我们使用这样的一个manifest来创建service1234567891011apiVersion: v1kind: Servicemetadata: name: nginx-servicespec: type: NodePort ports: - port: 80 nodePort: 30001 selector: name: nginx-pod 他的含义是在node上暴露出30001端口。当访问node上的30001端口时，其请求会转发到service对应的cluster IP的80端口，并进一步转发到pod的80端口。 kuer-proxy目前有userspace和iptables两种实现方式。 userspace是在用户空间，通过kuber-proxy实现LB的代理服务。这个是kube-proxy的最初的版本，较为稳定，但是效率也自然不太高。 另外一种方式是iptables的方式。是纯采用iptables来实现LB。是目前一般kube默认的方式。 userspace这里具体举个例子，以nginx-service为例，kube为其分配了一个clusterIP。分配clusterIP的作用还是如上文所说，是方便pod到service的数据访问使用describe可以查看到详细信息。可以看到暴露出来的NodePort端口30001。 nodePort的工作原理与clusterIP大致相同，是发送到node上指定端口的数据，通过iptables重定向到kube-proxy对应的端口上。然后由kube-proxy进一步把数据发送到其中的一个pod上。运行以下命令查看路由1iptables -S -t nat 12345678910111213141516171819202122[root@redhat-minion-1 ~]# iptables -S -t nat-P PREROUTING ACCEPT-P INPUT ACCEPT-P OUTPUT ACCEPT-P POSTROUTING ACCEPT-N DOCKER-N KUBE-NODEPORT-CONTAINER-N KUBE-NODEPORT-HOST-N KUBE-PORTALS-CONTAINER-N KUBE-PORTALS-HOST-A PREROUTING -m comment --comment "handle ClusterIPs; NOTE: this must be before the NodePort rules" -j KUBE-PORTALS-CONTAINER-A PREROUTING -m addrtype --dst-type LOCAL -m comment --comment "handle service NodePorts; NOTE: this must be the last rule in the chain" -j KUBE-NODEPORT-CONTAINER-A OUTPUT -m comment --comment "handle ClusterIPs; NOTE: this must be before the NodePort rules" -j KUBE-PORTALS-HOST-A OUTPUT -m addrtype --dst-type LOCAL -m comment --comment "handle service NodePorts; NOTE: this must be the last rule in the chain" -j KUBE-NODEPORT-HOST-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER-A POSTROUTING -s 172.17.41.0/24 ! -o docker0 -j MASQUERADE-A KUBE-NODEPORT-CONTAINER -p tcp -m comment --comment "default/nginx-service:" -m tcp --dport 30001 -j REDIRECT --to-ports 49441-A KUBE-NODEPORT-HOST -p tcp -m comment --comment "default/nginx-service:" -m tcp --dport 30001 -j DNAT --to-destination 192.168.10.88:49441-A KUBE-PORTALS-CONTAINER -d 10.254.0.1/32 -p tcp -m comment --comment "default/kubernetes:" -m tcp --dport 443 -j REDIRECT --to-ports 42991-A KUBE-PORTALS-CONTAINER -d 10.254.95.63/32 -p tcp -m comment --comment "default/nginx-service:" -m tcp --dport 80 -j REDIRECT --to-ports 49441-A KUBE-PORTALS-HOST -d 10.254.0.1/32 -p tcp -m comment --comment "default/kubernetes:" -m tcp --dport 443 -j DNAT --to-destination 192.168.10.88:42991-A KUBE-PORTALS-HOST -d 10.254.95.63/32 -p tcp -m comment --comment "default/nginx-service:" -m tcp --dport 80 -j DNAT --to-destination 192.168.10.88:49441 参考文章12http://www.cnblogs.com/xuxinkun/p/5799986.htmlhttp://blog.csdn.net/u013760355/article/details/68061976]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>docker</tag>
        <tag>kubernetes</tag>
        <tag>flanneld</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s中node的隔离与恢复]]></title>
    <url>%2F2018%2F10%2F17%2Fblog%2Fk8s%E4%B8%ADnode%E7%9A%84%E9%9A%94%E7%A6%BB%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[描述在硬件升级、硬件维护等情况下，我们需要将某些Node进行隔离，脱离Kubernetes集群的调度范围。Kubernetes提供了一种机制，既可以将Node纳入调度范围，也可以将Node脱离调度范围。 方案一创建配置文件unschedule_node.yaml，在spec部分指定unschedulable为true：12345678apiVersion: v1kind: Nodemetadata: name: kubernetes-minion1 labels: kubernetes.io/hostname: kubernetes-minion1spec: unschedulable: true 然后，通过kubectl replace命令完成对Node状态的修改：12$ kubectl replace -f unschedule_node.yaml nodes/kubernetes-minion1 查看Node的状态，可以观察到在Node的状态中增加了一项SchedulingDisabled：123$ kubectl get nodesNAME LABELS STATUSkubernetes-minion1 kubernetes.io/hostname=kubernetes-minion1 Ready, SchedulingDisabled 对于后续创建的Pod，系统将不会再向该Node进行调度。另一种方法是不使用配置文件，直接使用kubectl patch命令完成：1$ kubectl patch node kubernetes-minion1 -p '&#123;＂spec＂:&#123;＂unschedulable＂:true&#125;&#125;' 需要注意的是，将某个Node脱离调度范围时，在其上运行的Pod并不会自动停止，管理员需要手动停止在该Node上运行的Pod。 同样，如果需要将某个Node重新纳入集群调度范围，则将unschedulable设置为false，再次执行kubectl replace或kubectl patch命令就能恢复系统对该Node的调度。 方案二通用kubectl提供的API实现NODE的隔离与恢复隔离12kubectl cordon [nodename]kubectl get nodes 恢复12kubectl uncordon [nodename]kubectl get nodes 挤压——把需要挤压的节点上的PODS清除123kubectl drain [nodename] --ignore-daemonsetskubectl get nodeskubectl get pods -o wide 可以发现，该节点上的POD都清除了 节点清除之后，可以对节点进行删除操作]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s master高可用部署]]></title>
    <url>%2F2018%2F09%2F17%2Fblog%2Fk8s%20master%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[描述192.168.21.206 master1 192.168.21.208 master2 192.168.21.210 master3 在一台主机上使用kubeadm初始化一个集群1、把192.168.21.206上的/etc/kubernetes目录拷贝到192.168.21.210主机上的/etc/kubernetes目录2、生成证书文件 12345cd /etc/kubernetes/pkiopenssl genrsa -out apiserver-k8s.key 2048openssl req -new -key apiserver-k8s.key -subj "/CN=kube-apiserver," -out apiserver-k8s.csrecho subjectAltName = DNS:k8s,DNS:kubernetes,DNS:kubernetes.default,DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, IP:10.96.0.1, IP:192.168.21.210 &gt; /etc/kubernetes/pki/apiserver-k8s.extopenssl x509 -req -in apiserver-k8s.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out apiserver-k8s.crt -days 365 -extfile apiserver-k8s.ext 3、修改证书文件kube-apiserver.xml12--tls-cert-file=/etc/kubernetes/pki/apiserver-k8s.crt--tls-private-key-file=/etc/kubernetes/pki/apiserver-k8s.key 4、如果使用的是K8S1.7还需要修改一个证书文件5、改 IP地址admin.conf controller-manager.conf kubelet.conf scheduler.conf kube-apiserver.xml6、重启kubelet1systemctl restart kubelet 7、配置环境变量1export KUBECONFIG=/etc/kubernetes/admin.conf 添加节点1、在master上获取token1kubeadm token list 2、在节点上执行1kubeadm join --token 8358ba.70fdd01e8e5eb18b $MASTER_IP:6443 3、把master上/etc/kubernetes/pki目录里面的证书拷贝到节点的相同目录4、修改kubelet.confi文件的证书目录5、重启kubelet]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes1.6集群搭建]]></title>
    <url>%2F2018%2F09%2F17%2Fblog%2Fkubernetes1.6%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[描述开始之前关闭防火墙： systemctl disable firewalld修改主机机：hostnamectl set-hostname kube-node12192.168.10.33 kube-node192.168.10.34 kube-master kubernate1.6.4 集群环境搭建master:192.168.10.34node:192.168.10.33 安装kubelet和kubeadm下载RPM包https://github.com/huangjiasingle/k8s-rpm 选择最新版本1.6.4 ，下载之后进行安装 说明：安装之前需要装socat 包 然后安装：1yum loaclinstall -y *.rpm 注意:主备节点都需要安装，切记 然后在主备节点上安装docker,安装完之后，启动服务：123456789101112131415161718systemctl start docker [root@kube-node ~]# docker versionClient: Version: 1.10.3 API version: 1.22 Go version: go1.5.3 Git commit: 20f81dd Built: Thu Mar 10 16:08:02 2016 OS/Arch: linux/amd64Server: Version: 1.10.3 API version: 1.22 Go version: go1.5.3 Git commit: 20f81dd Built: Thu Mar 10 16:08:02 2016 OS/Arch: linux/amd64 load 镜像可以pull镜像也可以直接load镜像，前提是要有导出好的镜像文件 docker命令自己学习补充 导入的镜像列表如下： 初始化集群 master启动之后初始化集群 1kubeadm init --pod-network-cidr=10.244.0.0/16 --kubernetes-version=v1.6.4 执行的时候，如果出现如下报错：1Jun 8 22:55:33 kube-master kubelet: error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: "systemd" is different from docker cgroup driver: "cgroupfs" 需要修改 NODE上也需要改 把systemd 修改成cgroupfs12/etc/systemd/system/kubelet.service.d/10-kubeadm.confEnvironment="KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs" 启动结果：1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@kube-master ~]# kubeadm init --pod-network-cidr=10.244.0.0/16 --kubernetes-version=v1.6.4[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.[init] Using Kubernetes version: v1.6.4[init] Using Authorization mode: RBAC[preflight] Running pre-flight checks[preflight] Starting the kubelet service[certificates] Generated CA certificate and key.[certificates] Generated API server certificate and key.[certificates] API Server serving cert is signed for DNS names [kube-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.10.34][certificates] Generated API server kubelet client certificate and key.[certificates] Generated service account token signing key and public key.[certificates] Generated front-proxy CA certificate and key.[certificates] Generated front-proxy client certificate and key.[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/admin.conf"[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/controller-manager.conf"[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/scheduler.conf"[apiclient] Created API client, waiting for the control plane to become ready[apiclient] All control plane components are healthy after 110.668938 seconds[apiclient] Waiting for at least one node to register[apiclient] First node has registered after 6.592495 seconds[token] Using token: 21b4a4.230097a80c8639a6[apiconfig] Created RBAC rules[addons] Created essential addon: kube-proxy[addons] Created essential addon: kube-dnsYour Kubernetes master has initialized successfully!To start using your cluster, you need to run (as a regular user): sudo cp /etc/kubernetes/admin.conf $HOME/ sudo chown $(id -u):$(id -g) $HOME/admin.conf export KUBECONFIG=$HOME/admin.confYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: http://kubernetes.io/docs/admin/addons/You can now join any number of machines by running the following on each nodeas root: kubeadm join --token 21b4a4.230097a80c8639a6 192.168.10.34:6443 在master上执行123sudo cp /etc/kubernetes/admin.conf $HOME/ sudo chown $(id -u):$(id -g) $HOME/admin.conf export KUBECONFIG=$HOME/admin.conf 在node 上执行：123456789101112131415161718192021[root@kube-node ~]# kubeadm join --token 21b4a4.230097a80c8639a6 192.168.10.34:6443[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.[preflight] Running pre-flight checks[preflight] WARNING: kubelet service is not enabled, please run 'systemctl enable kubelet.service'[preflight] Starting the kubelet service[discovery] Trying to connect to API Server "192.168.10.34:6443"[discovery] Created cluster-info discovery client, requesting info from "https://192.168.10.34:6443"[discovery] Cluster info signature and contents are valid, will use API Server "https://192.168.10.34:6443"[discovery] Successfully established connection with API Server "192.168.10.34:6443"[bootstrap] Detected server version: v1.6.4[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)[csr] Created API client to obtain unique certificate for this node, generating keys and certificate signing request[csr] Received signed certificate from the API server, generating KubeConfig...[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"Node join complete:* Certificate signing request sent to master and response received.* Kubelet informed of new secure connection details.Run 'kubectl get nodes' on the master to see this machine join. 配置网络下载地址：https://github.com/coreos/flannel/tree/master/Documentationkube-flannel.yml kube-flannel-rbac.yml1234567[root@kube-master ~]# kubectl apply -f kube-flannel.ymlserviceaccount "flannel" createdconfigmap "kube-flannel-cfg" createddaemonset "kube-flannel-ds" created[root@kube-master ~]# kubectl apply -f kube-flannel-rbac.ymlclusterrole "flannel" createdclusterrolebinding "flannel" created 查看POD 查看NODE1234[root@kube-master ~]# kubectl get nodesNAME STATUS AGE VERSIONkube-master Ready 32m v1.6.4kube-node Ready 35s v1.6.4 查看DOCKERmaster1234567891011121314151617181920[root@kube-master ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMEScef090fe8ae6 fc5e302d8309 "/sidecar --v=2 --log" 5 minutes ago Up 5 minutes k8s_sidecar_kube-dns-3913472980-3ngkv_kube-system_5e85ea3e-4cc1-11e7-87d2-0800273ed16a_06e27e0c912ca 1091847716ec "/dnsmasq-nanny -v=2 " 5 minutes ago Up 5 minutes k8s_dnsmasq_kube-dns-3913472980-3ngkv_kube-system_5e85ea3e-4cc1-11e7-87d2-0800273ed16a_052e1b1c62347 f8363dbf447b "/kube-dns --domain=c" 5 minutes ago Up 5 minutes k8s_kubedns_kube-dns-3913472980-3ngkv_kube-system_5e85ea3e-4cc1-11e7-87d2-0800273ed16a_07ed8933be29b gcr.io/google_containers/pause-amd64:3.0 "/pause" 5 minutes ago Up 5 minutes k8s_POD_kube-dns-3913472980-3ngkv_kube-system_5e85ea3e-4cc1-11e7-87d2-0800273ed16a_0d513c3e80f00 cd4ae0be5e1b "/opt/bin/flanneld --" 6 minutes ago Up 6 minutes k8s_kube-flannel_kube-flannel-ds-rkvk4_kube-system_1f0dda6a-4cc5-11e7-87d2-0800273ed16a_13e7a1ae91d2a cd4ae0be5e1b "/bin/sh -c 'set -e -" 6 minutes ago Up 6 minutes k8s_install-cni_kube-flannel-ds-rkvk4_kube-system_1f0dda6a-4cc5-11e7-87d2-0800273ed16a_035388a791345 gcr.io/google_containers/pause-amd64:3.0 "/pause" 6 minutes ago Up 6 minutes k8s_POD_kube-flannel-ds-rkvk4_kube-system_1f0dda6a-4cc5-11e7-87d2-0800273ed16a_0ee581272c23b e073a55c288b "/usr/local/bin/kube-" 33 minutes ago Up 33 minutes k8s_kube-proxy_kube-proxy-t230v_kube-system_5e7e7561-4cc1-11e7-87d2-0800273ed16a_057acdbcbbc8e gcr.io/google_containers/pause-amd64:3.0 "/pause" 33 minutes ago Up 33 minutes k8s_POD_kube-proxy-t230v_kube-system_5e7e7561-4cc1-11e7-87d2-0800273ed16a_0274052fa35fe 4e3810a19a64 "kube-apiserver --kub" 33 minutes ago Up 33 minutes k8s_kube-apiserver_kube-apiserver-kube-master_kube-system_e215197843d67464823d0c66610eb358_0f1d34b8914f9 0ea16a85ac34 "kube-controller-mana" 33 minutes ago Up 33 minutes k8s_kube-controller-manager_kube-controller-manager-kube-master_kube-system_7400b523ee1c1e62e195a8abf7fb80e7_018d64034d9a7 1fab9be555e1 "kube-scheduler --add" 33 minutes ago Up 33 minutes k8s_kube-scheduler_kube-scheduler-kube-master_kube-system_3145edd89dab0492bdacc0dd589d0e90_0ee9793637c66 243830dae7dd "etcd --listen-client" 33 minutes ago Up 33 minutes k8s_etcd_etcd-kube-master_kube-system_7075157cfd4524dbe0951e00a8e3129e_09875990dd959 gcr.io/google_containers/pause-amd64:3.0 "/pause" 33 minutes ago Up 33 minutes k8s_POD_kube-apiserver-kube-master_kube-system_e215197843d67464823d0c66610eb358_0fd9f23fe3826 gcr.io/google_containers/pause-amd64:3.0 "/pause" 33 minutes ago Up 33 minutes k8s_POD_kube-scheduler-kube-master_kube-system_3145edd89dab0492bdacc0dd589d0e90_07a123d72f0c0 gcr.io/google_containers/pause-amd64:3.0 "/pause" 33 minutes ago Up 33 minutes k8s_POD_kube-controller-manager-kube-master_kube-system_7400b523ee1c1e62e195a8abf7fb80e7_0dcb214b77c62 gcr.io/google_containers/pause-amd64:3.0 "/pause" 33 minutes ago Up 33 minutes k8s_POD_etcd-kube-master_kube-system_7075157cfd4524dbe0951e00a8e3129e_0 查看node12345678[root@kube-node kubelet.service.d]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe25e2f8b675a cd4ae0be5e1b "/opt/bin/flanneld --" 28 seconds ago Up 26 seconds k8s_kube-flannel_kube-flannel-ds-l480m_kube-system_c2a99b0b-4cc5-11e7-87d2-0800273ed16a_1f84fc813883f cd4ae0be5e1b "/bin/sh -c 'set -e -" 32 seconds ago Up 30 seconds k8s_install-cni_kube-flannel-ds-l480m_kube-system_c2a99b0b-4cc5-11e7-87d2-0800273ed16a_00ff63bb1ccf9 e073a55c288b "/usr/local/bin/kube-" 35 seconds ago Up 32 seconds k8s_kube-proxy_kube-proxy-8c4r8_kube-system_c2b07bb5-4cc5-11e7-87d2-0800273ed16a_0925df18507da gcr.io/google_containers/pause-amd64:3.0 "/pause" 36 seconds ago Up 34 seconds k8s_POD_kube-flannel-ds-l480m_kube-system_c2a99b0b-4cc5-11e7-87d2-0800273ed16a_0a57cdf6cec13 gcr.io/google_containers/pause-amd64:3.0 "/pause" 36 seconds ago Up 34 seconds k8s_POD_kube-proxy-8c4r8_kube-system_c2b07bb5-4cc5-11e7-87d2-0800273ed16a_0 问题解答1、the connection to the server localhost:8080 was refused - did you specify the right host or port?12345sudo cp /etc/kubernetes/admin.conf $HOME/sudo chown $(id -u):$(id -g) $HOME/admin.confexport KUBECONFIG=$HOME/admin.conf然后在执行：kubectl get - -all 或者123456789101112vi /etc/kubernetes/manifests/kube-apiserver.yaml找到文件中有个叫- - -insecure-port默认是0,就是不开启http的访问方式 所以你的8080访问不到 - - -insecure-port=8080- - -insecure-bind-address=127.0.0.1重启kubelet服务 master上的 2、获取token123kubeadm token list获取之后可以加入到集群kubeadm join --token=a022f1.a6340056ead7e466 192.168.10.56:6443]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Kubernetes</tag>
        <tag>yml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过Prometheus收集Docker指标]]></title>
    <url>%2F2018%2F08%2F17%2Fblog%2F%E9%80%9A%E8%BF%87Prometheus%E6%94%B6%E9%9B%86Docker%E6%8C%87%E6%A0%87%2F</url>
    <content type="text"><![CDATA[描述Prometheus是一个开源系统监控和警报工具包。您可以将Docker配置为Prometheus目标。本主题向您展示如何配置Docker，设置Prometheus作为Docker容器运行，并使用Prometheus监控Docker实例。 警告：可用指标和这些指标的名称正在积极开发中，并可能随时更改。 目前，您只能监控Docker本身。您目前无法使用Docker目标监控您的应用程序。 配置Docker要将Docker守护程序配置为普罗米修斯目标，您需要指定 metrics-address。最好的方法是通过daemon.json默认情况下位于以下位置之一的。如果该文件不存在，请创建它。1234&#123; "metrics-addr" : "0.0.0.0:9323", "experimental" : true&#125; 配置并运行Prometheus管网下载直接解压即可。替换prometheus.yml文件为：12345678910111213141516171819202122232425262728293031323334353637# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: 'codelab-monitor'# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files: # - "first.rules" # - "second.rules"# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9090'] - job_name: 'docker-195' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['192.168.21.195:9323'] - job_name: 'docker-196' static_configs: - targets: ['192.168.21.196:9323'] 启动Prometheus1./prometheus 验证登录http://127.0.0.1:9090 查看targets 查看监控指标]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd常用操作]]></title>
    <url>%2F2018%2F08%2F17%2Fblog%2Fetcd%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[描述etcd是一个分布式键值存储，它提供了一种可靠的方式来存储跨机器集群的数据。它是开源的，可以在GitHub上找到。etcd优雅地处理网络分区期间的领导选举，并容忍包括领导者在内的机器故障。 您的应用程序可以读取和写入数据到etcd。一个简单的用例是将数据库连接详细信息或功能标志作为关键值对存储在etcd中。可以监视这些值，允许您的应用在更改时自行重新配置。 高级应用程序利用一致性保证来实现数据库领导者选举或对一群工作人员进行分布式锁定。 打印成员列表12345678./etcdctl --write-out=table --endpoints=localhost:2379 member list+------------------+---------+--------+----------------------------+----------------------------+| ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS |+------------------+---------+--------+----------------------------+----------------------------+| ba78e54b36d36c50 | started | infra1 | http://192.168.21.151:2380 | http://192.168.21.151:2379 || c6a63eef7452c8b1 | started | infra0 | http://192.168.21.149:2380 | http://192.168.21.149:2379 || efd972cb002e70bc | started | infra2 | http://192.168.21.153:2380 | http://192.168.21.153:2379 |+------------------+---------+--------+----------------------------+----------------------------+ 更新peerURLs12./etcdctl member update &lt;memberID&gt; &lt;peerURLs&gt;./etcdctl member update efd972cb002e70bc http://127.0.0.1:2380 删除成员12$ etcdctl member remove a8266ecf031671f3Removed member a8266ecf031671f3 from cluster 添加成员（扩容）添加成员是一个两步过程： 1、通过成员API或etcdctl member add命令将新成员添加到集群。 说明：全部操作使用etcd V3 12345etcdctl member add infra3 --peer-urls=http://192.168.21.202:2380 export ETCD_NAME="infra3"export ETCD_INITIAL_CLUSTER="infra3=http://192.168.21.202:2380,infra1=http://192.168.21.151:2380,infra0=http://192.168.21.149:2380,infra2=http://192.168.21.153:2380"export ETCD_INITIAL_CLUSTER_STATE="existing" 2、使用新群集配置启动新成员，包括已更新成员（现有成员+新成员）的列表。 etcdctl已通知集群有关新成员的信息，并打印出成功启动它所需的环境变量。现在使用新成员的相关标志启动新的etcd进程：12345export ETCD_NAME="infra3"export ETCD_INITIAL_CLUSTER="infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380,infra3=http://10.0.1.13:2380"export ETCD_INITIAL_CLUSTER_STATE=existing./etcd --initial-advertise-peer-urls http://192.168.21.202:2380 --listen-peer-urls http://192.168.21.202:2380 --listen-client-urls http://192.168.21.202:2379,http://127.0.0.1:2379 --advertise-client-urls http://192.168.21.202:2379 --initial-cluster-token etcd-cluster-1 --data-dir infra3 3、查看状态1234567891011121314151617root@zyzx-node1:[/root/etcd-v3.2.16-linux-amd64]./etcdctl member list --endpoints=192.168.21.149:2379,192.168.21.151:2379,192.168.21.153:2379,192.168.21.202:2379 75499131c19cbbbd, started, infra3, http://192.168.21.202:2380, http://192.168.21.202:237982aa79e98a2686d6, started, infra2, http://192.168.21.153:2380, http://192.168.21.153:2379ba78e54b36d36c50, started, infra1, http://192.168.21.151:2380, http://192.168.21.151:2379c6a63eef7452c8b1, started, infra0, http://192.168.21.149:2380, http://192.168.21.149:2379root@zyzx-node1:[/root/etcd-v3.2.16-linux-amd64] ./etcdctl endpoint status --endpoints=192.168.21.149:2379,192.168.21.151:2379,192.168.21.153:2379,192.168.21.202:2379192.168.21.149:2379, c6a63eef7452c8b1, 3.2.16, 2.6 MB, true, 4, 27392192.168.21.151:2379, ba78e54b36d36c50, 3.2.16, 2.6 MB, false, 4, 27392192.168.21.153:2379, 82aa79e98a2686d6, 3.2.16, 2.6 MB, false, 4, 27392192.168.21.202:2379, 75499131c19cbbbd, 3.2.16, 3.2 MB, false, 4, 27392root@zyzx-node1:[/root/etcd-v3.2.16-linux-amd64]./etcdctl endpoint health --endpoints=192.168.21.149:2379,192.168.21.151:2379,192.168.21.153:2379,192.168.21.202:2379192.168.21.149:2379 is healthy: successfully committed proposal: took = 1.302649ms192.168.21.151:2379 is healthy: successfully committed proposal: took = 1.457264ms192.168.21.153:2379 is healthy: successfully committed proposal: took = 1.48595ms192.168.21.202:2379 is healthy: successfully committed proposal: took = 1.453579ms 4、数据测试123456789101112131415#在一台节点上增加一条数据，数据是否会同步到其他节点root@zyzx-node1:[/root/etcd-v3.2.16-linux-amd64]./etcdctl put hello worldOKroot@zyzx-node1:[/root/etcd-v3.2.16-linux-amd64]./etcdctl get hellohelloworldroot@zyzx-node2:[/root/etcd-v3.2.16-linux-amd64]./etcdctl get hellohelloworldroot@LY1F-R020510-VM12:[/root/etcd-v3.2.16-linux-amd64]./etcdctl get hellohelloworld 备份与恢复1、备份操作12#保存快照./etcdctl --endpoints=$ENDPOINTS snapshot save snapshot-test.db 2、恢复操作12345./etcdctl snapshot restore snapshot.db --name m3 --data-dir=/home/etcd_data恢复后的文件需要修改权限为 etcd:etcd--name:重新指定一个数据目录，可以不指定，默认为 default.etcd--data-dir：指定数据目录建议使用时不指定 name 但指定 data-dir，并将 data-dir 对应于 etcd 服务中配置的 data-dir etcd配置参数https://skyao.gitbooks.io/learning-etcd3/content/documentation/op-guide/configuration.html]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Docker使用Devicemapper]]></title>
    <url>%2F2018%2F08%2F17%2Fblog%2F%E9%85%8D%E7%BD%AEDocker%E4%BD%BF%E7%94%A8Devicemapper%2F</url>
    <content type="text"><![CDATA[描述docker devicemapper有两种配置模式loop-lvm和direct lvm，默认使用loop-lvm配置模式，但是在使用该模式的时候，通过docker info，信息提示 WARNING: Usage of loopback devices is strongly discouraged for production use. Use --storage-opt dm.thinpooldev to specify a custom block storage device，在生产环境中不推荐使用loop-lvm模式，推荐使用direct-lvm模式，下面就是direct-lvm模式的配置步骤。 创建PV1[root@localhost ~]# pvcreate /dev/sdc1 创建VG1[root@localhost ~]# vgcreate docker /dev/sdc1 创建LV12[root@localhost ~]#lvcreate --wipesignatures y -n thinpool docker -l 95%VG [root@localhost ~]#lvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VG 转换pool为thin pool1[root@localhost ~]lvconvert -y --zero n -c 512K --thinpool docker/thinpool --poolmetadata docker/thinpoolmeta 编辑针对docker/thinpool的profile文件如下12345[root@localhost ~]# vi /etc/lvm/profile/docker-thinpool.profile activation &#123; thin_pool_autoextend_threshold=80 thin_pool_autoextend_percent=20 &#125; 使用上述的profile文件1[root@localhost ~]# lvchange --metadataprofile docker-thinpool docker/thinpool 验证lv已经处于monitor状态123456[root@localhost ~]# lvs -o+seg_monitor LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert Monitor home centos -wi-ao---- 141.62g root centos -wi-ao---- 50.00g swap centos -wi-ao---- 7.88g thinpool docker twi-aot--- 950.00g 1.08 0.02 monitored 调整 docker 存储1）备份12[root@n33 ~]# mkdir /var/lib/docker.bk[root@n33 ~]# mv /var/lib/docker/* /var/lib/docker.bk 如果这个 docker engine 上已经有部分 images 在使用，且需要保存，请先提前推送到自己的 registry 中保存。 修改docker.service配置文件中的Execstart参数如下两种方式： 1、启动服务参数 1ExecStart=/usr/bin/dockerd --storage-driver=devicemapper --storage-opt=dm.thinpooldev=/dev/mapper/docker-thinpool --storage-opt=dm.use_deferred_removal=true --storage-opt=dm.use_deferred_deletion=true 2、docker配置文件 也可以在daemon配置文件中配置，如默认的配置文件/etc/docker/daemon.json中，可如下配置： 12345678&#123; "storage-driver": "devicemapper", "storage-opts": [ "dm.thinpooldev=/dev/mapper/docker-thinpool", "dm.use_deferred_removal=true", "dm.use_deferred_deletion=true" ]&#125; 重启daemon以及docker12[root@localhost ~]# systemctl daemon-reload [root@localhost ~]# systemctl restart docker 参考https://docs.docker.com/storage/storagedriver/device-mapper-driver/#configure-direct-lvm-mode-for-production]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keepalived安装配置]]></title>
    <url>%2F2018%2F07%2F17%2Fblog%2FKeepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[描述Keepalived是一个免费开源的，用C编写的类似于layer3, 4 &amp; 7交换机制软件，具备我们平时说的第3层、第4层和第7层交换机的功能。主要提供loadbalancing（负载均衡）和 high-availability（高可用）功能，负载均衡实现需要依赖Linux的虚拟服务内核模块（ipvs），而高可用是通过VRRP协议实现多台机器之间的故障转移服务。 上图是Keepalived的功能体系结构，大致分两层：用户空间（user space）和内核空间（kernel space）。 内核空间：主要包括IPVS（IP虚拟服务器，用于实现网络服务的负载均衡）和NETLINK（提供高级路由及其他相关的网络功能）两个部份。 用户空间： WatchDog：负载监控checkers和VRRP进程的状况 VRRP Stack：负载负载均衡器之间的失败切换FailOver，如果只用一个负载均稀器，则VRRP不是必须的。 Checkers：负责真实服务器的健康检查healthchecking，是keepalived最主要的功能。换言之，可以没有VRRP Stack，但健康检查healthchecking是一定要有的。 IPVS wrapper：用户发送设定的规则到内核ipvs代码 Netlink Reflector：用来设定vrrp的vip地址等。 Keepalived的所有功能是配置keepalived.conf文件来实现的。 安装与配置2.1 下载及安装以当前最新版本1.2.24为例 将从官网下载的keepalived-1.2.24.tar.gz包，上传到/root/tools目录下。 1234tar keepalived-1.2.24.tar.gzcd keepalived-1.2.24./configuremake &amp;&amp; make install 说明：如果在./configure之后提示1234!!! OpenSSL is not properly installed on your system. !!! !!! Can not include OpenSSL headers files. 解决方法： yum -y install openssl-devel 2.2 配置规范启动 1234567891011121314151617181920生成启动脚本命令cp /usr/local/etc/rc.d/init.d/keepalived /etc/init.d/ 配置启动脚本的参数cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/ 创建默认的keepalived配置文件路径mkdir /etc/keepalived 把keepalived.conf模板拷贝到 /etc/keepalived目录cp /usr/local/etc/keepalived/keepalived.conf /etc/keepalived/ cp /usr/local/sbin/keepalived /usr/sbin/ 启动：/etc/init.d/keepalived start停止/etc/init.d/keepalived stop状态/etc/init.d/keepalived status keepalived服务控制123456systemctl enable keepalived.service #设置开机自动启动systemctl disable keepalived.service #取消开机自动启动systemctl start keepalived.service #启动服务systemctl restart keepalived.service #重启服务systemctl stop keepalived.service #停止服务systemctl status keepalived.service #查看服务状态 2.3 配置文件的详细说明主节点配置 备节点配置 说明：备节点的proiority设置为比主节点的要小 2.4 全局定义块1、email通知（notification_email、smtp_server、smtp_connect_timeout）：用于服务有故障时发送邮件报警，可选项，不建议用。需要系统开启sendmail服务，建议用第三独立监控服务，如用nagios全面监控代替。 2、lvs_id：lvs负载均衡器标识，在一个网络内，它的值应该是唯一的。 3、router_id：用户标识本节点的名称，通常为hostname 4、花括号｛｝：用来分隔定义块，必须成对出现。如果写漏了，keepalived运行时不会得到预期的结果。由于定义块存在嵌套关系，因此很容易遗漏结尾处的花括号，这点需要特别注意。 2.5 VRRP实例定义块vrrp_sync_group：同步vrrp级，用于确定失败切换（FailOver）包含的路由实例个数。即在有2个负载均衡器的场景，一旦某个负载均衡器失效，需要自动切换到另外一个负载均衡器的实例是哪 group：至少要包含一个vrrp实例，vrrp实例名称必须和vrrp_instance定义的一致 vrrp_instance：vrrp实例名 1&gt; state：实例状态，只有MASTER 和 BACKUP两种状态，并且需要全部大写。抢占模式下，其中MASTER为工作状态，BACKUP为备用状态。当MASTER所在的服务器失效时，BACKUP所在的服务会自动把它的状态由BACKUP切换到MASTER状态。当失效的MASTER所在的服务恢复时，BACKUP从MASTER恢复到BACKUP状态。 2&gt; interface：对外提供服务的网卡接口，即VIP绑定的网卡接口。如：eth0，eth1。当前主流的服务器都有2个或2个以上的接口（分别对应外网和内网），在选择网卡接口时，一定要核实清楚。 3&gt;mcast_src_ip：本机IP地址 4&gt;virtual_router_id：虚拟路由的ID号，每个节点设置必须一样，可选择IP最后一段使用，相同的 VRID 为一个组，他将决定多播的 MAC 地址。 5&gt; priority：节点优先级，取值范围0～254，MASTER要比BACKUP高 6&gt;advert_int：MASTER与BACKUP节点间同步检查的时间间隔，单位为秒 7&gt;lvs_sync_daemon_inteface：负载均衡器之间的监控接口,类似于 HA HeartBeat的心跳线。但它的机制优于 Heartbeat，因为它没有“裂脑”这个问题,它是以优先级这个机制来规避这个麻烦的。在 DR 模式中，lvs_sync_daemon_inteface与服务接口interface使用同一个网络接口 8&gt; authentication：验证类型和验证密码。类型主要有 PASS、AH 两种，通常使用PASS类型，据说AH使用时有问题。验证密码为明文，同一vrrp实例MASTER与BACKUP使用相同的密码才能正常通信。 9&gt;smtp_alert：有故障时是否激活邮件通知 10&gt;nopreempt：禁止抢占服务。默认情况，当MASTER服务挂掉之后，BACKUP自动升级为MASTER并接替它的任务，当MASTER服务恢复后，升级为MASTER的BACKUP服务又自动降为BACKUP，把工作权交给原MASTER。当配置了nopreempt，MASTER从挂掉到恢复，不再将服务抢占过来。 11&gt;virtual_ipaddress：虚拟IP地址池，可以有多个IP，每个IP占一行，不需要指定子网掩码。注意：这个IP必须与我们的设定的vip保持一致。 主备切换可以看到目前在主节点上12345678910[root@kube-master keepalived]# ip a |grep 192.168.10.16 inet 192.168.10.16/24 scope global secondary enp0s3 停止主节点上的keepalived[root@kube-master keepalived]# systemctl stop keepalived[root@kube-master keepalived]# ip a |grep 192.168.10.16已经没有IP了去备节点上查看[root@kube-mini keepalived]# ip a |grep 192.168.10.16 inet 192.168.10.16/24 scope global secondary enp0s3 日志配置keepalived默认把日志写入到/var/log/message文件中如果想让keepalived把日志写到指定的文件，需要修改如下配置：123456789101112131415[root@kube-master init.d]# cat /etc/sysconfig/keepalived# Options for keepalived. See `keepalived --help' output and keepalived(8) and# keepalived.conf(5) man pages for a list of all options. Here are the most# common ones :## --vrrp -P Only run with VRRP subsystem.# --check -C Only run with Health-checker subsystem.# --dont-release-vrrp -V Dont remove VRRP VIPs &amp; VROUTEs on daemon stop.# --dont-release-ipvs -I Dont remove IPVS topology on daemon stop.# --dump-conf -d Dump the configuration data.# --log-detail -D Detailed log messages.# --log-facility -S 0-7 Set local syslog facility (default=LOG_DAEMON)#KEEPALIVED_OPTIONS="-D -d -S 0" 修改该文件vi /etc/rsyslog.conf1234567891011121314151617181920212223242526增加：local0.* /var/log/keepalived.log重启rsyslog 服务systemctl restart rsyslog重启keepalived服务systemctl restart keepalived日志如下[root@kube-master init.d]# tail -f /var/log/keepalived.log Oct 9 13:27:31 kube-master Keepalived_vrrp[13400]: VRRP_Instance(VI_1) Transition to MASTER STATEOct 9 13:27:32 kube-master Keepalived_vrrp[13400]: VRRP_Instance(VI_1) Entering MASTER STATEOct 9 13:27:32 kube-master Keepalived_vrrp[13400]: VRRP_Instance(VI_1) setting protocol VIPs.Oct 9 13:27:32 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16Oct 9 13:27:32 kube-master Keepalived_vrrp[13400]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on enp0s3 for 192.168.10.16Oct 9 13:27:32 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16Oct 9 13:27:32 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16Oct 9 13:27:32 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16Oct 9 13:27:32 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16Oct 9 13:27:32 kube-master Keepalived_healthcheckers[13399]: Netlink reflector reports IP 192.168.10.16 addedOct 9 13:27:37 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16Oct 9 13:27:37 kube-master Keepalived_vrrp[13400]: VRRP_Instance(VI_1) Sending/queueing gratuitous ARPs on enp0s3 for 192.168.10.16Oct 9 13:27:37 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16Oct 9 13:27:37 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16Oct 9 13:27:37 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16Oct 9 13:27:37 kube-master Keepalived_vrrp[13400]: Sending gratuitous ARP on enp0s3 for 192.168.10.16]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>Keepalived</tag>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes通过yum安装配置]]></title>
    <url>%2F2018%2F07%2F17%2Fblog%2Fkubernetes%E9%80%9A%E8%BF%87yum%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[先决条件在REDHAT7.1下安装配置Kubernetes，你需要一个主机作为master，和一个或多个主机作为群集node 开始创建集群系统信息在/etc/hosts 中配置需要用到的主机IP和主机名，确保机器之前能互相PING通12redhat-master = 192.168.10.99redhat-minion-1 = 192.168.10.88 配置YUM源进入 /etc/yum.repos.d目录，新建 redhat.repo1234[virt7-docker-common-release]name=virt7-docker-common-releasebaseurl=http://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/gpgcheck=0 开始安装 master和minion 都需要安装1yum -y install --enablerepo=virt7-docker-common-release kubernetes etcd flannel 注意：安装kubernetes的时候需要主机安装 socat 如果没有安装，则提示异常退出 修改 /etc/kubernetes/config文件如下： 注意：需要禁用防火墙 在 master 节点配置kubernetes服务 编译/etc/etcd/etcd.conf1234567# [member]ETCD_NAME=defaultETCD_DATA_DIR="/var/lib/etcd/default.etcd"ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"#[cluster]ETCD_ADVERTISE_CLIENT_URLS="http://0.0.0.0:2379" 编辑/etc/kubernetes/apiserver1234567891011121314151617# The address on the local server to listen to.KUBE_API_ADDRESS="--address=0.0.0.0"# The port on the local server to listen on.KUBE_API_PORT="--port=8080"# Port kubelets listen onKUBELET_PORT="--kubelet-port=10250"# Comma separated list of nodes in the etcd clusterKUBE_ETCD_SERVERS="--etcd-servers=http://redhat-master:2379"# Address range to use for servicesKUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.254.0.0/16"# Add your own!KUBE_API_ARGS="" 启动etcd服务123systemctl start etcdetcdctl mkdir /kube-centos/networketcdctl mk /kube-centos/network/config "&#123; \"Network\": \"172.30.0.0/16\", \"SubnetLen\": 24, \"Backend\": &#123; \"Type\": \"vxlan\" &#125; &#125;" 特别注意：/kube-centos/network与下面的Flannel配置中的FLANNEL_ETCD_PREFIX对应 配置/etc/sysconfig/flanneld 服务：master和minion 都需要配置1234567891011# Flanneld configuration options# etcd url location. Point this to the server where etcd runsFLANNEL_ETCD_ENDPOINTS="http://redhat-master:2379"# etcd config key. This is the configuration key that flannel queries# For address range assignmentFLANNEL_ETCD_PREFIX="/kube-redhat/network"# Any additional options that you want to pass#FLANNEL_OPTIONS="" 特别注意：FLANNEL_ETCD_PREFIX=”/kube-redhat/network”与上面的etcd配置中的Network对应 在master主机上启动服务12345for SERVICES in etcd kube-apiserver kube-controller-manager kube-scheduler flanneld; do systemctl restart $SERVICES systemctl enable $SERVICES systemctl status $SERVICESdone 在节点上配置Kubernetes服务。我们需要配置kubelet开始kubelet和代理 编辑/etc/kubernetes/kubelet123456789101112131415# The address for the info server to serve onKUBELET_ADDRESS="--address=0.0.0.0"# The port for the info server to serve onKUBELET_PORT="--port=10250"# You may leave this blank to use the actual hostname# Check the node number!KUBELET_HOSTNAME="--hostname-override=redhat-minion-n"# Location of the api-serverKUBELET_API_SERVER="--api-servers=http://redhat-master:8080"# Add your own!KUBELET_ARGS="" 配置/etc/sysconfig/flanneld (in all the nodes)1234567891011# Flanneld configuration options# etcd url location. Point this to the server where etcd runsFLANNEL_ETCD_ENDPOINTS="http://redhat-master:2379"# etcd config key. This is the configuration key that flannel queries# For address range assignmentFLANNEL_ETCD_PREFIX="/kube-redhat/network"# Any additional options that you want to pass#FLANNEL_OPTIONS="" 在minion主机上启动服务12345for SERVICES in kube-proxy kubelet flanneld docker; do systemctl restart $SERVICES systemctl enable $SERVICES systemctl status $SERVICESdone 安装配置完成，进行验证：]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Kubernetes</tag>
        <tag>yml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes资源创建yml语法]]></title>
    <url>%2F2018%2F07%2F17%2Fblog%2FKubernetes%E8%B5%84%E6%BA%90%E5%88%9B%E5%BB%BAyml%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[描述在是用kubernetes中，我们对资源的创建大部分都是通过1kubelet create -f RESOURCE.yaml 刚开看的时候不免有一些迷茫，看不懂语法，不知道怎么写；今天本文就介绍一下kubernetes construct语法。 Construct语法其实就是由kubelet格式化成API的post data，提交给apiserver，因此这里支持yaml，json两种数据结构的文件。 Pod资源1234567891011121314151617181920212223242526272829apiVersion: v1 指定api版本，此值必须在kubectl apiversion中kind: Pod 指定创建资源的角色/类型metadata: 资源的元数据/属性 name: test 资源的名字，在同一个namespace中必须唯一 labels: 设定资源的标签 sex: boy 标签以key/value的结构存在 age: 18spec: #specification of the resource content 指定该资源的内容 restartPolicy: Never 表明改容器仅仅运行一次，默认k8s的策略，在此容器退出后，会立即创建一个相同的容器 volumes: 定义一组挂载设备 - name: volume 定义一个挂载设备的名字 hostPath: /data/www/html 挂载设备类型为hostPath，路径为宿主机下的/data/www/html,这里设备类型支持很多种 containers: 指定资源中的容器 - name: container1 容器的名字 image: “docker.coocla.org/ubuntu:last” 容器使用的镜像地址 volumeMounts: - mountPath: /mnt 挂载到容器的某个路径下 name: volume 挂载设备的名字，与volumes[*].name 需要对应 livenessProbe: 容器健康监测 httpGet: http形式监测，返回200-399之间，则认为容器正常 path: /health port: 8080 initialDelaySeconds: 15 表明第一次检测在容器启动后多长时间后开始 timeoutSeconds: 1 检测的超时时间 env: 指定容器中的环境变量 - name: str 变量的名字 value: &quot;hello world” 变量的值 command: [&quot;/bin/bash&quot;, &quot;-c&quot;] 覆盖容器中的Entrypoint,对应Dockefile中的ENTRYPOINT args: [&quot;/bin/echo&quot;, &quot;$(str)&quot;] 对应Dockerfile中CMD参数 健康监测还支持另外一种方法：123456exec: 执行命令的方法进行监测，如果其退出码不为0，则认为容器正常 command: - cat - /tmp/healthinitialDelaySeconds: 15timeoutSeconds: 1 ReplicationController的语法参数1234567891011121314apiVersion: v1kind: ReplicationControllermetadata: name: nginxspec: replicas: 2 指定rc中pod的个数 template: 指定rc中pod的模板，rc中的pod都是按照这个模板来创建的 metadata: 指定rc中pod的元数据，注意这里不需要在指定pod的名字，它由rc复制生成 labels: app: nginx spec: container: - name: nginx image: nginx Service123456789101112131415apiVersion: v1kind: Servicemetadata: name: nginxsvc labels: app: nginxspec: 指定Service中的内容 ports: 映射列表 - port: 80 service的端口 porotocal: TCP 映射的协议类型，支持TCP/UDP targetPort: 80 映射到pod的端口 name: www.baidu.com 该映射的名字selector: 匹配器port: 80app: nginx 匹配label中app为nginx，port为80的pod Secret12345678910111213apiVersion: v1kind: Secretmetadata: name: mysecrettype: 0paque 定义secret的类型，这里支持三种类型 password: xxx|base64 以key/value的形式定义，value需要经过base64编码才可以，在secret被挂载到container中后，会以key作为文件名，value的值经过base64解码作为内容，以文件的形式存在于container中 username: xxx|base64---type: kubernetes.io/service-account-token 第二种secret类型，用作创建服务账号的token，用作进程间通信的认证---type: kubernetes.io/dockercfg 第三种secret类型，用作在创建container，对docker registry的认证data: .dockercfg: `cat ~/.dockercfg | base64` 以上为部分资源参数，当然还有更多的参数可以指定，及更多的资源可以通过定义construct来创建。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Kubernetes</tag>
        <tag>yml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker私有仓库创建]]></title>
    <url>%2F2018%2F06%2F17%2Fblog%2FDocker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[描述和Mavan的管理一样，Dockers不仅提供了一个中央仓库，同时也允许我们使用registry搭建本地私有仓库。 使用私有仓库有许多优点： 节省网络带宽，针对于每个镜像不用每个人都去中央仓库上面去下载，只需要从私有仓库中下载即可； 提供镜像资源利用，针对于公司内部使用的镜像，推送到本地的私有仓库中，以供公司内部相关人员使用。接下来我们就大致说一下如何在本地搭建私有仓库。 说明：目前Docker Registry已经升级到了v2，最新版的Docker已不再支持v1。Registry v2使用Go语言编写，在性能和安全性上做了很多优化，重新设计了镜像的存储格式。此文档是在v1的基础上写的，如果需要安装registry v2，只需下载registry:2.2即可，或者可以下载后面的安装脚本运行安装 环境准备虚拟机：192.168.10.22 用作私有仓库 安装脚本如下：1234567891011121314151617181920212223242526272829#!/bin/bash# Description: create a private registry v2.2# Version: 0.2## Author: wangtao 479021795@qq.com# Date: 2015/10/29set -o xtraceif [[ $UID -ne 0 ]]; then echo "Not root user. Please run as root." exit 0fi# Install Docker if notdocker -vif [[ $? -ne 0 ]]; then echo "Please install Docker first." exit 0fiREGISTRY_VERSION=2.2# Download registry image v2.2docker pull registry:$&#123;REGISTRY_VERSION&#125;# Start registry containermkdir /opt/registrydocker run -d -p 5000:5000 --restart=always -v /opt/registry:/var/lib/registry --name hummer_registry registry:$&#123;REGISTRY_VERSION&#125; Registry的存放目录在Docker Hub上显示的是/tmp/registry-dev，但是映射之后发现并没有存放在该目录，查看源码发现，镜像信息存放在/var/lib/registry目录下，因此这里修改为将/opt/registry目录映射到/var/lib/registry。 执行脚本名称 ： 查看安装的镜像文件脚本执行成功，为启动5000端口 安装测试接下来我们就要操作把一个本地镜像push到私有仓库中。此处使用的是swarm。 接下来修改一下该镜像的tag。1docker tag swarm 192.168.10.22:5000/swarm 接下来把打了tag的镜像上传到私有仓库1docker push 192.168.10.22:5000/swarm 因为Docker从1.3.X之后，与docker registry交互默认使用的是https，然而此处搭建的私有仓库只提供http服务，所以当与私有仓库交互时就会报上面的错误。为了解决这个问题需要在启动docker server时增加启动参数为默认使用http访问。需要修改：12vi /etc/sysconfig/docker增加 --insecure-registry 192.168.10.22:5000 说明：修改完之后，一定要重启docker服务1systemctl restart docker push成功 查看仓库里的镜像文件1234[root@redhat-master ~]# curl -X GET http://192.168.10.22:5000/v2/_catalog&#123;"repositories":["swarm"]&#125;[root@redhat-master ~]# curl -X GET http://192.168.10.22:5000/v2/swarm/tags/list&#123;"name":"swarm","tags":["latest"]&#125; 删除主机上的swarm镜像123[root@redhat-master ~]# docker rmi -f 192.168.10.22:5000/swarmUntagged: 192.168.10.22:5000/swarm:latestDeleted: sha256:36b1e23becabc0b27c5787712dce019982c048665fd9e7e6cb032a46bcac510d 从私有仓库下载镜像1docker pull 192.168.10.22:5000/swarm]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>mesos</tag>
        <tag>docker</tag>
        <tag>matathon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes架构及资源关系简单总结]]></title>
    <url>%2F2018%2F06%2F17%2Fblog%2FKubernetes%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%B5%84%E6%BA%90%E5%85%B3%E7%B3%BB%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[描述之前在《Kubernetes初体验》一文中已经简单介绍了Kubernetes的架构和一些基本概念，最近接着学习了一下，觉得Kubernetes的这些资源（或者称为对象）对于理解和学习Kubernetes非常重要，而且因为比较多，所以决定写篇博客来做一下总结，加深记忆。当然，本文不会对每个资源做深入描述，因为每个资源要介绍的比较清楚都需要一篇长篇大论了。后面我会分篇详细介绍每一个资源，当然最好的了解方式还是去看Kubernetes官方对于这些资源的描述：https://kubernetes.io/docs/reference。本文的目标有两个： 对Kubernetes的架构做一个简单的介绍。对Kubernetes的大部分资源极其关系做一个简单的介绍。 文章尽可能简明、简短。Just keep it simple and focus。 Kubernetes架构先引用一下官方的架构图： 对于本文来说，我觉得这张图有点复杂了，但是我又懒得自己画了，就用这张吧。Kubernetes是一个集群，和传统的集群相似，它也是有一个主节点和若干个工作节点组成。在Kubernetes中，主节点称之为Master节点，就是上图中左边的大框；工作节点称之为Node（原来称为Minion，一个意思）。下面我们分别介绍Master节点和Node节点。 ##MasterMaster节点上面主要由四个模块组成：APIServer、scheduler、controller manager、etcd。 1、APIServer。APIServer的功能如其名，负责对外提供RESTful的Kubernetes API服务，它是系统管理指令的统一入口，任何对资源进行增删改查的操作都要交给APIServer处理后再提交给etcd。如架构图中所示，kubectl（Kubernetes提供的客户端工具，该工具内部就是对Kubernetes API的调用）是直接和APIServer交互的。 2、schedule。scheduler的职责很明确，就是负责调度pod（Kubernetes中最小的调度单元，后面马上就会介绍）到合适的Node上。如果把scheduler看成一个黑匣子，那么它的输入是pod和由多个Node组成的列表，输出是Pod和一个Node的绑定（bind），即将这个pod部署到这个Node上。虽然scheduler的职责很简单，但我们知道调度系统的智能程度对于整个集群是非常重要的。Kubernetes目前提供了调度算法，但是同样也保留了接口，用户可以根据自己的需求定义自己的调度算法。 3、controller manager。如果说APIServer做的是“前台”的工作的话，那controller manager就是负责“后台”的。后面我们马上会介绍到资源，每个资源一般都对应有一个控制器，而controller manager就是负责管理这些控制器的。还是举个例子来说明吧：比如我们通过APIServer创建一个pod，当这个pod创建成功后，APIServer的任务就算完成了。而后面保证Pod的状态始终和我们预期的一样的重任就由controller manager去保证了。 4、etcd。etcd是一个高可用的键值存储系统，Kubernetes使用它来存储各个资源的状态，从而实现了Restful的API。 至此，Kubernetes Master就简单介绍完了。当然，每个模块内部的实现都很复杂，而且功能也比较复杂，我现在也只是比较浅的了解了一下。如果后续了解的比较清楚了，再做总结分享。 Node真正干活的来了。每个Node节点主要由三个模块组成：kubelet、kube-proxy、runtime。先从简单的说吧。 1、runtime。runtime指的是容器运行环境，目前Kubernetes支持docker和rkt两种容器，一般都指的是docker，毕竟docker现在是最主流的容器。 2、kube-proxy。该模块实现了Kubernetes中的服务发现和反向代理功能。反向代理方面：kube-proxy支持TCP和UDP连接转发，默认基于Round Robin算法将客户端流量转发到与service对应的一组后端pod。服务发现方面，kube-proxy使用etcd的watch机制，监控集群中service和endpoint对象数据的动态变化，并且维护一个service到endpoint的映射关系，从而保证了后端pod的IP变化不会对访问者造成影响。另外kube-proxy还支持session affinity。（这里涉及到了service的概念，可以先跳过，等了解了service之后再来看。） 3、kubelet。Kubelet是Master在每个Node节点上面的agent，是Node节点上面最重要的模块，它负责维护和管理该Node上面的所有容器，但是如果容器不是通过Kubernetes创建的，它并不会管理。本质上，它负责使Pod得运行状态与期望的状态一致。 至此，Kubernetes的Master和Node就简单介绍完了。下面我们来看Kubernetes中的各种资源/对象。 PodPod是Kubernetes里面抽象出来的一个概念，它具有如下特点： Pod是能够被创建、调度和管理的最小单元； 每个Pod都有一个独立的IP； 一个Pod由一个或多个容器构成； 一个Pod内的容器共享Pod的所有资源，这些资源主要包括：共享存储（以Volumes的形式）、共享网络、共享端口等。 集群内的Pod之间不论是否在同一个Node上都可以任意访问，这一般是通过一个二层网络来实现的。 Kubernetes虽然也是一个容器编排系统，但不同于其他系统，它的最小操作单元不是单个容器，而是Pod。这个特性给Kubernetes带来了很多优势，比如最显而易见的是同一个Pod内的容器可以非常方便的互相访问（通过localhost就可以访问）和共享数据。使用Pod时我们需要注意两点： 虽然Pod内可以有多个容器，但一般我们只将有亲密关系的容器放在一个Pod内，比如这些容器需要相互访问、共享数据等。举个最典型的例子，比如我们有一个系统，前端是tomcat作为web，后端是存储数据的数据库mysql，那么将这两个容器部署在一个Pod内就非常合理了，因为他们通过localhost就可以访问彼此。 虽然每个Pod都有独立的IP，但是不推荐前台通过IP去访问Pod，因为Pod一旦销毁重建，IP就会变化。如果我们的Pod提供了对外的Web服务，那么我们可以通过Kubernetes提供的service去访问，后面会介绍到。 下面是一个Pod的描述文件nginx-pod.yaml：123456789101112apiVersion: v1kind: Podmetadata: name: nginx-pod labels: app: nginxspec: containers: - image: registry.hnaresearch.com/library/nginx:latest name: nginx ports: - containerPort: 80 apiVersion表示API的版本，kind表示我们要创建的资源的类型。metadata是Pod的一些元数据描述。spec描述了我们期望该Pod内运行的容器。通过kubectl create -f nginx-pod.yaml就可以创建一个Pod，这个Pod里面只有一个nginx容器。12345➜ kubectl create -f nginx-pod.yamlpod "nginx-pod" created➜ kubectl get podNAME READY STATUS RESTARTS AGEnginx-pod 1/1 Running 0 1h 这里我们只是为了示例，其实实际应用中我们很少会去直接创建一个Pod，因为这样创建的Pod就像个没人管的孩子，挂了的话也不会有人去重新建立一个新的来顶替它。Kubernetes提供了很多创建Pod的方式，下面我们接着介绍。 Replication ControllerReplication Controller简称RC，一般翻译为副本控制器，这里的副本指的是Pod。如它的名字所言RC的作用就是保证任意时刻集群中都有期望个数的Pod副本在正常运行。我们通过一个简单的RC描述文件（mysql-rc.yaml）来介绍它：123456789101112131415161718192021apiVersion: v1kind: ReplicationControllermetadata: name: mysqlspec: replicas: 1 selector: app: mysql template: metadata: labels: app: mysql spec: containers: - name: mysql image: registry.hnaresearch.com/library/mysql:5.6 ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: "123456" 上面这个文件描述了一个RC，名字叫mysql，最上面的spec描述了我们期望有1个副本，这些副本都是按照下面的template去创建的。如果某一时刻副本数比replicas描述的少，就按照template去创建新的，如果多了，就干掉几个。而下面的spec描述了这个Pod内运行的容器。 123456789➜ kubectl create -f mysql-rc.yamlreplicationcontroller "mysql" created➜ kubectl get rcNAME DESIRED CURRENT READY AGEmysql 1 1 1 7s➜ kubectl get podNAME READY STATUS RESTARTS AGEmysql-1l717 1/1 Running 0 27snginx-pod 1/1 Running 0 1h 然后我们进行一些删除操作：12345678910➜ kubectl delete pod nginx-podpod "nginx-pod" deleted➜ kubectl get podNAME READY STATUS RESTARTS AGEmysql-1l717 1/1 Running 0 5m➜ kubectl delete pod mysql-1l717pod "mysql-1l717" deleted➜ kubectl get podNAME READY STATUS RESTARTS AGEmysql-2vl9k 1/1 Running 0 4s 我们先删掉之前通过Pod描述文件创建的nginx-pod，按照预期它被删除了，并没有重建。然后我们删掉mysql-1l717，发现又出来一个新的mysql-2vl9k。这是因为mysql这个是通过RC创建的，除非删除它的RC，否则任意时刻该RC都会保证有预期个Pod副本在运行。 那么，RC是怎么和Pod产生关联的呢？上面的selector是什么含义？OK，我们来介绍下一个对象。 Labels和SelectorLabel是附属在Kubernetes对象上的键值对，它可以在创建的时候指定，也可以随时增删改。一个对象上面可以有任意多个Labels。它往往对于用户是有意义的，对系统是没有特殊含义的。我个人理解你可以简单把他当做Git上面的tag。这里我们只介绍一下它和Selector配合使用时的场景。我们从上面Pod和RC的描述文件中可以看到，每个Pod都有一个Labels，而RC的Selector部分也有一个定义了一个labels。RC会认为凡是和它Selector部分定义的labels相同的Pod都是它预期的副本。比如凡是labels为app=mysql的Pod都是刚才定义的RC的副本。 所以就有一个注意点，我们不要单独去创建Pod，更不要单独去创建符合某个RC的Selector的Pod，那样RC会认为是它自己创建的这个Pod而导致与预期Pod数不一致而干掉某些Pod。当然Labels还有很多用途，Selector除了等值外也有一些其他判读规则，这里不细述。 Service终于轮到Service出场了，之前我们已经多次提到它了。Service是Kubernetes里面抽象出来的一层，它定义了由多个Pods组成的逻辑组（logical set），可以对组内的Pod做一些事情： 对外暴露流量 做负载均衡（load balancing） 服务发现（service-discovery）。 前面我们说了如果我们想将Pod内容器提供的服务暴露出去，就要使用Service。因为Service除了上面的特性外，还有一个集群内唯一的私有IP和对外的端口，用于接收流量。如果我们想将一个Service暴露到集群外，即集群外也可以访问的话，有两种方法： LoadBalancer - 提供一个公网的IP NodePort - 使用NAT将Service的端口暴露出去。 为什么不能通过Pod的IP，而要通过Service呢？因为在Kubernetes中，Pod是可能随时死掉被重建的，所以说其IP是不可靠的。但是Service一旦创建，其IP就会一直固定直到这个Service消亡。其实我们能够看到，Kubernetes中一个Service就相当于一个微服务。这里我们就不细述Service的创建方法以及如何使用LB以及NodePort了。 Replica Sets和DeploymentReplica Sets被称为下一代的Replication Controller，它被设计出来的目的是替代RC并提供更多的功能。就目前看，ReplicaSet和RC的唯一区别是对于Labels和Selector的支持。RC只支持等值的方式，而ReplicaSet还支持集合的选择方式（In，Not In）。另外，ReplicaSet很少像RC一样单独使用（当然，它可以单独使用），一般都是配合Deployment一起使用。 Deployment也是Kubernetes新增加的一种资源，从它的名字就可以看出它主要是为部署而设计的，之前的文章中已经有具体的例子了。想像一下我们利用RC创建了一些Pod，但现在我们想要更新Pod内容器使用的镜像或者想更改副本的个数等。这些我们无法通过修改已有的RC去做，只能删除旧的，创建新的。但这样Pod内的容器就会停止，也即业务就会中断，这在生产环境中往往是不可接受的。但有了Deployment以后，这些问题就都可以解决了。通过Deployment我们可以动态的控制副本个数、ReplicaSet和Pod的状态、滚动升级等。Deployment的强大真的需要很长的一篇文章来介绍，后续的博客再介绍吧。 HPAHPA全称Horizontal Pod Autoscaling，即Pod的水平自动扩展，我觉得这个简直就是Kubernetes的黑科技。因为它可以根据当前系统的负载来自动水平扩容，如果系统负载超过预定值，就开始增加Pod的个数，如果低于某个值，就自动减少Pod的个数。因为被以前的系统扩容缩容深深的折磨过，所以我觉得这个功能是多么的强大。当然，目前Kubernetes的HPA只能根据CPU和内存去度量系统的负载，而且目前还依赖heapster去收集CPU的使用情况，所以功能还不是很强大，但是其完善也只是时间的问题了。让我们期待吧。 Namespace有时我们可能有这样的需求，需要在所有Pod上面（包括将来新创建的）都运行某个容器，比如用于监控、日志收集等。那我们就可以使用DaemonSet，它可以保证所有容器上面都运行一份我们指定的容器的实例。而且，通过Labels和Selector，我们可以实现只在某些Pod上面部署，非常的灵活。 但是现在也有一些局限，比如如果我们无法更改已经部署的Daemon Set。如果需要更改，只能删除重建。当然，更改的功能也已经在开发中了。 其他当然，Kubernetes还有很多其他的资源/对象，比如执行一次任务的Job，存储相关的Volume等，这些我觉得都没法简单的说清楚其功能。后续再介绍。写到这里，感觉本文已经和开始的说的简明、简短有些渐行渐远了…Oops]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
        <tag>kubernates</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker常用命令总结]]></title>
    <url>%2F2018%2F06%2F17%2Fblog%2Fdocker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[描述docker常用命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#显示虚悬镜像docker images -f dangling=true#删除虚悬镜像docker rmi $(docker images -q -f dangling=true)#删除所有镜像docker rmi $(docker images -q)#删除所有容器docker rm -f -v $(docker ps -a -q)#删除/启动所有退出的容器：docker rm/start $(docker ps -qf status=exited)#列出部分镜像docker images ubuntu* 【可以跟正则表达式】#只显示特定列以冒号分割docker images --format "&#123;&#123;.ID&#125;&#125;:&#123;&#123;.Repository&#125;&#125;:&#123;&#123;.Tag&#125;&#125;"#以表格等距显示docker images --format "table&#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Repository&#125;&#125;\t&#123;&#123;.Tag&#125;&#125;"#体查看镜像内的历史记录docker history tomcat:v1.0#查看容器的元数据信息docker inspect 容器IDdocker inspect -f"&#123;&#123;.HostConfig.CpuRealtimePeriod&#125;&#125;" c44ec20cef5f#更改容器中的时区时间docker run -it -e TZ='Asia/Shanghai' tom:v1.2 bash#是/etc/localtime在作怪，用户只需要将容器内部的localtime改成你想要的时区就行了。ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #显示当前运行容器的名称docker ps --format='&#123;&#123;.Names&#125;&#125;'#输出所有容器名包含test的容器，并打印容器名docker ps -f name=test --format='&#123;&#123;.Names&#125;&#125;'#查看退出状态的容器，并打印容器名docker ps -f status=exited --format="&#123;&#123;.Names&#125;&#125;"#只列出镜像的id以及仓库名称：docker images --format "&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;"#只列出容器的相关id,image,status和namedocker ps --format "&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Image&#125;&#125; : &#123;&#123;.Status&#125;&#125; : &#123;&#123;.Names&#125;&#125;"#使用alias来预定义常用的命令alias dockerrm='docker rm -f -v'#从宿主机拷贝文件到容器docker cp yum.log ecc6160b2884:/usr/local/tomcat#从容器拷贝文件到宿主机docker cp ecc6160b2884:/usr/local/tomcat /opt]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker network namespace]]></title>
    <url>%2F2018%2F03%2F17%2Fblog%2Fdocker%20network%20namespace%20%2F</url>
    <content type="text"><![CDATA[描述默认情况下，当 docker 实例被创建出来后，使用 ip netns 命令无法看到容器实例对应的 network namespace。这是因为 ip netns 命令是从 /var/run/netns 文件夹中读取内容的。步骤： 1、找到容器的主进程ID123docker run -it --name=wx tomcat:6 bashdocker inspect --format '&#123;&#123;.State.Pid&#125;&#125;' wx90818 2、创建 /var/run/netns 目录以及符号连接12mkdir /var/run/netnsln -s /proc/90818/ns/net /var/run/netns/wx 3、此时可以使用 ip netns 命令了12345678910111213141516171819说明：可以使用ip netns list查看命名空间ip netnsip netns exec wx ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN link/ipip 0.0.0.0 brd 0.0.0.0336: eth0@if337: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:05 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.5/24 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::42:acff:fe11:5/64 scope link valid_lft forever preferred_lft forever ip netns exec [后边可以执行容器中的命令]]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 时间不同步]]></title>
    <url>%2F2018%2F03%2F17%2Fblog%2Fdocker%20%E6%97%B6%E9%97%B4%E4%B8%8D%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[描述有时候会发现，容器中的时间与本地时间没有保持一致。需要修改配置解决，下面提供三种方法：1、Dockerfile1RUN echo "Asia/Shanghai" &gt; /etc/timezone 2、Sync the host time zone12345678 docker run -v /etc/localtime:/etc/localtime &lt;IMAGE:TAG&gt; ``` 3、container ```shell docker exec -it &lt;CONTAINER NAME&gt; bash echo "Asia/Shanghai" &gt; /etc/timezone`]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose使用]]></title>
    <url>%2F2018%2F03%2F17%2Fblog%2Fdocker-compose%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[描述大部分命令都可以运行在一个或多个服务上。如果没有特别的说明，命令则应用在项目所有的服务上。 执行 docker-compose [COMMAND] –help 查看具体某个命令的使用说明。 基本的使用格式是1docker-compose [options] [COMMAND] [ARGS...] 选项 --verbose 输出更多调试信息。 --version 打印版本并退出。 -f, --file FILE 使用特定的 compose 模板文件，默认为 docker-compose.yml。 -p, --project-name NAME 指定项目名称，默认使用目录名称。 命令build 构建或重新构建服务。 服务一旦构建后，将会带上一个标记名，例如 web_db。 可以随时在项目目录下运行 docker-compose build 来重新构建服务。 help 获得一个命令的帮助。 kill 通过发送 SIGKILL 信号来强制停止服务容器。支持通过参数来指定发送的信号，例如1$ docker-compose kill -s SIGINT logs 查看服务的输出。 port 打印绑定的公共端口。 ps 列出所有容器。 pull 拉取服务镜像。 rm 删除停止的服务容器。 run 在一个服务上执行一个命令。 例如：1$ docker-compose run ubuntu ping docker.com 将会启动一个 ubuntu 服务，执行 ping docker.com 命令。 默认情况下，所有关联的服务将会自动被启动，除非这些服务已经在运行中。 该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照期望创建。 两个不同点： 给定命令将会覆盖原有的自动运行命令；不会自动创建端口，以避免冲突。如果不希望自动启动关联的容器，可以使用 –no-deps 选项，例如1$ docker-compose run --no-deps web python manage.py shell 将不会启动 web 容器所关联的其它容器。 scale 设置同一个服务运行的容器个数。 通过 service=num 的参数来设置数量。例如：1$ docker-compose scale web=2 worker=3 start 启动一个已经存在的服务容器。 stop 停止一个已经运行的容器，但不删除它。通过 docker-compose start可以再次启动这些容器。 up 构建，（重新）创建，启动，链接一个服务相关的容器。 链接的服务都将会启动，除非他们已经运行。 默认情况， docker-compose up 将会整合所有容器的输出，并且退出时，所有容器将会停止。 如果使用 docker-compose up -d ，将会在后台启动并运行所有的容器。 默认情况，如果该服务的容器已经存在，docker-compose up 将会停止并尝试重新创建他们（保持使用 volumes-from 挂载的卷），以保证 docker-compose.yml 的修改生效。如果你不想容器被停止并重新创建，可以使用 docker-compose up --no-recreate。如果需要的话，这样将会启动已经停止的容器。 环境变量环境变量可以用来配置 Compose 的行为。 以DOCKER_开头的变量和用来配置 Docker 命令行客户端的使用一样。如果使用 boot2docker , $(boot2docker shellinit)将会设置它们为正确的值。 COMPOSE_PROJECT_NAME 设置通过 Compose 启动的每一个容器前添加的项目名称，默认是当前工作目录的名字。 COMPOSE_FILE 设置要使用的 docker-compose.yml 的路径。默认路径是当前工作目录。 DOCKER_HOST 设置 Docker daemon 的地址。默认使用 unix:///var/run/docker.sock，与 Docker 客户端采用的默认值一致。 DOCKER_TLS_VERIFY 如果设置不为空，则与 Docker daemon 交互通过 TLS 进行。 DOCKER_CERT_PATH 配置 TLS 通信所需要的验证（ca.pem、cert.pem 和 key.pem）文件的路径，默认是~/.docker 。]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop上传下载文件过程原理]]></title>
    <url>%2F2018%2F02%2F17%2Fblog%2Fhadoop%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E8%BF%87%E7%A8%8B%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[HDFS的体系结构NameNode：名称节点，是HDFS的管理员职责： 1、管理HDFS2、维护文件的元信息fsimage和操作日志edits3、日志edits：体现了HDFS最新的状态4、合并：定期将edits中的信息 —-&gt; fsimage 文件中5、接收客户端的请求 (1) NameNode会缓存1000M的元信息1234配置参数：hadoop-env.sh44 # The maximum amount of heap to use, in MB. Default is 1000.45 #export HADOOP_HEAPSIZE=46 #export HADOOP_NAMENODE_INIT_HEAPSIZE="" (2) 元信息的文件：fsimage —-&gt; 二进制 —&gt; 通过image viewer查看器12345产生：（*）内存满了 （*）stop-dfs.sh 停机加载：start-dfs.sh路径：/root/training/hadoop-2.4.1/tmp/dfs/name/currenthdfs oiv -i fsimage_0000000000000000179 -o ~/temp/fsimage.xml -p XML (3) 客户端操作日志：edits文件 —&gt; 二进制的文件 —&gt; 通过edits viewer查看器123路径：/root/training/hadoop-2.4.1/tmp/dfs/name/current使用日志查看器：hdfs oev -i edits_inprogress_0000000000000000182 -o ~/temp/log.xml (4) 如果只有一个NameNode1234567（*）问题1：如果死了，整个的HDFS无法访问（*）问题2：压力会比较大hadoop 1.x 没有解决办法hadoop 2.x 问题1 ----&gt; 失败迁移fail over ----&gt; 借助ZooKeeper问题2 ----&gt; 实现Load Balance ----&gt; 借助NameNode的联盟（Federation） DataNode: 数据节点(1) 在全分布环境下，至少两个(2) 用数据块保存数据, hadoop 1.x 64M hadoop2.x 128M(3) 具备水平复制功能(4) 机架感知(5) 保存的目录：在数据节点上的：/root/training/hadoop-2.4.1/tmp/dfs/data 数据上传和下载的过程上传过程 下载过程 HDFS保存数据的目录结构]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang学习第一天]]></title>
    <url>%2F2018%2F01%2F17%2Fblog%2Fgolang%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E5%A4%A9%2F</url>
    <content type="text"><![CDATA[描述Go 编程语言是一个开源项目，它使程序员更具生产力。 Go 语言具有很强的表达能力，它简洁、清晰而高效。得益于其并发机制， 用它编写的程序能够非常有效地利用多核与联网的计算机，其新颖的类型系统则使程序结构变得灵活而模块化。 Go 代码编译成机器码不仅非常迅速，还具有方便的垃圾收集机制和强大的运行时反射机制。 它是一个快速的、静态类型的编译型语言，感觉却像动态类型的解释型语言。 03_变量的使用.go12345678910111213141516171819202122232425262728293031323334package mainimport ( "fmt")func main() &#123; //一、变量 程序运行期间可以改变的 //1、声明格式： var 变量名 类型，注意：声明了就要使用 //2、只声明没有初始化按变量的默认值比如 int默认为0 //3、同一个&#123;&#125;里，变量必须唯一 var a int fmt.Println("a = ", a) //4、可以同时声明多个变量 //var b ,c int a = 10 fmt.Println("a = ", a) //二、变量的初始化，声明时可以直接赋值 var b int = 10 //初始化声明变量时同事赋值 b = 20 fmt.Println("b = ", b) //三、自动推导类型 必须初始化，根据初始化的值确定类型（常用） c := 2 d := 3.124323333 //%T打印变量所属的类型 fmt.Printf("c = %T\n", c) fmt.Printf("c = %v\n", c) fmt.Printf("c = %+v\n", c) fmt.Printf("c = %#v\n", c) fmt.Printf("%d\n", d)&#125; 04_自动推导类型.go12345678910111213141516171819package mainimport "fmt"func main() &#123; //赋值前必须先声明变量 var a int a = 10 //赋值可以使用N次 fmt.Println("a = ", a) //:=作用 自动推导类型 先声明类型在赋值 //自动推导只能使用一次，用于初始化时 b := 20 fmt.Println("b = ", b) b := 30 //已经声明过了，不能在声明，可以直接使用 b = 30 //只是赋值可以的 fmt.Println("b = ", b)&#125; 05_Printf和Println的区别.go123456789101112131415161718package mainimport ( "fmt")func main() &#123; a := 10 //println是输出之后直接换行 fmt.Println("a = ", a) //printf格式化输出 %d 是把a 的值放到%d的位置 fmt.Printf("a = %d\n", a) b := 20 c := 30 fmt.Println("a = ", a, "b = ", b, "c = ", c) fmt.Printf("a=%d,b=%d,c=%d ", a, b, c)&#125; 06_多重赋值和匿名变量.go1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( "fmt")//go函数可以返回多个值func test() (a, b, c int) &#123; return 1, 2, 3&#125;func main() &#123; // a := 10 // b := 20 // c := 30 a, b, c := 10, 20, 30 fmt.Println("a = ", a, "b = ", b, "c = ", c) //传统的变量交换 var tmp int tmp = a a = b b = tmp fmt.Println("a = ", a, "b = ", b) //变量交换 a, b = b, a fmt.Println("a = ", a, "b = ", b) //_匿名变量，丢弃数据不处理 //_匿名变量配合函数返回值使用才有优势 tmp, _ = a, b fmt.Println("tmp = ", tmp) var i, j, x int i, j, x = test() fmt.Println("i = ", i, "j = ", j, "x = ", x) _, j, _ = test() fmt.Println("i = ", i, "j = ", j, "x = ", x)&#125; 07_常量的使用.go123456789101112131415161718package mainimport ( "fmt")func main() &#123; //变量:程序运行期间可以改变，变量声明需要var //常量：程序运行期间不可以改变，变量声明需要const const a int = 10 //a = 20 err a是常量，不允许修改 fmt.Println("a = ", a) const b = 11.2 //没有使用:= 赋值 fmt.Println("b = ", b) fmt.Printf("b type %T\n", b)&#125; 08_多个变量和常量赋值.go123456789101112131415161718192021222324252627282930313233package mainimport ( "fmt")func main() &#123; //不同类型变量的声明 // var a int // var b float32 //优雅的写法 var ( a int b float32 ) a, b = 12, 34.32 fmt.Println("a = ", a, "b = ", b) // const i int // const j float32 //优雅的写法 const ( //可以自动推导 // i int = 10 // j float32 = 3.15 i = 10 j = 3.15 ) fmt.Println("i = ", i, "j = ", j)&#125; 09_iota枚举.go1234567891011121314151617181920212223242526272829303132333435363738package mainimport ( "fmt")func main() &#123; //1、iota常量自动生成器，每行自动累加1 //2、iota给常量赋值使用 const ( a = iota //0 b = iota //1 c = iota //2 ) fmt.Println("a = ", a, "b = ", b, "c = ", c) //3、iota遇到const重置为0 const d = iota fmt.Println("d = ", d) //4、可以只写一个iota const ( a1 = iota b1 c1 ) fmt.Println("a1 = ", a1, "b1 = ", b1, "c1 = ", c1) //5、如果是同一行，值都一样 const ( i = iota j1, j2, j3 = iota, iota, iota k = iota ) fmt.Println(i, j1, j2, j3, k)&#125; 10_bool类型.go1234567891011121314151617181920212223package mainimport ( "fmt")func main() &#123; //1、声明变量 var a bool a = true fmt.Println("a = ", a) //2、自动推导类型 var b = false fmt.Println("b = ", b) c := false fmt.Println("c = ", c) //3、默认值为false var d bool fmt.Println("d = ", d)&#125; 11_浮点类型.go123456789101112131415161718package mainimport ( "fmt")func main() &#123; //1、声明变量 var f1 float32 f1 = 3.14 fmt.Println("f = ", f1) //2、 自动推导类型 f2 := 3.14 fmt.Printf("f2 type is %T\n", f2) //f2 type is float64 //float64存储小数比fload32更准确&#125; ##12 ##12 ##12]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cxf部署在was中出现类加载的问题]]></title>
    <url>%2F2017%2F11%2F17%2Fblog%2Fcxf%E9%83%A8%E7%BD%B2%E5%9C%A8was%E4%B8%AD%E5%87%BA%E7%8E%B0%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[描述使用cxf2.7.6版本，在tomcat下开发部署web service访问正常，但是发布到was8.5则提示错误，提示的错误为： 单是抛出的异常，很容易就定位问题是提示说在xmlschema包里找不到这个方法。 于是我就查看了工程里面的xmlschema包，我用的版本是xmlschema-core-2.0.3.jar，包里面明明有read方法，为什么提示说没有read方法呢。 所以就有点怀疑工程里面的xmlschema.jar包使用了websphere的jar包，然后上网找了资料。 为了定位问题准确，我从网上下载了XmlSchema-1.4.7.jar版本的包，放到本地工程，把本地工程的xmlschema-core-2.0.3.jar去掉，然后启动tomcat，哈哈，这下tomcat抛出错误了，而且错误和替换包版本的war发布在websphere后的错误一样，这就说明本地工程的xmlschema包的确是使用了websphere自带的版本包，而websphere的包显然是版本过低。那怎么才能优先使用自己的jar包呢，于是去修改了war包的类加载顺序，发觉正常的jar包也不能识别了，发布websphere抛出一大堆classCastException的类转换错误，最后只能想别的办法了。后来想到websphere有共享库这么一个功能，也就是说可以设置共享库，使得war能使用上自己的jar包版本。 配置共享库1、拷贝冲突JAR把项目中的xmlschema-core-2.0.3.jar拷贝到websphere的lib包目录下:1/home/was/sharelib 该目录为共享库的目录 2、新建共享库 选择好作用域：为SERVER wsadmin脚本1AdminConfig.create('Library', AdminConfig.getid('/Server:/'), '[[nativePath ""] [name "xmlschema"] [isolatedClassLoader false] [description "xmlschema"] [classPath "/home/was/sharelib/xmlschema-core-2.0.1.jar"]]') 其中，类路径填写jar包的绝对路径，这个路径也就是前面所说的把本地的xmlschema包拷贝到websphere路径的绝对路径地址。填完后保存。 3、设置服务器使用共享库点击服务器-&gt;服务器类型-&gt;Websphere Application Server 选择“类已装入并且是先使用本地类装入器（父类最后）”，然后确定。wsadmin脚本12server1=AdminConfig.getid('/Server:/')AdminConfig.create('Classloader', AdminConfig.list('ApplicationServer',server1), '[[mode PARENT_LAST]]') 4、共享库引用 wsadmin脚本1234vi server.xml&lt;classloaders xmi:id="Classloader_1501571089954" mode="PARENT_LAST"&gt; &lt;libraries xmi:id="LibraryRef_1501573183338" libraryName="xmlschema"/&gt;&lt;/classloaders&gt; 进行修改 5、在war包添加共享库的使用 wsadmin脚本1AdminApp.edit('sysmgnt_war' , '[ -MapSharedLibForMod [[ sysmgnt_war META-INF/application.xml "xmlschema" ]]]' ) 6、修改类加载方式12打开deployment.xml文件在classloader标签中增加mode="PARENT_LAST"属性 7、重启服务器这一步是最后也是很重要的一步，所有设置只有在重启服务器才能生效。 问题跟踪再次启动SERVER，调用服务的时候，出现如下报错 在项目中搜索，没有发现DocumentImpl 这个类。 然后与开发人员联系，把他们给的两个JAR放到 共享目录中，问题解决。123456把jaxb-impl-2.2.6.jar和 xercesImpl-2.6.2-jaxb-1.0.6.jar 放到/home/was/sharelib目录修改libraries.xml 增加如下内容&lt;classPath&gt;/home/was/sharelib/jaxb-impl-2.2.6.jar&lt;/classPath&gt;&lt;classPath&gt;/home/was/sharelib/xercesImpl-2.6.2-jaxb-1.0.6.jar&lt;/classPath&gt;如下图： 重启SERVER，问题解决！]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>was</tag>
        <tag>webservice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos配置NFS服务器]]></title>
    <url>%2F2017%2F10%2F17%2Fblog%2Fcentos%E9%85%8D%E7%BD%AENFS%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[描述NFS 是Network File System的缩写，即网络文件系统。一种使用于分散式文件系统的协定，功能是让客户端通过网络访问不同主机上磁盘里的数据，主要用在类Unix系统上实现文件共享的一种方法。 NFS在文件传送或信息传送过程中依赖于RPC协议。RPC，远程过程调用 (Remote Procedure Call) 是能使客户端执行其他系统中程序的一种机制。NFS本身是没有提供信息传输的协议和功能的，但NFS却能让我们通过网络进行资料的分享，这是因为NFS使用了一些其它的传输协议。而这些传输协议用到这个RPC功能的。可以说NFS本身就是使用RPC的一个程序。或者说NFS也是一个RPC SERVER。所以只要用到NFS的地方都要启动RPC服务，不论是NFS SERVER或者NFS CLIENT。这样SERVER和CLIENT才能通过RPC来实现PROGRAM PORT的对应。可以这么理解RPC和NFS的关系：NFS是一个文件系统，而RPC是负责负责信息的传输。为了方便在linux主机中共享文件，我们搭建一个nfs服务器用于共享文件。 两台rhel7虚拟机在服务器端安装NFS服务软件包，服务器地址：192.168.10.11 安装NFS服务软件包123456[root@zyzx-master Packages]# rpm -ivh rpcbind-0.2.0-32.el7.x86_64.rpm 准备中... ################################# [100%] 软件包 rpcbind-0.2.0-32.el7.x86_64 已经安装[root@zyzx-master Packages]# rpm -ivh nfs-utils-1.3.0-0.21.el7.x86_64.rpm 准备中... ################################# [100%] 软件包 nfs-utils-1:1.3.0-0.21.el7.x86_64 已经安装 关闭防火墙1234567891011121314151617systemctl stop firewalldsystemctl disable firewalld#要想禁用selinux,则需要编辑selinux的配置文件,把SELINUX设置成disabled,然后重启生效[root@bogon share]#vi /etc/sysconfig/selinux[root@bogon share]#cat /etc/sysconfig/selinux# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled# SELINUXTYPE= can take one of three two values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection.SELINUXTYPE=targeted 启动NFS服务12345678先为rpcbind和nfs做开机启动：(必须先启动rpcbind服务) systemctl enable rpcbind.servicesystemctl enable nfs-server.service然后分别启动rpcbind和nfs服务：systemctl start rpcbind.servicesystemctl start nfs-server.service确认NFS服务器启动成功： 创建NFS目录1mkdir /nfs 编辑nfs配置文件：/etc/exports1/nfs 192.168.10.0/24(rw,sync) 12345678910111213141516171819202122232425262728293031NFS服务的主要配置文件为 /etc/exports./etc/exports文件内容格式： &lt;输出目录&gt; 客户端（选项:访问权限,用户映射,其他] 输出目录是指NFS系统中所定义的共享给客户端使用的文件系统 客户端是定义网络中可以访问这个NFS共享目录的IP地址或网段或域名等 客户端常用的指定方式 指定ip地址的主机：192.168.100.1 指定一个子网：192.168.100.0/24 也可以写成:192.168.100.0/255.255.255.0 指定域名的主机：david.bsmart.cn 指定域中的所有主机：*.bsmart.cn 所有主机：* 选项用来设置输出目录的访问权限、用户映射等。 NFS主要有3类选项： 设置输出目录只读：ro 设置输出目录读写：rw 用户映射选项 all_squash：将远程访问的所有普通用户及所属组都映射为匿名用户或用户组（nfsnobody）； no_all_squash：与all_squash取反（默认设置）； root_squash：将root用户及所属组都映射为匿名用户或用户组（默认设置）； no_root_squash：与rootsquash取反； anonuid=xxx：将远程访问的所有用户都映射为匿名用户，并指定该用户为本地用户（UID=xxx）； anongid=xxx：将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户（GID=xxx）； 其它选项 secure：限制客户端只能从小于1024的tcp/ip端口连接nfs服务器（默认设置）； insecure：允许客户端从大于1024的tcp/ip端口连接服务器； sync：将数据同步写入内存缓冲区与磁盘中，效率低，但可以保证数据的一致性； async：将数据先保存在内存缓冲区中，必要时才写入磁盘； wdelay：检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可以提高效率（默认设置）； no_wdelay：若有写操作则立即执行，应与sync配合使用； subtree：若输出目录是一个子目录，则nfs服务器将检查其父目录的权限(默认设置)； no_subtree：即使输出目录是一个子目录，nfs服务器也不检查其父目录的权限，这样可以提高效率； 在客户端验证在客户端查看可挂载nfs共享目录，发现一个可挂载目录，客户端地址：192.168.10.12123[root@zyzx-node2 nfs]# showmount -e 192.168.10.11Export list for 192.168.10.11:/nfs 192.168.10.0/24 在客户端创建共享目录并挂载1mount -t nfs 192.168.10.11:/nfs /mnt/nfs 使用df命令查看，发现已经挂载成功12[root@zyzx-node2 nfs]# df -h|grep nfs192.168.10.11:/nfs 28G 19G 9.0G 68% /mnt/nfs 在服务端放文件，客户端目录可以显示1234567891011121314服务端[root@zyzx-master Packages]# cd /nfs/[root@zyzx-master nfs]# ll总用量 12-rwxrwxrwx 1 root root 44 12月 14 03:35 abc.txt-rw------- 1 root root 5449 12月 14 03:30 admin.conf客户端[root@zyzx-node2 nfs]# pwd/mnt/nfs[root@zyzx-node2 nfs]# ll总用量 12-rwxrwxrwx. 1 root root 44 12月 14 03:35 abc.txt-rw-------. 1 root root 5449 12月 14 03:30 admin.conf]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AWK相关实例]]></title>
    <url>%2F2017%2F08%2F17%2Fblog%2FAWK%E7%9B%B8%E5%85%B3%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[描述Unix: awk ‘/pattern/ {print “$1”}’ # 标准 Unix shell环境DOS/Win: awk ‘/pattern/ {print “$1”}’ # DJGPP 可编译通过awk “/pattern/ {print \”$1\”}” # GnuWin32，UnxUtils，Mingw环境 需要特别注意的是，DJGPP编译器可以允许awk脚本使用Unix的引号语法‘/like/ {“this”}’。但是，用户必须知道在DOS/Windows环境下，使用CMD.EXE或者COMMAND.COM程序的话，单引号并不能保护重定向符号（&lt;, &gt;）和管道（|）。如果使用双引号的话，在DOS/CMD命令解释器下的特殊符号和他们的特殊含义都会被忽略。如果你的命令提示符是bash、ksh或者其他的Unix终端，单引号和双引号会沿用Unix标准的用法。 同样，DOS/Win用户必须记住用，百分号（%）用来标记DOS/Win环境变量，如果想要在awk使用的话，需要使用双百分号（%%）来表示一个百分号%。 如果我能确定一个脚本不需要被指出是使用在Unix, DOS或者CMD环境下，我通常会省略引号。如果一个例子是GNU awk所特有的，将会用 ‘gawk’命令来代替。如果你发现错误或者新的命令想要添加到这个列表里（总长度控制在65个字符一下），请通知我。首先我经常会尝试去写一个最短字符的脚本。为了省空间，我通常使用‘1’来代替’{print}’去打印每行，两种写法都能正确运行。 文本间隔： 文本间隔： 每行后面增加一行空行12awk '1;&#123;print ""&#125;'awk 'BEGIN&#123;ORS="\n\n"&#125;;1' 每行后面增加一行空行。输出文件不会包含连续的两个或两个以上的空行注意：在Unix系统， DOS行包括的 CRLF （\r\n） 通常会被作为非空行对待因此 ‘NF’ 将会返回TRUE。```shellawk ‘NF{print $0 “\n”}’ 每行后面增加两行空行```shellawk ‘1;{print “\n”}’ 编号和计算： 以文件为单位，在每句行前加上编号 （左对齐）使用制表符 （\t） 来代替空格可以有效保护页变的空白。```shellawk ‘{print FNR “\t” $0}’ files* 用制表符 （\t） 给所有文件加上连贯的编号。```shellawk ‘{print NR “\t” $0}’ files* 以文件为单位，在每句行前加上编号 （编号在左，右对齐）如果在DOS环境下，需要写两个’%’awk ‘{printf(“%5d : %s\n”, NR,$0)}’ 给非空白行的行加上编号记得Unix对于 \r 的处理的特殊之处。（上面已经提到）awk ‘NF{$0=++a “ :” $0};{print}’awk ‘{print (NF? ++a “ :” :””) $0}’ 计算行数 （模拟 “wc -l”）awk ‘END{print NR}’ 计算每行每个区域之和awk ‘{s=0; for (i=1; i&lt;=NF; i++) s=s+$i; print s}’ 计算所有行所有区域的总和awk ‘{for (i=1; i&lt;=NF; i++) s=s+$i}; END{print s}’ 打印每行每区域的绝对值awk ‘{for (i=1; i&lt;=NF; i++) if ($i &lt; 0) $i = -$i; print }’awk ‘{for (i=1; i&lt;=NF; i++) $i = ($i &lt; 0) ? -$i : $i; print }’ 计算所有行所有区域（词）的个数awk ‘{ total = total + NF }; END {print total}’ file 打印包含 “Beth” 的行数awk ‘/Beth/{n++}; END {print n+0}’ file 打印第一列最大的行并且在行前打印出这个最大的数awk ‘$1 &gt; max {max=$1; maxline=$0}; END{ print max, maxline}’ 打印每行的列数，并在后面跟上此行内容awk ‘{ print NF “:” $0 } ‘ 打印每行的最后一列awk ‘{ print $NF }’ 打印最后一行的最后一列awk ‘{ field = $NF }; END{ print field }’ 打印列数超过4的行awk ‘NF &gt; 4’ 打印最后一列大于4的行awk ‘$NF &gt; 4’ 构建字符串： 构建一指定长度的字符串（比如，513个空格）awk ‘BEGIN{while (a++&lt;513) s=s “ “; print s}’ 在某一位置中插入以特定长度的字符串例子：在每行第6列后插入49个空格gawk –re-interval ‘BEGIN{while(a++&lt;49)s=s “ “};{sub(/^.{6}/,”&amp;” s)};1’ 构建数组： 以下两个部分并不是一句话脚本，但是这些技巧相当便捷所以也包括进来 构建一个叫”month”的数组，以数字为索引，month[1]就是’Jan’，month[2]就是‘Feb’，month[3]就是’Mar’，以此类推。split(“Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec”, month, “ “) 构建一个叫”mdigit”的数组，以字符串为索引，mdigit[“Jan”] 等于 1，mdigit[“Feb”] 等于 2，等等。需要有”month”数组。for (i=1; i&lt;=12; i++) m_digit[month[i]] = i 文本转换和替代： 在Unix环境：转换DOS新行 （CR/LF） 为Unix格式awk ‘{sub(/\r$/,””)};1’ 假设每行都以Ctrl-M结尾 在Unix环境：转换Unix新行 （LF） 为DOS格式awk ‘{sub(/$/,”\r”)};1’ 在DOS环境：转换Unix新行 （LF） 为DOS格式awk 1 在DOS环境：转换DOS新行 （CR/LF） 为Unix格式DOS版本的awk不能运行, 只能用gawk:gawk -v BINMODE=”w” ‘1’ infile &gt;outfile 用 “tr” 替代的方法。tr -d \r outfile GNU tr 版本为 1.22 或者更高 删除每行前的空白（包括空格符和制表符）使所有文本左对齐awk ‘{sub(/^[ \t]+/, “”)};1’ 删除每行结尾的空白（包括空格符和制表符）awk ‘{sub(/[ \t]+$/, “”)};1’ 删除每行开头和结尾的所有空白（包括空格符和制表符）awk ‘{gsub(/^[ \t]+|[ \t]+$/,””)};1’awk ‘{$1=$1};1’ 每列之间的空白也被删除 在每一行开头处插入5个空格 （做整页的左位移）awk ‘{sub(/^/, “ “)};1’ 用79个字符为宽度，将全部文本右对齐awk ‘{printf “%79s\n”, $0}’ file* 用79个字符为宽度，将全部文本居中对齐awk ‘{l=length();s=int((79-l)/2); printf “%”(s+l)”s\n”,$0}’ file* 每行用 “bar” 查找替换 “foo”awk ‘{sub(/foo/,”bar”)}; 1’ 仅仅替换第一个找到的”foo”gawk ‘{$0=gensub(/foo/,”bar”,4)}; 1’ 仅仅替换第四个找到的”foo”awk ‘{gsub(/foo/,”bar”)}; 1’ 全部替换 在包含 “baz” 的行里，将 “foo” 替换为 “bar”awk ‘/baz/{gsub(/foo/, “bar”)}; 1’ 在不包含 “baz” 的行里，将 “foo” 替换为 “bar”awk ‘!/baz/{gsub(/foo/, “bar”)}; 1’ 将 “scarlet” 或者 “ruby” 或者 “puce” 替换为 “red”awk ‘{gsub(/scarlet|ruby|puce/, “red”)}; 1’ 倒排文本 （模拟 “tac”）awk ‘{a[i++]=$0} END {for (j=i-1; j&gt;=0;) print a[j–] }’ file* 如果一行结尾为反斜线符，将下一行接到这行后面（如果有连续多行后面带反斜线符，将会失败）awk ‘/\$/ {sub(/\$/,””); getline t; print $0 t; next}; 1’ file* 排序并打印所有登录用户的姓名awk -F “:” ‘{ print $1 | “sort” }’ /etc/passwd 以相反的顺序打印出每行的前两列awk ‘{print $2, $1}’ file 调换前两列的位置awk ‘{temp = $1; $1 = $2; $2 = temp}’ file 打印每行，并删除第二列awk ‘{ $2 = “”; print }’ 倒置每行并打印awk ‘{for (i=NF; i&gt;0; i–) printf(“%s “,i);printf (“\n”)}’ file 用逗号链接每5行awk ‘ORS=NR%5?”,”:”\n”‘ file 选择性的打印某些行： 打印文件的前十行 （模拟 “head”）awk ‘NR &lt; 11’ 打印文件的第一行 （模拟 “head -1”）awk ‘NR&gt;1{exit};1’ 打印文件的最后两行 （模拟 “tail -2”）awk ‘{y=x “\n” $0; x=$0};END{print y}’ 打印文件的最后一行 （模拟 “tail -1”）awk ‘END{print}’ 打印匹配正则表达式的行 （模拟 “grep”）awk ‘/regex/‘ 打印不匹配正则表达式的行 （模拟 “grep -v”）awk ‘!/regex/‘ 打印第5列等于”abc123”的行awk ‘$5 == “abc123”‘ 打印第5列不等于”abc123”的行这个同样可以用于打印少于5列的行awk ‘$5 != “abc123”‘awk ‘!($5 == “abc123”)’ 用正则匹配某一列awk ‘$7 ~ /^[a-f]/‘ 打印第7列匹配的行awk ‘$7 !~ /^[a-f]/‘ 打印第7列不匹配的行 打印匹配正则表达式的前一行，但是不打印当前行awk ‘/regex/{print x};{x=$0}’awk ‘/regex/{print (x==”” ? “match on line 1” : x)};{x=$0}’ 打印匹配正则表达式的后一行，但是不打印当前行awk ‘/regex/{getline;print}’ 以任何顺序查找包含 AAA、BBB 和 CCC 的行awk ‘/AAA/; /BBB/; /CCC/‘ 以指定顺序查找包含 AAA、BBB 和 CCC 的行awk ‘/AAA.BBB.CCC/‘ 打印长度大于64个字节的行awk ‘length &gt; 64’ 打印长度小于64个字节的行awk ‘length &lt; 64’ 打印从匹配正则起到文件末尾的内容awk ‘/regex/,0’awk ‘/regex/,EOF’ 打印指定行之间的内容 （8-12行, 包括第8和第12行）awk ‘NR==8,NR==12’ 打印第52行awk ‘NR==52’awk ‘NR==52 {print;exit}’ 对于大文件更有效率 打印两个正则匹配间的内容 （包括正则的内容）awk ‘/Iowa/,/Montana/‘ 大小写敏感 选择性的删除某些行： 删除所有空白行 （类似于 “grep ‘.’ “）awk NFawk ‘/./‘ 删除重复连续的行 （模拟 “uniq”）awk ‘a !~ $0; {a=$0}’ 删除重复的、非连续的行awk ‘! a[$0]++’ 最简练awk ‘!($0 in a) {a[$0];print}’ 最有效]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Java Api操作HDFS]]></title>
    <url>%2F2017%2F05%2F17%2Fblog%2F%E4%BD%BF%E7%94%A8Java%20Api%E6%93%8D%E4%BD%9CHDFS%2F</url>
    <content type="text"><![CDATA[描述导入所需JAR包12345/opt/hadoop-2.4.1/share/hadoop/common/opt/hadoop-2.4.1/share/hadoop/common/lib /opt/hadoop-2.4.1/share/hadoop/hdfs/opt/hadoop-2.4.1/share/hadoop/hdfs/lib 创建目录12345678910111213141516171819202122232425262728293031323334353637package com.ibm.hdfs.util;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.junit.Test;/** * Created by Administrator on 2017/5/16. * 如果出现如下报错，需要配置执行JAVA程序的用户权限 * Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): * Permission denied: user=collen, access=WRITE, inode="/":root:supergroup:drwxr-xr-x * 方法一：设置环境变量 System.setProperty("HADOOP_USER_NAME","root"); * 方法二：使用JAVA程序-DHADOOP_USER_NAME=root 参数方式 配置启动JAVA程序的方式 * 方法三：使用chmod方式 hdfs dfs -chmod 777 指定目录 * 方法四：使用dfs.permissions ----&gt; false不验证 配置HDFS-SITE.XML文件 */public class HdfsDemo &#123; @Test public void testMkdir() throws Exception&#123; //System.setProperty("HADOOP_USER_NAME","root"); //配置信息代表HDFS的NAMENODE Configuration conf = new Configuration(); conf.set("fs.defaultFS","hdfs://192.168.10.44:9000"); //得到HDFS的client端-----&gt;子类:DistributedFileSystem FileSystem fileSystem = FileSystem.get(conf); //创建目录 fileSystem.mkdirs(new Path("/tools")); //关闭客户端 fileSystem.close(); &#125;&#125; 上传操作12345678910111213141516171819202122232425@Test public void testUpload()throws Exception&#123; //配置信息代表HDFS的NAMENODE Configuration conf = new Configuration(); conf.set("fs.defaultFS","hdfs://192.168.10.44:9000"); //得到HDFS的client端-----&gt;子类:DistributedFileSystem FileSystem fileSystem = FileSystem.get(conf); OutputStream outputStream = fileSystem.create(new Path("/tools/hadoop-2.7.2.tar.gz")); InputStream inputStream = new FileInputStream("D:\\software\\javatools\\hadoop-2.7.2.tar.gz"); //传统操作 //byte[] buffer = new byte[1024]; //int len=0; //while((len= inputStream.read(buffer))&gt;0)&#123; // outputStream.write(buffer,0,len); //&#125; //简化操作 IOUtils.copyBytes(inputStream,outputStream,1024); outputStream.flush(); outputStream.close(); inputStream.close(); &#125; 下载操作1234567891011121314151617@Test public void testDownload()throws Exception&#123; //配置信息代表HDFS的NAMENODE Configuration conf = new Configuration(); conf.set("fs.defaultFS","hdfs://192.168.10.44:9000"); //得到HDFS的client端-----&gt;子类:DistributedFileSystem FileSystem fileSystem = FileSystem.get(conf); InputStream inputStream = fileSystem.open(new Path("/tools/hadoop-2.7.2.tar.gz")); OutputStream outputStream = new FileOutputStream("d:\\ha.tar.gz"); IOUtils.copyBytes(inputStream,outputStream,1024); outputStream.close(); inputStream.close(); &#125; 获取文件信息123456789101112131415161718192021@Test public void testsGetFileStatus()throws Exception&#123; //配置信息代表HDFS的NAMENODE Configuration conf = new Configuration(); conf.set("fs.defaultFS","hdfs://192.168.10.44:9000"); //得到HDFS的client端-----&gt;子类:DistributedFileSystem FileSystem fileSystem = FileSystem.get(conf); //获取tools目录下所有的文件信息 FileStatus fileStatus [] = fileSystem.listStatus(new Path("/tools")); for (FileStatus file :fileStatus)&#123; System.out.println(file.isDirectory()?"directory":"file"); System.out.println("name:"+file.getPath().getName()); System.out.println(file.getBlockSize()); System.out.println(file.getOwner()); System.out.println(file.getPermission()); System.out.println("**************************************"); &#125; &#125; 获取数据块信息1234567891011121314151617181920@Test public void testsGetFileBlocks()throws Exception&#123; //配置信息代表HDFS的NAMENODE Configuration conf = new Configuration(); conf.set("fs.defaultFS","hdfs://192.168.10.44:9000"); //得到HDFS的client端-----&gt;子类:DistributedFileSystem FileSystem fileSystem = FileSystem.get(conf); //获取 /tools/hadoop-2.7.2.tar.gz文件的数据块信息 FileStatus fileStatus = fileSystem.getFileStatus(new Path("/tools/hadoop-2.7.2.tar.gz")); //获取该文件的数据块位置信息：获取文件的所有数据块 BlockLocation[] blockLocations = fileSystem.getFileBlockLocations(fileStatus, 0, fileStatus.getLen()); for (BlockLocation block:blockLocations)&#123; //打印数据块信息 System.out.println(Arrays.toString(block.getHosts())+"\t"+Arrays.toString(block.getNames())); &#125; fileSystem.close(); &#125;]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>云计算</tag>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三部分：第二章、带着祷告和顺服的心查经]]></title>
    <url>%2F2016%2F08%2F17%2Fblog%2F%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%EF%BC%9A%E7%AC%AC%E4%BA%8C%E7%AB%A0%E3%80%81%E5%B8%A6%E7%9D%80%E7%A5%B7%E5%91%8A%E5%92%8C%E9%A1%BA%E6%9C%8D%E7%9A%84%E5%BF%83%E6%9F%A5%E7%BB%8F%2F</url>
    <content type="text"><![CDATA[描述12345脱离了圣灵的引导，我们是没办法正确解读圣经的。我们读经必须要带着祈求、渴慕和爱祂的心，渴望圣灵来带领我们，以至于我们愿意说：“主啊，我们现在要来读你的话语，求你帮助我们明白这些话。”而当我们读懂的时候，更求你帮助我们去遵行。我们读经前要祷告，求主你帮助我们不仅仅是明白你的道，更是去行你的道。 有没有“最正确”的查经方法？ 查经很重要，这点恐怕没人反对。但是，什么才是最好的查经方法，就众说纷纭了。基督徒如何读经并没有统一模式。有些人把圣经当作课本或规则手册，在圣经里寻找生活方向。有些人喜欢故事和圣经里的人物，把圣经当作灵感的来源，效法圣经里的敬虔模范。还有些人采取一种神秘的方式对待圣经，他们随手一翻，看哪句话给自己属灵的引导或鼓励，帮助自己面对生活。还有一种比较学术的方法，人们仔细研究每句经文，努力找出作者的本意。 中心概括]]></content>
      <categories>
        <category>团契生活</category>
      </categories>
      <tags>
        <tag>小组学习</tag>
        <tag>得人如鱼</tag>
        <tag>门徒训练</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决ocijdbc10 (Not found in java.library.path)]]></title>
    <url>%2F2016%2F08%2F17%2Fblog%2F%E8%A7%A3%E5%86%B3ocijdbc10%20(Not%20found%20in%20java.library.path)%2F</url>
    <content type="text"><![CDATA[描述把之前在TOMCAT上的应用迁移到WAS中，应用安装完成之后，在启动的时候出现如下错误： java.lang.UnsatisfiedLinkError: ocijdbc10 (Not found in java.library.path) 解决方法该错误为找不到ocijdbc10的驱动程序，在测试环境安装oracle 10.2.0的客户端，安装完成之后。 配置环境变量如下：123export ORACLE_BASE=/home/was/oracle/export ORACLE_HOME=$ORACLE_BASE/product/10.2.0/db_1/export LD_LIBRARY_PATH=$ORACLE_HOME/lib 启动SERVER，该问题解决。 但是在生产环境按如上方法进行修改时，发现问题还是一样。 排查问题发现生产环境的ORACLE客户端版本为 11.2.0 通过配置环境变量如下：123export ORACLE_BASE=/home/was/oracle11export ORACLE_HOME=$ORACLE_BASE/app/oracle/product/11.2.0/client_1export LD_LIBRARY_PATH=/home/was/oracle11/app/oracle/product/11.2.0/client_1/lib 启动SERVER还是报同样的错误。 最近发现lib目录中用到的是ocijdbc11 的库文件。但项目中使用的是ojdbc14.jar 发现ojdbc14.jar是 oracle10的驱动 ojdbc6.jar才是oracle11的驱动。把ojdbc14.jar 替换成ojdbc6.jar问题解决 补充说明在使用Oracle JDBC驱动时，有些问题你是不是通过替换不同版本的Oracle JDBC驱动来解决的？最常使用的ojdbc14.jar有多个版本，classes12.jar有多个版本你了解吗？ 连接类型：1、JDBC OCI： oci是oracle call interface的缩写，此驱动类似于传统的ODBC 驱动。因为它需要Oracle Call Interface and Net8，所以它需要在运行使用此驱动的JAVA程序的机器上安装客户端软件，其实主要是用到orcale客户端里以dll方式提供的oci和服务器配 置。 2、JDBC Thin： thin是for thin client的意思，这种驱动一般用在运行在WEB浏览器中的JAVA程序。它不是通过OCI or Net8，而是通过Java sockets进行通信，是纯java实现的驱动，因此不需要在使用JDBC Thin的客户端机器上安装orcale客户端软件，所以有很好的移植性，通常用在web开发中。 随Oracle 8i发布的Oracle JDBC驱动8.1.7版本 classes111.zip 适用于JDK 1.1.x classes12.zip 适用于JDK 1.2.x 只有zip文件，无jar文件。 随Oracle 9i发布的Oracle JDBC驱动9.2.0版本 classes111.jar 适用于JDK 1.1.x classes12.jar 适用于JDK 1.2 and JDK 1.3 （我的项目环境JDK1.6，oracle 10g，windows，用了这个目前没发现问题） ojdbc14.jar 适用于JDK 1.4 classes111.zip 适用于JDK 1.1.x classes12.zip 适用于JDK 1.2.x *_g.jar 只是用javac -g编译，生成所有调试信息，其它全一样 新特性：1、Thin连接类型的驱动对BFILE，BLOB，CLOB 提供直接支持，以前通常是调用PL/SQL来实现。 2、支持JDBC 3.0 特性 3、ojdbc14.jar 支持JDK 1.4 4、ojdbc14.jar 支持保存点（Savepoint） 5、可以在不同的连接池中使用PreparedStatement，这是重要的性能提升 从此以后新的jar文件的命名采用 ojdbc.jar 格式 ，以前的jar文件名称不变 随Oracle 10.2发布的Oracle JDBC驱动10.2版本 classes12.jar 适用于JDK 1.2 and JDK 1.3. ojdbc14.jar 适用于 JDK 1.4 and 5.0 *_g.jar 只是用javac -g编译，生成所有调试信息，其它全一样 特点： 1、全面支持JDK 1.5 2、支持JDBC 3.0 随Oracle 11.1发布的Oracle JDBC驱动11.1版本 ojdbc5.jar: 适用于jdk5 ojdbc6.jar: 适用于jdk6 （如果你使用jdk1.5,就不能使用这个驱动） *_g.jar 只是用javac -g编译，生成所有调试信息，其它全一样 新特性： 1、ojdbc6.jar：支持JDK6，支持JDBC 4.0，新的java.sql.SQLXML类型没有被支持。 ojdbc5.jar：全面支持使用JDK5 和 JDBC 3.0 。 2、建议使用oracle.jdbc.OracleDriver类，不建议使用oracle.jdbc.driver.OracleDriver。从9.0.1开始的每个release都推荐使用oracle.jdbc。 3、j2se 1.2,1.3,1.4不再支持。11R1不再包括这些版本的jar和zip，如果仍然使用这些版本，可以继续使用10gR2的jdbc。 4、11gR1 Thin driver支持AES加密算法，SHA1 hash算法，RADIUS, KERBEROS，SSL认证机制. 5、支持ANYDATE和ANYTYPE类型。这两种类型自9i引入，11R1前，程序员只能通过PL/SQL操作。 6、高级队列支持。11R1提供了访问AQ的高性能接口。 7、支持数据库变更通知。 8、Thin和OCI的数据库启动和关闭。11R1提供了这样的方法来启动和关闭数据库。 9、新的工厂方法。Oracle JDBC 11R1 oracle.jdbc.OracleConnection提供了创建Oracle对象的工厂方法。 包括ARRAY, BFILE, DATE, INTERVALDS, NUMBER, STRUCT, TIME,TIMESTAMP,TIMESTAMP等。 总体讲新版本的JDBC驱动 性能强、很多bug被发现并已解决。我遇到的，之前使用ojdbc14.jar（不记得哪个版本了）批量插入10万条，实际只插入了3万多条，其它的丢失了，换ojdbc6.jar后，一次commit批量插入100万条也OK了。 尽量使用和数据库版本一致的驱动,有bug时，换高版本的JDBC驱动试试 。 如果一个jdbc的jar包你不知道是那个版本的,可以解压这个jar包,再META-INF\MANIFEST.MF 文件中找”Oracle JDBC Driver version - 10.1.0.2.0”字样,就知道版本了.]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>was</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动运行脚本控制命令等地方是否出现WebSphere明文口令]]></title>
    <url>%2F2016%2F08%2F17%2Fblog%2F%E8%87%AA%E5%8A%A8%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%91%BD%E4%BB%A4%E7%AD%89%E5%9C%B0%E6%96%B9%E6%98%AF%E5%90%A6%E5%87%BA%E7%8E%B0WebSphere%E6%98%8E%E6%96%87%E5%8F%A3%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[描述如果was启用了安全性，在停止WAS server的时候必须输入用户名和密码：1./stopServer.sh server1 -username wasadmin -password wasadmin 黑客可以通过查询脚本、shell 历史、ps -ef等方法看到用户名、密码，造成安全隐患。 解决方案解决问题的方法：编辑 /WebSphere安装目录/profiles/server目录/properties/soap.client.props123com.ibm.SOAP.securityEnabled=truecom.ibm.SOAP.loginUserid=wasadmincom.ibm.SOAP.loginPassword=wasadmin com.ibm.SOAP.loginUserid登录DMGR的用户名，com.ibm.SOAP.loginPassword 为登录DMGR的密码。配置完properties文件的用户密码之后,通过PropFilePasswordEncoder来加密密码，命令格式为：PropFilePasswordEncoder.sh properties文件的绝对路径 密码的property名字12例如：st./PropFilePasswordEncoder.sh /opt/IBM/WebSphere/AppServer/profiles/AppSrv01/properties/soap.client.props com.ibm.SOAP.loginPassword 执行命令之后，打开soap.client.props文件里面password已经加密。（注意：com.ibm.SOAP.securityEnabled=true）12345678例如：com.ibm.SOAP.securityEnabled=true#------------------------------------------------------------------------------# - authenticationTarget ( BasicAuth[default], KRB5. These are the only supported selection# on a pure client for JMX SOAP Connector Client. )#------------------------------------------------------------------------------com.ibm.SOAP.authenticationTarget=BasicAuthcom.ibm.SOAP.loginUserid=wasadmincom.ibm.SOAP.loginPassword=&#123;xor&#125;KD4sPjsyNjE= 重启server，即生效]]></content>
      <categories>
        <category>技术文章</category>
      </categories>
      <tags>
        <tag>was</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一次为了写点东西花钱]]></title>
    <url>%2F2016%2F07%2F17%2Fblog%2F%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%B8%BA%E4%BA%86%E5%86%99%E7%82%B9%E4%B8%9C%E8%A5%BF%E8%8A%B1%E9%92%B1%2F</url>
    <content type="text"><![CDATA[描述WordMark 是一款轻量级到 Markdown 客户端，拥有 Windows、macOS 与 Linux 版本，支持发布到 Wordpress、GitHub、Evernote 等平台，以及支持 imgur 七牛 等图片平台，适合于喜欢使用 Markdown 创作文字的同学。 WordMark 定位于博客客户端与编辑器，所以支持 WordPress、ghost、Medium、GitHub、Evernote、Blogger、tumblr、印象笔记、Dropbox 是亮点，另外还支持 imgur、AWS、Flickr、七牛 图片上传服务，对于喜欢撰写博客点 Markdown 用户来说，非常方便。 购买用了一段时间 wordmark 感觉得心应手，突然有一点打开之后提示，悲剧了： 网上找了好久也没有注册码、序列号之类的，更没有破解版、绿色版。 看来之能花钱买了，网上查一下，也不贵36.3 。还有零有整的。不知道老外咋想的呵呵 第一次花钱买一个小软件。特此纪念！]]></content>
      <categories>
        <category>生活感悟</category>
      </categories>
      <tags>
        <tag>wordmark</tag>
        <tag>工作</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[铭恩宝贝的日常——20170501]]></title>
    <url>%2F2016%2F03%2F17%2Fblog%2F%E9%93%AD%E6%81%A9%E5%AE%9D%E8%B4%9D%E7%9A%84%E6%97%A5%E5%B8%B8%E2%80%94%E2%80%9420170501%2F</url>
    <content type="text"><![CDATA[描述铭恩宝贝的日常，记录与2017年的五一劳动节。 注册了时光相册，用于存放小铭恩的照片和视频，留下美好的回忆。 1睡的真香呵呵 1最好看的一张呵呵 1夕阳美景——拍摄于郑州东区 1大理洱海 蜜月之旅]]></content>
      <categories>
        <category>铭恩宝贝</category>
      </categories>
      <tags>
        <tag>铭恩</tag>
        <tag>儿子</tag>
      </tags>
  </entry>
</search>
